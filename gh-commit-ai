#!/usr/bin/env bash

set -e

VERSION="1.0.0"

# Colors for output (simplified palette)
RED='\033[38;2;174;32;18m'     # #AE2012 (errors only)
NC='\033[0m' # No Color

# Simple YAML parser (supports only simple key: value pairs)
parse_yaml_config() {
    local config_file="$1"

    if [ ! -f "$config_file" ]; then
        return
    fi

    while IFS=: read -r key value; do
        # Skip comments and empty lines
        [[ "$key" =~ ^[[:space:]]*# ]] && continue
        [[ -z "$key" ]] && continue

        # Trim whitespace
        key=$(echo "$key" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
        value=$(echo "$value" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')

        # Remove quotes from value
        value=$(echo "$value" | sed 's/^["'\'']\|["'\'']$//g')

        # Only set if not already set by environment variable
        case "$key" in
            ai_provider|AI_PROVIDER)
                CONFIG_AI_PROVIDER="${CONFIG_AI_PROVIDER:-$value}"
                ;;
            ollama_model|OLLAMA_MODEL)
                CONFIG_OLLAMA_MODEL="${CONFIG_OLLAMA_MODEL:-$value}"
                ;;
            ollama_host|OLLAMA_HOST)
                CONFIG_OLLAMA_HOST="${CONFIG_OLLAMA_HOST:-$value}"
                ;;
            anthropic_model|ANTHROPIC_MODEL)
                CONFIG_ANTHROPIC_MODEL="${CONFIG_ANTHROPIC_MODEL:-$value}"
                ;;
            openai_model|OPENAI_MODEL)
                CONFIG_OPENAI_MODEL="${CONFIG_OPENAI_MODEL:-$value}"
                ;;
            groq_model|GROQ_MODEL)
                CONFIG_GROQ_MODEL="${CONFIG_GROQ_MODEL:-$value}"
                ;;
            use_scope|USE_SCOPE)
                CONFIG_USE_SCOPE="${CONFIG_USE_SCOPE:-$value}"
                ;;
            diff_max_lines|DIFF_MAX_LINES)
                CONFIG_DIFF_MAX_LINES="${CONFIG_DIFF_MAX_LINES:-$value}"
                ;;
            learn_from_history|LEARN_FROM_HISTORY)
                CONFIG_LEARN_FROM_HISTORY="${CONFIG_LEARN_FROM_HISTORY:-$value}"
                ;;
            use_gitmoji|USE_GITMOJI)
                CONFIG_USE_GITMOJI="${CONFIG_USE_GITMOJI:-$value}"
                ;;
            code_review_model|CODE_REVIEW_MODEL)
                CONFIG_CODE_REVIEW_MODEL="${CONFIG_CODE_REVIEW_MODEL:-$value}"
                ;;
            code_review_anthropic_model|CODE_REVIEW_ANTHROPIC_MODEL)
                CONFIG_CODE_REVIEW_ANTHROPIC_MODEL="${CONFIG_CODE_REVIEW_ANTHROPIC_MODEL:-$value}"
                ;;
            code_review_openai_model|CODE_REVIEW_OPENAI_MODEL)
                CONFIG_CODE_REVIEW_OPENAI_MODEL="${CONFIG_CODE_REVIEW_OPENAI_MODEL:-$value}"
                ;;
            code_review_groq_model|CODE_REVIEW_GROQ_MODEL)
                CONFIG_CODE_REVIEW_GROQ_MODEL="${CONFIG_CODE_REVIEW_GROQ_MODEL:-$value}"
                ;;
            commit_language|COMMIT_LANGUAGE)
                CONFIG_COMMIT_LANGUAGE="${CONFIG_COMMIT_LANGUAGE:-$value}"
                ;;
            analysis_threshold|ANALYSIS_THRESHOLD)
                CONFIG_ANALYSIS_THRESHOLD="${CONFIG_ANALYSIS_THRESHOLD:-$value}"
                ;;
        esac
    done < "$config_file"
}

# Load configuration from files (global then local)
# Global config (in user's home directory)
if [ -f "$HOME/.gh-commit-ai.yml" ]; then
    parse_yaml_config "$HOME/.gh-commit-ai.yml"
fi

# Local config (in current repository)
if [ -f ".gh-commit-ai.yml" ]; then
    parse_yaml_config ".gh-commit-ai.yml"
fi

# Configuration (priority: env vars > local config > global config > defaults)
AI_PROVIDER="${AI_PROVIDER:-${CONFIG_AI_PROVIDER:-auto}}"  # Options: auto, ollama, anthropic, openai, groq
OLLAMA_MODEL="${OLLAMA_MODEL:-${CONFIG_OLLAMA_MODEL:-gemma3:12b}}"
OLLAMA_HOST="${OLLAMA_HOST:-${CONFIG_OLLAMA_HOST:-http://localhost:11434}}"
ANTHROPIC_MODEL="${ANTHROPIC_MODEL:-${CONFIG_ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}}"
ANTHROPIC_API_KEY="${ANTHROPIC_API_KEY:-}"
OPENAI_MODEL="${OPENAI_MODEL:-${CONFIG_OPENAI_MODEL:-gpt-4o-mini}}"
OPENAI_API_KEY="${OPENAI_API_KEY:-}"
GROQ_MODEL="${GROQ_MODEL:-${CONFIG_GROQ_MODEL:-llama-3.3-70b-versatile}}"
GROQ_API_KEY="${GROQ_API_KEY:-}"
DIFF_MAX_LINES="${DIFF_MAX_LINES:-${CONFIG_DIFF_MAX_LINES:-200}}"  # Limit diff lines for faster processing
USE_SCOPE="${USE_SCOPE:-${CONFIG_USE_SCOPE:-false}}"  # Enable/disable conventional commit scopes
USE_GITMOJI="${USE_GITMOJI:-${CONFIG_USE_GITMOJI:-false}}"  # Enable/disable gitmoji prefixes
LEARN_FROM_HISTORY="${LEARN_FROM_HISTORY:-${CONFIG_LEARN_FROM_HISTORY:-true}}"  # Enable/disable learning from commit history
ANALYSIS_THRESHOLD="${ANALYSIS_THRESHOLD:-${CONFIG_ANALYSIS_THRESHOLD:-15}}"  # Skip expensive analysis for commits smaller than this (lines changed)
# Code review specific models (optional - falls back to regular models if not set)
CODE_REVIEW_MODEL="${CODE_REVIEW_MODEL:-${CONFIG_CODE_REVIEW_MODEL:-}}"  # Dedicated model for code reviews (Ollama)
CODE_REVIEW_ANTHROPIC_MODEL="${CODE_REVIEW_ANTHROPIC_MODEL:-${CONFIG_CODE_REVIEW_ANTHROPIC_MODEL:-}}"  # Anthropic model for reviews
CODE_REVIEW_OPENAI_MODEL="${CODE_REVIEW_OPENAI_MODEL:-${CONFIG_CODE_REVIEW_OPENAI_MODEL:-}}"  # OpenAI model for reviews
CODE_REVIEW_GROQ_MODEL="${CODE_REVIEW_GROQ_MODEL:-${CONFIG_CODE_REVIEW_GROQ_MODEL:-}}"  # Groq model for reviews

# Language configuration for commit messages
COMMIT_LANGUAGE="${COMMIT_LANGUAGE:-${CONFIG_COMMIT_LANGUAGE:-}}"  # Language for commit messages (en, es, fr, de, ja, zh, etc.)

# Detect language from git config or system locale if not explicitly set
detect_language() {
    # If already set, use it
    if [ -n "$COMMIT_LANGUAGE" ]; then
        echo "$COMMIT_LANGUAGE"
        return
    fi

    # Try to get from git config
    local git_language=$(git config --get commit.language 2>/dev/null || echo "")
    if [ -n "$git_language" ]; then
        echo "$git_language"
        return
    fi

    # Try to detect from system locale
    local lang_var="${LANG:-${LC_ALL:-}}"
    if [ -n "$lang_var" ]; then
        # Extract language code (e.g., en_US.UTF-8 -> en, es_ES.UTF-8 -> es)
        local lang_code=$(echo "$lang_var" | cut -d'_' -f1 | cut -d'.' -f1)
        if [ -n "$lang_code" ] && [ "$lang_code" != "C" ] && [ "$lang_code" != "POSIX" ]; then
            echo "$lang_code"
            return
        fi
    fi

    # Default to English
    echo "en"
}

# Detect and set the language
DETECTED_LANGUAGE=$(detect_language)
COMMIT_LANGUAGE="${COMMIT_LANGUAGE:-$DETECTED_LANGUAGE}"

# Map language codes to full names for display
get_language_name() {
    case "$1" in
        en) echo "English" ;;
        es) echo "Spanish" ;;
        fr) echo "French" ;;
        de) echo "German" ;;
        ja) echo "Japanese" ;;
        zh) echo "Chinese" ;;
        pt) echo "Portuguese" ;;
        ru) echo "Russian" ;;
        it) echo "Italian" ;;
        ko) echo "Korean" ;;
        nl) echo "Dutch" ;;
        pl) echo "Polish" ;;
        tr) echo "Turkish" ;;
        ar) echo "Arabic" ;;
        hi) echo "Hindi" ;;
        *) echo "English" ;;
    esac
}

# Git diff exclusion patterns - exclude lock files and other generated files
# These files are auto-generated and not useful for AI analysis
GIT_EXCLUDE_PATTERN="':(exclude)package-lock.json' ':(exclude)yarn.lock' ':(exclude)pnpm-lock.yaml' ':(exclude)Gemfile.lock' ':(exclude)Cargo.lock' ':(exclude)poetry.lock' ':(exclude)composer.lock' ':(exclude)Pipfile.lock' ':(exclude)go.sum' ':(exclude)*.min.js' ':(exclude)*.min.css'"

# Network retry configuration
MAX_RETRIES="${MAX_RETRIES:-3}"  # Maximum number of retry attempts
RETRY_DELAY="${RETRY_DELAY:-2}"  # Initial retry delay in seconds (doubles each retry)
CONNECT_TIMEOUT="${CONNECT_TIMEOUT:-10}"  # Connection timeout in seconds
MAX_TIME="${MAX_TIME:-120}"  # Maximum time for entire request in seconds

# ============================================================================
# Security Functions
# ============================================================================

# Create a secure temporary file with restricted permissions (600)
# Returns the path to the created file
create_secure_temp_file() {
    local prefix="${1:-gh-commit-ai}"
    local temp_file

    # Use mktemp for secure temp file creation
    temp_file=$(mktemp "/tmp/${prefix}.XXXXXXXXXX") || {
        echo -e "${RED}Error: Failed to create secure temporary file${NC}" >&2
        return 1
    }

    # Ensure restrictive permissions (owner read/write only)
    chmod 600 "$temp_file" 2>/dev/null || {
        echo -e "${RED}Error: Failed to set secure permissions on temporary file${NC}" >&2
        rm -f "$temp_file"
        return 1
    }

    echo "$temp_file"
}

# Validate that a parameter is a positive integer
# Usage: validate_positive_integer <value> <param_name>
# Returns: 0 if valid, 1 if invalid
validate_positive_integer() {
    local value="$1"
    local param_name="$2"

    # Check if value is empty
    if [ -z "$value" ]; then
        echo -e "${RED}Error: ${param_name} cannot be empty${NC}" >&2
        return 1
    fi

    # Check if value is a positive integer
    if ! [[ "$value" =~ ^[0-9]+$ ]]; then
        echo -e "${RED}Error: ${param_name} must be a positive integer, got: $value${NC}" >&2
        return 1
    fi

    # Check if value is zero
    if [ "$value" -eq 0 ]; then
        echo -e "${RED}Error: ${param_name} must be greater than zero${NC}" >&2
        return 1
    fi

    return 0
}

# Validate that a parameter is within a set of allowed values
# Usage: validate_allowed_values <value> <param_name> <allowed1> <allowed2> ...
# Returns: 0 if valid, 1 if invalid
validate_allowed_values() {
    local value="$1"
    local param_name="$2"
    shift 2
    local allowed_values=("$@")

    # Check if value is empty
    if [ -z "$value" ]; then
        echo -e "${RED}Error: ${param_name} cannot be empty${NC}" >&2
        return 1
    fi

    # Check if value is in allowed list
    for allowed in "${allowed_values[@]}"; do
        if [ "$value" = "$allowed" ]; then
            return 0
        fi
    done

    # Value not found in allowed list
    echo -e "${RED}Error: ${param_name} must be one of: ${allowed_values[*]}, got: $value${NC}" >&2
    return 1
}

# Sanitize a string to prevent command injection
# Removes or escapes potentially dangerous characters
# Usage: sanitize_string <string>
sanitize_string() {
    local input="$1"

    # Remove null bytes, control characters, and backticks
    # Keep only printable ASCII + common unicode
    echo "$input" | tr -d '\000-\010\013-\037\177`$(){}[]<>|;&'
}

# ============================================================================
# Network and Error Handling
# ============================================================================

# Check if we have basic network connectivity
# Returns 0 if online, 1 if offline
check_network_connectivity() {
    # Try to resolve common DNS names
    if command -v host >/dev/null 2>&1; then
        host google.com >/dev/null 2>&1 && return 0
    elif command -v nslookup >/dev/null 2>&1; then
        nslookup google.com >/dev/null 2>&1 && return 0
    elif command -v ping >/dev/null 2>&1; then
        # Try ping with timeout (works on both macOS and Linux)
        ping -c 1 -W 2 8.8.8.8 >/dev/null 2>&1 && return 0
    fi

    return 1
}

# Check if a specific host is reachable
# Usage: check_host_reachability <hostname>
check_host_reachability() {
    local host="$1"

    if command -v host >/dev/null 2>&1; then
        host "$host" >/dev/null 2>&1 && return 0
    elif command -v nslookup >/dev/null 2>&1; then
        nslookup "$host" >/dev/null 2>&1 && return 0
    fi

    return 1
}

# Display offline mode error with helpful suggestions
show_offline_error() {
    local provider="$1"

    echo -e "${RED}Error: No internet connection detected${NC}" >&2
    echo "" >&2
    echo "Unable to reach $provider API. Possible causes:" >&2
    echo "  â€¢ No internet connection" >&2
    echo "  â€¢ Firewall blocking access" >&2
    echo "  â€¢ VPN or proxy issues" >&2
    echo "  â€¢ DNS resolution problems" >&2
    echo "" >&2
    echo "Suggestions:" >&2
    echo "  â€¢ Check your internet connection" >&2
    echo "  â€¢ Try: ping 8.8.8.8" >&2

    if [ "$provider" = "Ollama" ]; then
        echo "  â€¢ Ollama runs locally - check if it's running: ollama ps" >&2
    else
        echo "  â€¢ Use Ollama (local, no internet required):" >&2
        echo "    export AI_PROVIDER=ollama" >&2
        echo "    Install from: https://ollama.ai" >&2
    fi
}

# Validate that an API response contains expected content
# Usage: validate_api_response <response>
# Returns 0 if valid, 1 if invalid/incomplete
validate_api_response() {
    local response="$1"

    # Check if response is empty
    if [ -z "$response" ]; then
        return 1
    fi

    # Check if response is valid JSON (rough check)
    if ! echo "$response" | grep -q '{.*}'; then
        return 1
    fi

    return 0
}

# Enhanced error message for API key issues
show_api_key_error() {
    local provider="$1"
    local key_var="$2"

    echo -e "${RED}Error: $key_var is not set${NC}" >&2
    echo "" >&2
    echo "To use $provider, you need to set your API key:" >&2
    echo "  export $key_var=\"your-key-here\"" >&2
    echo "" >&2

    case "$provider" in
        "Anthropic")
            echo "Get your API key from: https://console.anthropic.com/settings/keys" >&2
            echo "Example: export ANTHROPIC_API_KEY=\"sk-ant-...\"" >&2
            ;;
        "OpenAI")
            echo "Get your API key from: https://platform.openai.com/api-keys" >&2
            echo "Example: export OPENAI_API_KEY=\"sk-proj-...\"" >&2
            ;;
        "Groq")
            echo "Get your API key from: https://console.groq.com/keys" >&2
            echo "Example: export GROQ_API_KEY=\"gsk_...\"" >&2
            ;;
    esac

    echo "" >&2
    echo "Alternative: Use Ollama (local, no API key needed):" >&2
    echo "  brew install ollama  # or download from https://ollama.ai" >&2
    echo "  ollama run gemma2:2b" >&2
    echo "  export AI_PROVIDER=ollama" >&2
}

# ============================================================================
# Retry Logic
# ============================================================================

# Retry wrapper with exponential backoff
# Usage: retry_with_backoff <attempt_num> <max_attempts> "<command>"
# Returns: 0 on success, 1 on failure after all retries
retry_api_call() {
    local url="$1"
    local data="$2"
    local output_file="$3"
    local error_file="$4"
    local provider_name="$5"
    shift 5
    # Remaining arguments are header options for curl (e.g., -H "Content-Type: application/json")
    local header_args=("$@")

    local attempt=1
    local delay="$RETRY_DELAY"

    while [ $attempt -le "$MAX_RETRIES" ]; do
        # Make the API call
        local exit_code=0
        curl -s -X POST "$url" \
            "${header_args[@]}" \
            -d "$data" \
            --connect-timeout "$CONNECT_TIMEOUT" \
            --max-time "$MAX_TIME" \
            -o "$output_file" 2>"$error_file" || exit_code=$?

        # Check if successful
        if [ $exit_code -eq 0 ] && [ -s "$output_file" ]; then
            # Check if response contains an error
            if ! grep -q '"error"' "$output_file" 2>/dev/null; then
                return 0  # Success!
            fi
        fi

        # If this was the last attempt, fail
        if [ $attempt -eq "$MAX_RETRIES" ]; then
            return 1
        fi

        # Determine error type for better messaging
        local error_msg=""
        case $exit_code in
            0)
                error_msg="API error (rate limit or invalid response)"
                ;;
            6)
                error_msg="Could not resolve host"
                ;;
            7)
                error_msg="Failed to connect"
                ;;
            28)
                error_msg="Timeout"
                ;;
            35)
                error_msg="SSL connection error"
                ;;
            52)
                error_msg="Empty response from server"
                ;;
            56)
                error_msg="Network error (receive failure)"
                ;;
            *)
                error_msg="Network error (code: $exit_code)"
                ;;
        esac

        # Show retry message
        echo -e "${YELLOW}âš  $error_msg - Retrying in ${delay}s (attempt $attempt/$MAX_RETRIES)${NC}" >&2

        # Wait with exponential backoff
        sleep $delay

        # Double the delay for next time (exponential backoff)
        delay=$((delay * 2))
        attempt=$((attempt + 1))
    done

    return 1  # All retries failed
}

# Auto-detect available AI providers and models
detect_available_providers() {
    local available=""

    # Check Anthropic (API key set)
    if [ -n "$ANTHROPIC_API_KEY" ]; then
        available="${available}anthropic "
    fi

    # Check OpenAI (API key set)
    if [ -n "$OPENAI_API_KEY" ]; then
        available="${available}openai "
    fi

    # Check Groq (API key set)
    if [ -n "$GROQ_API_KEY" ]; then
        available="${available}groq "
    fi

    # Check Ollama (running and has models)
    if curl -s --connect-timeout 1 "$OLLAMA_HOST/api/tags" >/dev/null 2>&1; then
        local models=$(curl -s "$OLLAMA_HOST/api/tags" 2>/dev/null | grep -o '"name":"[^"]*"' | sed 's/"name":"//;s/"//' | wc -l)
        if [ "$models" -gt 0 ]; then
            available="${available}ollama "
        fi
    fi

    echo "$available" | xargs  # Trim whitespace
}

# Get largest available Ollama model by parameter count
get_best_ollama_model() {
    # Use global cache (not repo-specific)
    local cache_file="/tmp/gh-commit-ai-ollama-model-cache"
    local cache_ttl=3600  # 1 hour

    # Check cache first
    if [ -f "$cache_file" ]; then
        local file_age=$(($(date +%s) - $(stat -f%m "$cache_file" 2>/dev/null || stat -c%Y "$cache_file" 2>/dev/null)))
        if [ "$file_age" -lt "$cache_ttl" ]; then
            cat "$cache_file"
            return
        fi
    fi

    # Query Ollama for available models
    local models=$(curl -s "$OLLAMA_HOST/api/tags" 2>/dev/null | grep -o '"name":"[^"]*"' | sed 's/"name":"//;s/"//')

    if [ -z "$models" ]; then
        echo ""
        return
    fi

    local largest_model=""
    local largest_size=0

    # Parse each model name and extract parameter size
    while IFS= read -r model; do
        # Extract size from model name (e.g., "70b", "32b", "7b", "1.5b")
        # Matches patterns like :70b, :32b, :7b, :1.5b, -70b, -32b, etc.
        local size=$(echo "$model" | grep -oE '[:_-]([0-9]+\.?[0-9]*)b' | grep -oE '[0-9]+\.?[0-9]*' | head -1)

        if [ -n "$size" ]; then
            # Convert to integer for comparison (multiply by 10 to handle decimals like 1.5b)
            local size_int=$(echo "$size * 10" | bc 2>/dev/null | cut -d. -f1)

            if [ -z "$size_int" ]; then
                # Fallback if bc not available
                size_int=$(printf "%.0f" "$(echo "$size * 10" | awk '{print $1 * $3}')")
            fi

            # Pick the largest model
            if [ "$size_int" -gt "$largest_size" ]; then
                largest_size="$size_int"
                largest_model="$model"
            fi
        fi
    done <<< "$models"

    # If we found a model with size, use it
    if [ -n "$largest_model" ]; then
        echo "$largest_model" | tee "$cache_file"
        return
    fi

    # Fallback: just return first model (for models without size in name)
    echo "$models" | head -1 | tee "$cache_file"
}

# Auto-select provider if set to "auto"
AUTO_DETECTED=false
if [ "$AI_PROVIDER" = "auto" ]; then
    # Detect what's available
    available_providers=$(detect_available_providers)

    if [ -z "$available_providers" ]; then
        echo -e "${RED}Error: No AI providers available${NC}"
        echo ""
        echo "Available options:"
        echo "  1. Install Ollama (free, local): https://ollama.ai"
        echo "     Then run: ollama pull qwen2.5-coder:7b"
        echo ""
        echo "  2. Set up Groq API (ultra-fast, generous free tier):"
        echo "     export GROQ_API_KEY=\"gsk-...\""
        echo "     Get your key from: https://console.groq.com/keys"
        echo ""
        echo "  3. Set up Anthropic API:"
        echo "     export ANTHROPIC_API_KEY=\"sk-ant-...\""
        echo ""
        echo "  4. Set up OpenAI API:"
        echo "     export OPENAI_API_KEY=\"sk-proj-...\""
        exit 1
    fi

    # Pick the best available provider (prefer local/free first, then fast/free APIs, then paid APIs)
    if echo "$available_providers" | grep -q "ollama"; then
        AI_PROVIDER="ollama"
        # Auto-select best Ollama model
        detected_model=$(get_best_ollama_model)
        if [ -n "$detected_model" ]; then
            OLLAMA_MODEL="$detected_model"
            AUTO_DETECTED=true
        fi
    elif echo "$available_providers" | grep -q "groq"; then
        AI_PROVIDER="groq"
        AUTO_DETECTED=true
    elif echo "$available_providers" | grep -q "anthropic"; then
        AI_PROVIDER="anthropic"
        AUTO_DETECTED=true
    elif echo "$available_providers" | grep -q "openai"; then
        AI_PROVIDER="openai"
        AUTO_DETECTED=true
    fi
fi

# Generate changelog from commit history
generate_changelog() {
    local since_ref="$1"
    local format="$2"

    # Build git log command
    local log_cmd="git log --pretty=format:'%H|%s|%b' --no-merges"
    if [ -n "$since_ref" ]; then
        # Check if the reference exists
        if ! git rev-parse "$since_ref" >/dev/null 2>&1; then
            echo -e "${RED}Error: Reference '$since_ref' not found"
            exit 1
        fi
        log_cmd="$log_cmd ${since_ref}..HEAD"
    fi

    # Get commits
    local commits=$(eval "$log_cmd")

    if [ -z "$commits" ]; then
        echo "No commits found"
        exit 0
    fi

    # Initialize arrays for different types
    local breaking_changes=()
    local features=()
    local fixes=()
    local docs=()
    local style=()
    local refactor=()
    local performance=()
    local tests=()
    local chores=()
    local other=()

    # Parse commits
    while IFS='|' read -r hash subject body; do
        # Parse conventional commit format
        local type=""
        local scope=""
        local description=""
        local is_breaking=false

        # Check for breaking change indicator
        if [[ "$subject" =~ ^([a-z]+)(\([a-z0-9_-]+\))?!:\ (.+)$ ]]; then
            type="${BASH_REMATCH[1]}"
            scope="${BASH_REMATCH[2]}"
            description="${BASH_REMATCH[3]}"
            is_breaking=true
        elif [[ "$subject" =~ ^([a-z]+)(\([a-z0-9_-]+\))?:\ (.+)$ ]]; then
            type="${BASH_REMATCH[1]}"
            scope="${BASH_REMATCH[2]}"
            description="${BASH_REMATCH[3]}"
        else
            # Not a conventional commit, skip or put in other
            type="other"
            description="$subject"
        fi

        # Remove parentheses from scope
        scope="${scope#(}"
        scope="${scope%)}"

        # Check body for BREAKING CHANGE
        if echo "$body" | grep -qiE '^BREAKING CHANGE:'; then
            is_breaking=true
        fi

        # Format entry
        local entry="- $description"
        if [ -n "$scope" ]; then
            entry="- **$scope**: $description"
        fi
        entry="$entry ([${hash:0:7}](../../commit/$hash))"

        # Categorize by type
        if [ "$is_breaking" = true ]; then
            breaking_changes+=("$entry")
        fi

        case "$type" in
            feat|feature)
                features+=("$entry")
                ;;
            fix)
                fixes+=("$entry")
                ;;
            docs)
                docs+=("$entry")
                ;;
            style)
                style+=("$entry")
                ;;
            refactor)
                refactor+=("$entry")
                ;;
            perf|performance)
                performance+=("$entry")
                ;;
            test|tests)
                tests+=("$entry")
                ;;
            chore|build|ci)
                chores+=("$entry")
                ;;
            *)
                other+=("$entry")
                ;;
        esac
    done <<< "$commits"

    # Generate changelog based on format
    echo ""
    echo "# Changelog"
    echo ""

    # Determine version header
    local version_header="Unreleased"
    if [ -n "$since_ref" ]; then
        # Try to get the next version from the since ref
        local current_version="$since_ref"
        version_header="[${current_version#v}...HEAD]"
    fi

    echo "## $version_header"
    echo ""
    echo "### Date: $(date +%Y-%m-%d)"
    echo ""

    # Breaking changes first (most important)
    if [ ${#breaking_changes[@]} -gt 0 ]; then
        echo "### âš ï¸ BREAKING CHANGES"
        echo ""
        for entry in "${breaking_changes[@]}"; do
            echo "$entry"
        done
        echo ""
    fi

    # Features
    if [ ${#features[@]} -gt 0 ]; then
        echo "### âœ¨ Features"
        echo ""
        for entry in "${features[@]}"; do
            echo "$entry"
        done
        echo ""
    fi

    # Bug fixes
    if [ ${#fixes[@]} -gt 0 ]; then
        echo "### ðŸ› Bug Fixes"
        echo ""
        for entry in "${fixes[@]}"; do
            echo "$entry"
        done
        echo ""
    fi

    # Documentation
    if [ ${#docs[@]} -gt 0 ]; then
        echo "### ðŸ“ Documentation"
        echo ""
        for entry in "${docs[@]}"; do
            echo "$entry"
        done
        echo ""
    fi

    # Performance improvements
    if [ ${#performance[@]} -gt 0 ]; then
        echo "### âš¡ Performance"
        echo ""
        for entry in "${performance[@]}"; do
            echo "$entry"
        done
        echo ""
    fi

    # Refactoring
    if [ ${#refactor[@]} -gt 0 ]; then
        echo "### â™»ï¸ Refactoring"
        echo ""
        for entry in "${refactor[@]}"; do
            echo "$entry"
        done
        echo ""
    fi

    # Tests
    if [ ${#tests[@]} -gt 0 ]; then
        echo "### âœ… Tests"
        echo ""
        for entry in "${tests[@]}"; do
            echo "$entry"
        done
        echo ""
    fi

    # Style changes
    if [ ${#style[@]} -gt 0 ]; then
        echo "### ðŸ’„ Style"
        echo ""
        for entry in "${style[@]}"; do
            echo "$entry"
        done
        echo ""
    fi

    # Chores
    if [ ${#chores[@]} -gt 0 ]; then
        echo "### ðŸ”§ Chores"
        echo ""
        for entry in "${chores[@]}"; do
            echo "$entry"
        done
        echo ""
    fi

    # Other
    if [ ${#other[@]} -gt 0 ]; then
        echo "### Other Changes"
        echo ""
        for entry in "${other[@]}"; do
            echo "$entry"
        done
        echo ""
    fi
}

# Suggest next semantic version based on commits
suggest_next_version() {
    local create_tag="$1"
    local tag_prefix="$2"

    # Check if we're in a git repository
    if ! git rev-parse --git-dir > /dev/null 2>&1; then
        echo -e "${RED}Error: Not a git repository${NC}" >&2
        exit 1
    fi

    # Get the last tag
    local last_tag=$(git describe --tags --abbrev=0 2>/dev/null)

    if [ -z "$last_tag" ]; then
        echo -e "${YELLOW}No tags found in repository${NC}"
        echo ""
        echo "Suggested first version: ${GREEN}${tag_prefix}0.1.0${NC}"
        echo ""
        echo "Reasoning:"
        echo "  â€¢ No previous tags exist"
        echo "  â€¢ Starting with 0.1.0 (pre-release version)"
        echo "  â€¢ Use 1.0.0 when ready for first stable release"
        echo ""

        if [ "$create_tag" = true ]; then
            echo -n "Create tag ${tag_prefix}0.1.0? (y/n): "
            read -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                git tag -a "${tag_prefix}0.1.0" -m "Release ${tag_prefix}0.1.0"
                echo -e "${GREEN}âœ“ Tag ${tag_prefix}0.1.0 created${NC}"
                echo "Push with: git push origin ${tag_prefix}0.1.0"
            else
                echo "Tag creation cancelled"
            fi
        fi
        return 0
    fi

    # Parse the current version
    local current_version="${last_tag#$tag_prefix}"  # Remove prefix

    # Extract major, minor, patch
    if [[ ! "$current_version" =~ ^([0-9]+)\.([0-9]+)\.([0-9]+) ]]; then
        echo -e "${RED}Error: Cannot parse version from tag: $last_tag${NC}" >&2
        echo "Expected format: ${tag_prefix}X.Y.Z (e.g., v1.2.3)" >&2
        exit 1
    fi

    local major="${BASH_REMATCH[1]}"
    local minor="${BASH_REMATCH[2]}"
    local patch="${BASH_REMATCH[3]}"

    echo -e "${BLUE}Current version: ${NC}${last_tag}"
    echo ""

    # Get commits since last tag
    local commits=$(git log "$last_tag..HEAD" --pretty=format:"%s" 2>/dev/null)

    if [ -z "$commits" ]; then
        echo -e "${YELLOW}No new commits since ${last_tag}${NC}"
        echo ""
        echo "Next version would be: ${GREEN}${tag_prefix}${major}.${minor}.${patch}${NC} (no change)"
        return 0
    fi

    # Count commit types
    local breaking_count=0
    local feat_count=0
    local fix_count=0
    local other_count=0

    # Analyze each commit
    while IFS= read -r commit_msg; do
        # Check for breaking changes (! after type or BREAKING CHANGE in message)
        if [[ "$commit_msg" =~ ^[a-z]+(\([a-z0-9_-]+\))?!: ]] || [[ "$commit_msg" =~ BREAKING[[:space:]]CHANGE ]]; then
            ((breaking_count++))
        # Check for features
        elif [[ "$commit_msg" =~ ^feat(\([a-z0-9_-]+\))?: ]]; then
            ((feat_count++))
        # Check for fixes
        elif [[ "$commit_msg" =~ ^fix(\([a-z0-9_-]+\))?: ]]; then
            ((fix_count++))
        else
            ((other_count++))
        fi
    done <<< "$commits"

    # Determine version bump
    local bump_type=""
    local new_major=$major
    local new_minor=$minor
    local new_patch=$patch

    if [ $breaking_count -gt 0 ]; then
        # Breaking changes â†’ Major bump
        bump_type="major"
        ((new_major++))
        new_minor=0
        new_patch=0
    elif [ $feat_count -gt 0 ]; then
        # New features â†’ Minor bump
        bump_type="minor"
        ((new_minor++))
        new_patch=0
    elif [ $fix_count -gt 0 ]; then
        # Bug fixes â†’ Patch bump
        bump_type="patch"
        ((new_patch++))
    else
        # Only other commits (docs, chore, etc.) â†’ Patch bump
        bump_type="patch"
        ((new_patch++))
    fi

    local suggested_version="${tag_prefix}${new_major}.${new_minor}.${new_patch}"

    # Display analysis
    echo -e "${GREEN}Suggested version: ${suggested_version}${NC} (${bump_type} bump)"
    echo ""
    echo "Analysis of $(echo "$commits" | wc -l | tr -d ' ') commits since ${last_tag}:"
    [ $breaking_count -gt 0 ] && echo "  â€¢ ${breaking_count} breaking change(s) â†’ Major bump required"
    [ $feat_count -gt 0 ] && echo "  â€¢ ${feat_count} new feature(s)"
    [ $fix_count -gt 0 ] && echo "  â€¢ ${fix_count} bug fix(es)"
    [ $other_count -gt 0 ] && echo "  â€¢ ${other_count} other commit(s) (docs, chore, etc.)"
    echo ""

    # Show reasoning
    echo "Reasoning:"
    if [ $breaking_count -gt 0 ]; then
        echo "  â€¢ Breaking changes detected â†’ MAJOR bump"
        echo "  â€¢ Bumping from ${major}.${minor}.${patch} to ${new_major}.${new_minor}.${new_patch}"
    elif [ $feat_count -gt 0 ]; then
        echo "  â€¢ New features added (no breaking changes) â†’ MINOR bump"
        echo "  â€¢ Bumping from ${major}.${minor}.${patch} to ${new_major}.${new_minor}.${new_patch}"
    else
        echo "  â€¢ Only fixes and other changes â†’ PATCH bump"
        echo "  â€¢ Bumping from ${major}.${minor}.${patch} to ${new_major}.${new_minor}.${new_patch}"
    fi
    echo ""

    # Create tag if requested
    if [ "$create_tag" = true ]; then
        echo -n "Create tag ${suggested_version}? (y/n): "
        read -n 1 -r
        echo
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            # Generate tag message from commit summary
            local tag_message="Release ${suggested_version}"
            if [ $breaking_count -gt 0 ]; then
                tag_message="${tag_message}\n\nBreaking Changes: ${breaking_count}"
            fi
            if [ $feat_count -gt 0 ]; then
                tag_message="${tag_message}\nNew Features: ${feat_count}"
            fi
            if [ $fix_count -gt 0 ]; then
                tag_message="${tag_message}\nBug Fixes: ${fix_count}"
            fi

            git tag -a "${suggested_version}" -m "$(echo -e "$tag_message")"
            echo -e "${GREEN}âœ“ Tag ${suggested_version} created${NC}"
            echo ""
            echo "Next steps:"
            echo "  git push origin ${suggested_version}     # Push the tag"
            echo "  git push                                 # Push commits"
        else
            echo "Tag creation cancelled"
        fi
    else
        echo "To create this tag:"
        echo "  git tag -a ${suggested_version} -m \"Release ${suggested_version}\""
        echo "  git push origin ${suggested_version}"
    fi
}

# Suggest commit splits for large changes
suggest_commit_splits() {
    local threshold="$1"
    local dry_run="$2"

    # Check if we're in a git repository
    GIT_DIR=$(git rev-parse --git-dir 2>/dev/null)
    if [ -z "$GIT_DIR" ]; then
        echo -e "${RED}Error: Not a git repository${NC}" >&2
        exit 1
    fi

    echo -e "${BLUE}â† Analyzing staged changes${NC}" >&2

    # Get staged changes
    local diff_content
    diff_content=$(git diff --cached)

    if [ -z "$diff_content" ]; then
        echo -e "${RED}Error: No staged changes to analyze${NC}" >&2
        echo "Tip: Stage your changes with 'git add' first" >&2
        exit 1
    fi

    # Count total lines changed
    local stats
    stats=$(git diff --cached --numstat)
    local total_lines=0
    while IFS=$'\t' read -r added removed file; do
        if [[ "$added" =~ ^[0-9]+$ ]] && [[ "$removed" =~ ^[0-9]+$ ]]; then
            total_lines=$((total_lines + added + removed))
        fi
    done <<< "$stats"

    echo -e "âœ“ Analyzed $total_lines lines across $(echo "$stats" | wc -l | tr -d ' ') files"

    # Check if changes exceed threshold
    if [ $total_lines -lt $threshold ]; then
        echo -e "${GREEN}âœ“ Changes are below threshold ($total_lines < $threshold lines)${NC}"
        echo "Your commit is a reasonable size. No split needed!"
        exit 0
    fi

    echo -e "${YELLOW}âš  Large commit detected: $total_lines lines (threshold: $threshold)${NC}"
    echo ""

    # Get file list with stats for AI analysis
    local file_summary=""
    while IFS=$'\t' read -r added removed file; do
        if [[ "$added" =~ ^[0-9]+$ ]] && [[ "$removed" =~ ^[0-9]+$ ]]; then
            file_summary="${file_summary}${file}: +${added} -${removed}\n"
        fi
    done <<< "$stats"

    # Sample the diff intelligently (use existing smart_sample_diff function)
    local sampled_diff
    sampled_diff=$(smart_sample_diff "$diff_content" 500)

    # Create prompt for AI
    local prompt="Analyze this large git commit and suggest how to split it into logical, smaller commits.

COMMIT SIZE: $total_lines lines changed

FILES CHANGED:
$file_summary

DIFF SAMPLE (first 500 lines):
$sampled_diff

Please suggest 2-4 logical ways to split this commit. For each suggested commit, provide:
1. A brief description of what it contains
2. The list of files that should be included
3. Why these changes belong together

Format your response as:

## Split Suggestion 1: [Description]
**Files:**
- file1.ext
- file2.ext

**Rationale:** [Why these changes belong together]

## Split Suggestion 2: [Description]
...

Focus on:
- Grouping related functionality together
- Separating different concerns (e.g., tests from implementation, docs from code)
- Creating commits that are independently reviewable
- Maintaining logical dependencies (e.g., don't split a function from its tests)

Be specific and practical."

    # Call AI to get split suggestions
    echo -e "${BLUE}â† Thinking (analyzing commit structure)${NC}" >&2

    local suggestions
    suggestions=$(call_ai_for_split "$prompt")

    if [ -z "$suggestions" ]; then
        echo -e "${RED}Error: Failed to generate split suggestions${NC}" >&2
        exit 1
    fi

    # Display suggestions
    echo ""
    echo -e "${GREEN}â•â•â• Split Suggestions â•â•â•${NC}"
    echo ""
    echo "$suggestions"
    echo ""
    echo -e "${GREEN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""

    # Interactive mode (if not dry-run)
    if [ "$dry_run" = "false" ]; then
        echo -e "${YELLOW}Note: Applying splits will require manual file staging.${NC}"
        echo "The suggestions above show logical groupings."
        echo ""
        echo "To apply these splits:"
        echo "  1. Reset staged changes: git reset"
        echo "  2. Stage files for first commit: git add file1 file2..."
        echo "  3. Commit: git commit -m \"message\""
        echo "  4. Repeat for each split"
        echo ""
        echo "Or use: gh commit-ai (to generate commit messages)"
    fi
}

# Helper function to call AI for split suggestions
call_ai_for_split() {
    local prompt="$1"

    # Detect and use available AI provider
    if [ "$AI_PROVIDER" = "auto" ]; then
        detect_available_providers > /dev/null
    fi

    # Route to appropriate provider
    case "$AI_PROVIDER" in
        ollama)
            call_ollama "$prompt"
            ;;
        anthropic)
            call_anthropic "$prompt"
            ;;
        openai)
            call_openai "$prompt"
            ;;
        groq)
            call_groq "$prompt"
            ;;
        *)
            echo -e "${RED}Error: Unknown AI provider: $AI_PROVIDER${NC}" >&2
            exit 1
            ;;
    esac
}

# Generate code review for changes
generate_code_review() {
    local review_all="$1"  # true = all changes, false = staged only

    # Check if we're in a git repository
    GIT_DIR=$(git rev-parse --git-dir 2>/dev/null)
    if [ -z "$GIT_DIR" ]; then
        echo -e "${RED}Error: Not a git repository${NC}" >&2
        exit 1
    fi

    echo -e "${BLUE}â† Analyzing changes${NC}" >&2

    # Get the diff to review (exclude lock files)
    local diff_content
    if [ "$review_all" = false ]; then
        # Staged changes only
        diff_content=$(eval "git diff --cached $GIT_EXCLUDE_PATTERN")
        if [ -z "$diff_content" ]; then
            echo -e "${RED}Error: No staged changes to review${NC}" >&2
            echo "Tip: Stage your changes with 'git add' or use --all to review all changes" >&2
            exit 1
        fi
    else
        # All changes (staged + unstaged)
        diff_content=$(eval "git diff HEAD $GIT_EXCLUDE_PATTERN")
        if [ -z "$diff_content" ]; then
            echo -e "${RED}Error: No changes to review${NC}" >&2
            exit 1
        fi
    fi

    # Apply smart sampling if diff is too large
    diff_content=$(smart_sample_diff "$diff_content" "$DIFF_MAX_LINES")

    # Get file statistics (exclude lock files)
    local file_stats
    if [ "$review_all" = false ]; then
        file_stats=$(eval "git diff --cached --stat $GIT_EXCLUDE_PATTERN")
    else
        file_stats=$(eval "git diff HEAD --stat $GIT_EXCLUDE_PATTERN")
    fi

    echo -e "${BLUE}âœ“ Changes analyzed${NC}" >&2

    # Build the review prompt
    local review_prompt="You are an expert code reviewer. Analyze the following code changes and provide a comprehensive code review.

Focus on identifying:
1. **Security Issues**: SQL injection, XSS, CSRF, insecure dependencies, exposed secrets, etc.
2. **Performance Concerns**: Inefficient algorithms, unnecessary loops, memory leaks, blocking operations
3. **Code Quality**: Violations of best practices, poor naming, duplicated code, overly complex logic
4. **Error Handling**: Missing try-catch blocks, unhandled errors, improper error propagation
5. **Potential Bugs**: Logic errors, edge cases, null/undefined handling, race conditions
6. **Maintainability**: TODO/FIXME comments, magic numbers, lack of documentation, tight coupling

For each issue found:
- Use a severity marker: ðŸ”´ Critical, ðŸŸ¡ Warning, ðŸ”µ Info
- Specify the file and line number
- Explain the issue clearly
- Suggest a fix or improvement

If no significant issues are found, provide a brief positive review.

Format your review as:
## Code Review Summary
[Brief overall assessment]

## Issues Found
[List each issue with severity, location, description, and suggestion]

## Recommendations
[General recommendations for improvement]

File changes:
\`\`\`
$file_stats
\`\`\`

Code diff:
\`\`\`diff
$diff_content
\`\`\`

Provide your review:"

    echo "" >&2

    # Use dedicated code review models if configured, otherwise fall back to regular models
    local original_ollama_model="$OLLAMA_MODEL"
    local original_anthropic_model="$ANTHROPIC_MODEL"
    local original_openai_model="$OPENAI_MODEL"
    local original_groq_model="$GROQ_MODEL"
    local using_dedicated_model=false

    if [ "$AI_PROVIDER" = "ollama" ] && [ -n "$CODE_REVIEW_MODEL" ]; then
        OLLAMA_MODEL="$CODE_REVIEW_MODEL"
        using_dedicated_model=true
        echo -e "${BLUE}Using dedicated review model: $OLLAMA_MODEL${NC}" >&2
    elif [ "$AI_PROVIDER" = "anthropic" ] && [ -n "$CODE_REVIEW_ANTHROPIC_MODEL" ]; then
        ANTHROPIC_MODEL="$CODE_REVIEW_ANTHROPIC_MODEL"
        using_dedicated_model=true
        echo -e "${BLUE}Using dedicated review model: $ANTHROPIC_MODEL${NC}" >&2
    elif [ "$AI_PROVIDER" = "openai" ] && [ -n "$CODE_REVIEW_OPENAI_MODEL" ]; then
        OPENAI_MODEL="$CODE_REVIEW_OPENAI_MODEL"
        using_dedicated_model=true
        echo -e "${BLUE}Using dedicated review model: $OPENAI_MODEL${NC}" >&2
    elif [ "$AI_PROVIDER" = "groq" ] && [ -n "$CODE_REVIEW_GROQ_MODEL" ]; then
        GROQ_MODEL="$CODE_REVIEW_GROQ_MODEL"
        using_dedicated_model=true
        echo -e "${BLUE}Using dedicated review model: $GROQ_MODEL${NC}" >&2
    else
        # Using regular model - show which one and potentially recommend a better model
        local current_model
        case "$AI_PROVIDER" in
            ollama)
                current_model="$OLLAMA_MODEL"
                echo -e "${BLUE}Using $AI_PROVIDER model: $current_model${NC}" >&2

                # Recommend better models for code review if using a small/weak model
                if [[ "$current_model" =~ (gemma2:2b|gemma3:4b|llama3.2:1b|llama3.2:3b|phi3:mini) ]]; then
                    echo -e "${YELLOW}ðŸ’¡ Tip: For better code reviews, consider using a larger model:${NC}" >&2
                    echo -e "${YELLOW}   CODE_REVIEW_MODEL=\"qwen2.5-coder:14b\" or \"deepseek-coder:6.7b\"${NC}" >&2
                    echo -e "${YELLOW}   Or add to .gh-commit-ai.yml: code_review_model: qwen2.5-coder:14b${NC}" >&2
                    echo "" >&2
                fi
                ;;
            anthropic)
                current_model="$ANTHROPIC_MODEL"
                echo -e "${BLUE}Using $AI_PROVIDER model: $current_model${NC}" >&2

                # Recommend Opus or Sonnet for code review if using Haiku
                if [[ "$current_model" =~ haiku ]]; then
                    echo -e "${YELLOW}ðŸ’¡ Tip: For more thorough code reviews, consider using Claude Sonnet or Opus${NC}" >&2
                    echo -e "${YELLOW}   CODE_REVIEW_ANTHROPIC_MODEL=\"claude-3-5-sonnet-20241022\"${NC}" >&2
                    echo "" >&2
                fi
                ;;
            openai)
                current_model="$OPENAI_MODEL"
                echo -e "${BLUE}Using $AI_PROVIDER model: $current_model${NC}" >&2

                # Recommend GPT-4o for code review if using mini
                if [[ "$current_model" =~ mini ]]; then
                    echo -e "${YELLOW}ðŸ’¡ Tip: For more thorough code reviews, consider using GPT-4o${NC}" >&2
                    echo -e "${YELLOW}   CODE_REVIEW_OPENAI_MODEL=\"gpt-4o\"${NC}" >&2
                    echo "" >&2
                fi
                ;;
            groq)
                current_model="$GROQ_MODEL"
                echo -e "${BLUE}Using $AI_PROVIDER model: $current_model${NC}" >&2

                # Recommend larger models for code review if using smaller models
                if [[ "$current_model" =~ (llama-3.1-8b|gemma2-9b|mixtral-8x7b) ]]; then
                    echo -e "${YELLOW}ðŸ’¡ Tip: For more thorough code reviews, consider using llama-3.3-70b-versatile${NC}" >&2
                    echo -e "${YELLOW}   CODE_REVIEW_GROQ_MODEL=\"llama-3.3-70b-versatile\"${NC}" >&2
                    echo "" >&2
                fi
                ;;
        esac
    fi

    # Call AI provider for review
    local review_result
    case "$AI_PROVIDER" in
        ollama)
            review_result=$(call_ollama "$review_prompt")
            ;;
        anthropic)
            review_result=$(call_anthropic "$review_prompt")
            ;;
        openai)
            review_result=$(call_openai "$review_prompt")
            ;;
        groq)
            review_result=$(call_groq "$review_prompt")
            ;;
        *)
            echo -e "${RED}Error: Unknown AI provider: $AI_PROVIDER${NC}" >&2
            exit 1
            ;;
    esac

    # Restore original models
    OLLAMA_MODEL="$original_ollama_model"
    ANTHROPIC_MODEL="$original_anthropic_model"
    OPENAI_MODEL="$original_openai_model"
    GROQ_MODEL="$original_groq_model"

    if [ -z "$review_result" ]; then
        echo -e "${RED}Error: Failed to generate code review${NC}" >&2
        exit 1
    fi

    # Display the review
    echo ""
    echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo -e "${GREEN}âœ“ Code Review Complete${NC}"
    echo -e "${GREEN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
    echo ""
    echo "$review_result"
    echo ""

    # Show cost information for paid APIs
    if [ "$AI_PROVIDER" = "anthropic" ] || [ "$AI_PROVIDER" = "openai" ]; then
        if [ -n "$INPUT_TOKENS" ] && [ -n "$OUTPUT_TOKENS" ]; then
            local total_tokens=$((INPUT_TOKENS + OUTPUT_TOKENS))
            echo -e "${BLUE}Token usage:${NC} $total_tokens tokens ($INPUT_TOKENS input + $OUTPUT_TOKENS output)"

            # Calculate and display cost
            local model
            if [ "$AI_PROVIDER" = "anthropic" ]; then
                model="$ANTHROPIC_MODEL"
            else
                model="$OPENAI_MODEL"
            fi

            local cost=$(calculate_cost "$AI_PROVIDER" "$model" "$INPUT_TOKENS" "$OUTPUT_TOKENS")
            if [ -n "$cost" ]; then
                echo -e "${BLUE}Estimated cost:${NC} \$$cost USD"

                # Track cumulative cost
                local total_cost=$(track_cumulative_cost "$cost")
                if [ -n "$total_cost" ]; then
                    echo -e "${BLUE}Today's total:${NC} \$$total_cost USD"
                fi
            fi
            echo ""
        fi
    fi
}

# Generate PR description from commits
generate_pr_description() {
    local base_branch="$1"
    local output_file="$2"

    # Check if we're in a git repository
    if ! git rev-parse --git-dir > /dev/null 2>&1; then
        echo -e "${RED}Error: Not a git repository${NC}" >&2
        exit 1
    fi

    # Get current branch
    local current_branch=$(git branch --show-current)
    if [ -z "$current_branch" ]; then
        echo -e "${RED}Error: Not on a branch (detached HEAD)${NC}" >&2
        exit 1
    fi

    # Auto-detect base branch if not provided
    if [ -z "$base_branch" ]; then
        # Try common base branches
        for candidate in main master develop development; do
            if git show-ref --verify --quiet refs/heads/$candidate; then
                base_branch=$candidate
                break
            fi
        done

        if [ -z "$base_branch" ]; then
            echo -e "${RED}Error: Could not auto-detect base branch${NC}" >&2
            echo "Please specify with --base <branch>" >&2
            exit 1
        fi
    fi

    # Verify base branch exists
    if ! git show-ref --verify --quiet refs/heads/$base_branch; then
        echo -e "${RED}Error: Base branch '$base_branch' does not exist${NC}" >&2
        exit 1
    fi

    # Get merge base (where branch diverged)
    local merge_base=$(git merge-base $base_branch HEAD 2>/dev/null)
    if [ -z "$merge_base" ]; then
        echo -e "${RED}Error: Could not find common ancestor with $base_branch${NC}" >&2
        exit 1
    fi

    # Get commits since divergence
    local commits=$(git log --pretty=format:"%H|%s|%b" ${merge_base}..HEAD)
    if [ -z "$commits" ]; then
        echo -e "${RED}Error: No commits found since divergence from $base_branch${NC}" >&2
        exit 1
    fi

    # Count commits
    local num_commits=$(echo "$commits" | wc -l | tr -d ' ')

    # Get overall diff stats
    local diff_stats=$(git diff --stat ${merge_base}..HEAD)

    # Get file changes summary
    local files_changed=$(git diff --name-status ${merge_base}..HEAD)

    # Build commit summary (for AI)
    local commit_summary=""
    while IFS='|' read -r hash subject body; do
        commit_summary="${commit_summary}
- ${subject}"
        if [ -n "$body" ]; then
            # Include first line of body if it exists
            local first_line=$(echo "$body" | head -1 | sed 's/^[[:space:]]*//')
            if [ -n "$first_line" ]; then
                commit_summary="${commit_summary}
  ${first_line}"
            fi
        fi
    done <<< "$commits"

    # Create prompt for AI
    local pr_prompt="Generate a comprehensive Pull Request description based on the commits and changes below.

Branch: $current_branch
Base branch: $base_branch
Number of commits: $num_commits

Commits:
$commit_summary

Diff stats:
$diff_stats

FILES CHANGED:
$files_changed

Generate a PR description with the following sections:

## Summary
A 2-3 sentence overview of what this PR accomplishes.

## Changes
- Detailed bullet points of key changes
- Organized by category if applicable (features, fixes, refactoring, etc.)

## Testing
- How to test these changes
- What scenarios to verify

FORMAT:
- Use markdown
- Be concise but comprehensive
- Focus on WHAT changed and WHY, not HOW
- Highlight any breaking changes
- Output ONLY the PR description, NO explanations"

    # Show progress
    echo "â†’ Analyzing $num_commits commits on branch: $current_branch" >&2
    echo "â†’ Comparing against: $base_branch" >&2
    echo "" >&2

    # Call AI to generate PR description
    local pr_description=""
    case "$AI_PROVIDER" in
        ollama)
            pr_description=$(call_ollama "$pr_prompt")
            ;;
        anthropic)
            pr_description=$(call_anthropic "$pr_prompt")
            ;;
        openai)
            pr_description=$(call_openai "$pr_prompt")
            ;;
        groq)
            pr_description=$(call_groq "$pr_prompt")
            ;;
        *)
            echo -e "${RED}Error: Unknown AI provider '$AI_PROVIDER'${NC}" >&2
            exit 1
            ;;
    esac

    # Strip any markdown fences
    pr_description=$(echo "$pr_description" | awk '
        /^```[a-zA-Z]*$/ { next }
        /^```$/ { next }
        /^\*\*explanation/ { exit }
        /^\*\*why/ { exit }
        /^\*\*note/ { exit }
        { print }
    ')

    # Output result
    if [ -n "$output_file" ]; then
        echo "$pr_description" > "$output_file"
        echo "âœ“ PR description saved to: $output_file" >&2
    else
        echo "$pr_description"
    fi
}

# Parse command-line arguments
DRY_RUN=false
PREVIEW=false
AMEND=false
MULTIPLE_OPTIONS=false
CHANGELOG_MODE=false
CHANGELOG_SINCE=""
CHANGELOG_FORMAT="keepachangelog"
VERBOSE=false
FORCED_TYPE=""
CUSTOM_MAX_LINES=""
NO_LOWERCASE=false

### Message history directory (will be set per-repository)
MESSAGE_HISTORY_DIR=""

# Save message to history (keeps last 5)
save_message_history() {
    local message="$1"
    local timestamp=$(date +%s)
    local history_file="$MESSAGE_HISTORY_DIR/msg_${timestamp}.txt"

    # Save the message
    echo "$message" > "$history_file"

    # Keep only the last 5 messages
    ls -t "$MESSAGE_HISTORY_DIR"/msg_*.txt 2>/dev/null | tail -n +6 | xargs rm -f 2>/dev/null || true
}

# Get last message from history
get_last_message() {
    local last_file=$(ls -t "$MESSAGE_HISTORY_DIR"/msg_*.txt 2>/dev/null | head -1)
    if [ -n "$last_file" ] && [ -f "$last_file" ]; then
        cat "$last_file"
    fi
}

# Check if last message is recent (within 5 minutes)
is_recent_message() {
    local last_file=$(ls -t "$MESSAGE_HISTORY_DIR"/msg_*.txt 2>/dev/null | head -1)
    if [ -z "$last_file" ] || [ ! -f "$last_file" ]; then
        return 1
    fi

    # Extract timestamp from filename (msg_TIMESTAMP.txt)
    local file_timestamp=$(basename "$last_file" | sed 's/msg_//;s/.txt//')
    local current_time=$(date +%s)
    local age=$((current_time - file_timestamp))

    # Recent if less than 5 minutes old (300 seconds)
    if [ "$age" -lt 300 ]; then
        return 0
    else
        return 1
    fi
}

# Clear message history (called after successful commit)
clear_message_history() {
    rm -f "$MESSAGE_HISTORY_DIR"/msg_*.txt 2>/dev/null || true
}

# ============================================================================
# API RESPONSE CACHING (Performance optimization)
# ============================================================================

# Generate cache key from diff content (reads from stdin)
get_diff_hash() {
    # Create hash of diff content for cache key (from stdin)
    if command -v md5sum &> /dev/null; then
        md5sum | awk '{print $1}'
    elif command -v md5 &> /dev/null; then
        md5
    else
        # Fallback: use first 32 chars of diff (not ideal but better than nothing)
        head -c 32 | sed 's/[^a-zA-Z0-9]//g'
    fi
}

# Get cached AI response if available and not expired
get_cached_response() {
    local cache_key="$1"
    local cache_file="${CACHE_DIR}/${cache_key}.txt"

    # Check if cache is disabled
    if [ "$DISABLE_CACHE" = "true" ]; then
        return 1
    fi

    # Check if cache file exists
    if [ ! -f "$cache_file" ]; then
        return 1
    fi

    # Check cache age (default: 24 hours = 86400 seconds)
    local cache_max_age="${CACHE_MAX_AGE:-86400}"
    local current_time=$(date +%s)
    local file_time=0

    # Get file modification time (BSD/macOS vs GNU/Linux compatible)
    if stat -f %m "$cache_file" &>/dev/null; then
        file_time=$(stat -f %m "$cache_file" 2>/dev/null || echo 0)
    else
        file_time=$(stat -c %Y "$cache_file" 2>/dev/null || echo 0)
    fi

    local file_age=$((current_time - file_time))

    if [ "$file_age" -gt "$cache_max_age" ]; then
        # Cache expired
        rm -f "$cache_file" 2>/dev/null || true
        return 1
    fi

    # Return cached content
    cat "$cache_file"
    return 0
}

# Save AI response to cache
save_cached_response() {
    local cache_key="$1"
    local response="$2"
    local cache_file="${CACHE_DIR}/${cache_key}.txt"

    # Don't cache if disabled
    if [ "$DISABLE_CACHE" = "true" ]; then
        return
    fi

    # Save response
    echo "$response" > "$cache_file"

    # Clean up old cache entries (keep last 100)
    ls -t "$CACHE_DIR"/*.txt 2>/dev/null | tail -n +101 | xargs rm -f 2>/dev/null || true
}

# Clear expired cache entries (called periodically during save)
clear_expired_cache() {
    local cache_max_age="${CACHE_MAX_AGE:-86400}"
    local current_time=$(date +%s)

    # Find and remove expired cache files (use ls for better compatibility)
    for file in "$CACHE_DIR"/*.txt; do
        [ -f "$file" ] 2>/dev/null || continue

        local file_time=0
        if stat -f %m "$file" &>/dev/null; then
            file_time=$(stat -f %m "$file" 2>/dev/null || echo 0)
        else
            file_time=$(stat -c %Y "$file" 2>/dev/null || echo 0)
        fi

        local age=$((current_time - file_time))
        if [ "$age" -gt "$cache_max_age" ]; then
            rm -f "$file" 2>/dev/null || true
        fi
    done
}

# Check for subcommands
if [ "$1" = "changelog" ]; then
    CHANGELOG_MODE=true
    shift

    # Parse changelog-specific flags
    while [[ $# -gt 0 ]]; do
        case $1 in
            --since)
                CHANGELOG_SINCE="$2"
                shift 2
                ;;
            --format)
                CHANGELOG_FORMAT="$2"
                shift 2
                ;;
            --help|-h)
                echo "gh-commit-ai changelog - Generate changelog from commit history"
                echo ""
                echo "Usage: gh commit-ai changelog [options]"
                echo ""
                echo "Options:"
                echo "  --since <ref>   Generate changelog since tag/commit (e.g., v1.0.0)"
                echo "  --format <fmt>  Changelog format (default: keepachangelog)"
                echo "  --help, -h      Show this help message"
                echo ""
                echo "Examples:"
                echo "  gh commit-ai changelog"
                echo "  gh commit-ai changelog --since v1.0.0"
                echo "  gh commit-ai changelog --since HEAD~10"
                exit 0
                ;;
            *)
                echo -e "${RED}Error: Unknown changelog option $1"
                echo "Use 'gh commit-ai changelog --help' for usage information"
                exit 1
                ;;
        esac
    done
elif [ "$1" = "split" ]; then
    SPLIT_MODE=true
    shift

    # Parse split-specific flags
    SPLIT_DRY_RUN=false
    SPLIT_THRESHOLD=1000
    while [[ $# -gt 0 ]]; do
        case $1 in
            --dry-run|-n)
                SPLIT_DRY_RUN=true
                shift
                ;;
            --threshold|-t)
                SPLIT_THRESHOLD="$2"
                # Validate threshold is a positive integer
                if ! validate_positive_integer "$SPLIT_THRESHOLD" "--threshold"; then
                    exit 1
                fi
                shift 2
                ;;
            --help|-h)
                echo "gh-commit-ai split - Suggest how to split large commits"
                echo ""
                echo "Usage: gh commit-ai split [options]"
                echo ""
                echo "Analyzes staged changes and suggests logical ways to split them"
                echo "into multiple smaller commits for better git history."
                echo ""
                echo "Options:"
                echo "  --dry-run, -n         Show suggestions without creating commits"
                echo "  --threshold, -t <n>   Line count threshold for large commits (default: 1000)"
                echo "  --help, -h            Show this help message"
                echo ""
                echo "Examples:"
                echo "  gh commit-ai split"
                echo "  gh commit-ai split --dry-run"
                echo "  gh commit-ai split --threshold 500"
                echo ""
                echo "The tool will:"
                echo "  1. Analyze your staged changes"
                echo "  2. Group related files together"
                echo "  3. Suggest logical commit splits"
                echo "  4. Let you interactively apply the splits"
                exit 0
                ;;
            *)
                echo -e "${RED}Error: Unknown split option $1${NC}"
                echo "Use 'gh commit-ai split --help' for usage information"
                exit 1
                ;;
        esac
    done
elif [ "$1" = "version" ] || [ "$1" = "semver" ]; then
    VERSION_MODE=true
    shift

    # Parse version-specific flags
    CREATE_TAG=false
    TAG_PREFIX="v"
    while [[ $# -gt 0 ]]; do
        case $1 in
            --create-tag|-t)
                CREATE_TAG=true
                shift
                ;;
            --prefix)
                TAG_PREFIX="$2"
                shift 2
                ;;
            --help|-h)
                echo "gh-commit-ai version - Suggest next semantic version"
                echo ""
                echo "Usage: gh commit-ai version [options]"
                echo "       gh commit-ai semver [options]"
                echo ""
                echo "Options:"
                echo "  --create-tag, -t    Create git tag for suggested version"
                echo "  --prefix <prefix>   Tag prefix (default: 'v')"
                echo "  --help, -h          Show this help message"
                echo ""
                echo "Analyzes commits since last tag to suggest next version:"
                echo "  â€¢ Breaking changes â†’ Major bump (1.0.0 â†’ 2.0.0)"
                echo "  â€¢ New features â†’ Minor bump (1.0.0 â†’ 1.1.0)"
                echo "  â€¢ Bug fixes only â†’ Patch bump (1.0.0 â†’ 1.0.1)"
                echo ""
                echo "Examples:"
                echo "  gh commit-ai version              # Suggest next version"
                echo "  gh commit-ai version --create-tag # Suggest and create tag"
                echo "  gh commit-ai semver -t            # Short alias with tag creation"
                exit 0
                ;;
            *)
                echo -e "${RED}Error: Unknown version option $1"
                echo "Use 'gh commit-ai version --help' for usage information"
                exit 1
                ;;
        esac
    done
elif [ "$1" = "install-hook" ]; then
    # Install prepare-commit-msg hook
    HOOK_DIR=".git/hooks"
    HOOK_FILE="$HOOK_DIR/prepare-commit-msg"

    # Check if we're in a git repository
    if ! git rev-parse --git-dir > /dev/null 2>&1; then
        echo -e "${RED}Error: Not a git repository"
        exit 1
    fi

    # Create hooks directory if it doesn't exist
    mkdir -p "$HOOK_DIR"

    # Check if hook already exists
    if [ -f "$HOOK_FILE" ]; then
        # Check if it's our hook
        if grep -q "gh-commit-ai hook" "$HOOK_FILE" 2>/dev/null; then
            echo "Hook already installed"
            exit 0
        else
            echo -e "${RED}Error: A prepare-commit-msg hook already exists"
            echo "Please manually merge or remove: $HOOK_FILE"
            exit 1
        fi
    fi

    # Create the hook
    cat > "$HOOK_FILE" << 'EOF'
#!/bin/bash
# gh-commit-ai hook
# This hook is OPT-IN: only runs when GH_COMMIT_AI=1

COMMIT_MSG_FILE="$1"
COMMIT_SOURCE="$2"

# Only run if explicitly enabled via environment variable
if [ "$GH_COMMIT_AI" != "1" ]; then
    exit 0
fi

# Don't run for merge commits, squash, or amend
if [ "$COMMIT_SOURCE" = "merge" ] || [ "$COMMIT_SOURCE" = "squash" ] || [ "$COMMIT_SOURCE" = "commit" ]; then
    exit 0
fi

# Generate commit message using gh-commit-ai
echo "Generating commit message with AI" >&2

# Run gh-commit-ai in preview mode to get the message
GENERATED_MSG=$(gh commit-ai --preview 2>&1 | grep -A 1000 "Generated commit message:" | tail -n +2)

if [ -n "$GENERATED_MSG" ]; then
    # Write the generated message to the commit message file
    echo "$GENERATED_MSG" > "$COMMIT_MSG_FILE"
    echo "âœ“ AI-generated message added. Review and edit if needed." >&2
else
    echo "âœ— Failed to generate message, opening editor with empty message" >&2
fi
EOF

    chmod +x "$HOOK_FILE"

    echo "âœ“ Pre-commit hook installed successfully!"
    echo ""
    echo "Usage (OPT-IN):"
    echo "  1. Regular commits work normally:"
    echo "     git commit"
    echo ""
    echo "  2. Use AI generation when you want it:"
    echo "     GH_COMMIT_AI=1 git commit"
    echo ""
    echo "  3. Or set up a convenient alias:"
    echo "     git config alias.ai-commit '!GH_COMMIT_AI=1 git commit'"
    echo "     git ai-commit    # Use AI generation"
    echo ""
    echo "To uninstall: gh commit-ai uninstall-hook"

    exit 0

elif [ "$1" = "uninstall-hook" ]; then
    # Uninstall prepare-commit-msg hook
    HOOK_FILE=".git/hooks/prepare-commit-msg"

    # Check if we're in a git repository
    if ! git rev-parse --git-dir > /dev/null 2>&1; then
        echo -e "${RED}Error: Not a git repository"
        exit 1
    fi

    if [ ! -f "$HOOK_FILE" ]; then
        echo "No hook to uninstall"
        exit 0
    fi

    # Check if it's our hook
    if ! grep -q "gh-commit-ai hook" "$HOOK_FILE" 2>/dev/null; then
        echo -e "${RED}Error: Hook file exists but is not from gh-commit-ai"
        echo "Please manually review: $HOOK_FILE"
        exit 1
    fi

    rm "$HOOK_FILE"
    echo "âœ“ Pre-commit hook uninstalled successfully"

    # Also remove the git alias if it exists
    if git config --get alias.ai-commit > /dev/null 2>&1; then
        echo ""
        echo "Note: Git alias 'ai-commit' still exists. To remove it:"
        echo "  git config --unset alias.ai-commit"
    fi

    exit 0
elif [ "$1" = "install-man" ]; then
    # Install man page
    echo "Installing man page for gh-commit-ai..."
    echo ""

    # Determine script directory (where man/ folder is)
    SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
    MAN_SOURCE="$SCRIPT_DIR/man/gh-commit-ai.1"

    if [ ! -f "$MAN_SOURCE" ]; then
        echo "Error: Man page not found at $MAN_SOURCE"
        exit 1
    fi

    # Determine where to install man page
    # Try standard locations in order of preference
    if [ -d "/usr/local/share/man/man1" ] && [ -w "/usr/local/share/man/man1" ]; then
        MAN_DIR="/usr/local/share/man/man1"
    elif [ -d "$HOME/.local/share/man/man1" ]; then
        MAN_DIR="$HOME/.local/share/man/man1"
    elif [ -d "$HOME/.local/share/man" ]; then
        mkdir -p "$HOME/.local/share/man/man1"
        MAN_DIR="$HOME/.local/share/man/man1"
    else
        # Create user man directory
        mkdir -p "$HOME/.local/share/man/man1"
        MAN_DIR="$HOME/.local/share/man/man1"
    fi

    # Copy man page
    cp "$MAN_SOURCE" "$MAN_DIR/gh-commit-ai.1"

    if [ $? -eq 0 ]; then
        echo "âœ“ Man page installed to $MAN_DIR/gh-commit-ai.1"
        echo ""
        echo "You can now view the manual with:"
        echo "  man gh-commit-ai"
        echo ""

        # Update man database if possible
        if command -v mandb >/dev/null 2>&1; then
            echo "Updating man database..."
            mandb -q 2>/dev/null || true
        fi

        # Check if man can find it
        if man -w gh-commit-ai >/dev/null 2>&1; then
            echo "âœ“ Man page is accessible"
        else
            echo "Note: You may need to add $HOME/.local/share/man to your MANPATH:"
            echo "  export MANPATH=\"\$HOME/.local/share/man:\$MANPATH\""
        fi
    else
        echo "Error: Failed to install man page"
        exit 1
    fi

    exit 0
elif [ "$1" = "uninstall-man" ]; then
    # Uninstall man page
    echo "Uninstalling man page for gh-commit-ai..."
    echo ""

    # Check standard locations
    MAN_LOCATIONS=(
        "/usr/local/share/man/man1/gh-commit-ai.1"
        "$HOME/.local/share/man/man1/gh-commit-ai.1"
    )

    FOUND=false
    for man_file in "${MAN_LOCATIONS[@]}"; do
        if [ -f "$man_file" ]; then
            rm -f "$man_file"
            echo "âœ“ Removed $man_file"
            FOUND=true
        fi
    done

    if [ "$FOUND" = false ]; then
        echo "No man page found to remove"
    else
        echo ""
        echo "Man page uninstalled successfully"

        # Update man database if possible
        if command -v mandb >/dev/null 2>&1; then
            echo "Updating man database..."
            mandb -q 2>/dev/null || true
        fi
    fi

    exit 0
elif [ "$1" = "install-completion" ]; then
    # Install shell completion
    echo "Installing shell completion for gh-commit-ai..."
    echo ""

    # Detect shell
    CURRENT_SHELL=$(basename "$SHELL")

    # Determine script directory (where completions/ folder is)
    SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

    if [ "$CURRENT_SHELL" = "bash" ]; then
        # Bash completion
        COMPLETION_SOURCE="$SCRIPT_DIR/completions/gh-commit-ai.bash"

        if [ ! -f "$COMPLETION_SOURCE" ]; then
            echo -e "${RED}Error: Completion file not found: $COMPLETION_SOURCE${NC}"
            exit 1
        fi

        # Try standard locations
        if [ -d "/usr/local/etc/bash_completion.d" ]; then
            # macOS (Homebrew)
            sudo cp "$COMPLETION_SOURCE" "/usr/local/etc/bash_completion.d/gh-commit-ai"
            echo "âœ“ Installed to /usr/local/etc/bash_completion.d/gh-commit-ai"
        elif [ -d "/etc/bash_completion.d" ]; then
            # Linux
            sudo cp "$COMPLETION_SOURCE" "/etc/bash_completion.d/gh-commit-ai"
            echo "âœ“ Installed to /etc/bash_completion.d/gh-commit-ai"
        else
            # User-local installation
            mkdir -p "$HOME/.bash_completion.d"
            cp "$COMPLETION_SOURCE" "$HOME/.bash_completion.d/gh-commit-ai"
            echo "âœ“ Installed to $HOME/.bash_completion.d/gh-commit-ai"
            echo ""
            echo "Add this to your ~/.bashrc to enable:"
            echo "  source $HOME/.bash_completion.d/gh-commit-ai"
        fi

        echo ""
        echo "Restart your shell or run: source ~/.bashrc"

    elif [ "$CURRENT_SHELL" = "zsh" ]; then
        # Zsh completion
        COMPLETION_SOURCE="$SCRIPT_DIR/completions/_gh-commit-ai"

        if [ ! -f "$COMPLETION_SOURCE" ]; then
            echo -e "${RED}Error: Completion file not found: $COMPLETION_SOURCE${NC}"
            exit 1
        fi

        # Try standard locations
        if [ -d "/usr/local/share/zsh/site-functions" ]; then
            # macOS (Homebrew)
            sudo cp "$COMPLETION_SOURCE" "/usr/local/share/zsh/site-functions/_gh-commit-ai"
            echo "âœ“ Installed to /usr/local/share/zsh/site-functions/_gh-commit-ai"
        elif [ -d "/usr/share/zsh/site-functions" ]; then
            # Linux
            sudo cp "$COMPLETION_SOURCE" "/usr/share/zsh/site-functions/_gh-commit-ai"
            echo "âœ“ Installed to /usr/share/zsh/site-functions/_gh-commit-ai"
        else
            # User-local installation
            mkdir -p "$HOME/.zsh/completion"
            cp "$COMPLETION_SOURCE" "$HOME/.zsh/completion/_gh-commit-ai"
            echo "âœ“ Installed to $HOME/.zsh/completion/_gh-commit-ai"
            echo ""
            echo "Add this to your ~/.zshrc to enable:"
            echo "  fpath=(\$HOME/.zsh/completion \$fpath)"
            echo "  autoload -Uz compinit && compinit"
        fi

        echo ""
        echo "Restart your shell or run: exec zsh"

    else
        echo -e "${YELLOW}Warning: Unknown shell: $CURRENT_SHELL${NC}"
        echo "Supported shells: bash, zsh"
        echo ""
        echo "Manual installation:"
        echo "  Bash: Copy completions/gh-commit-ai.bash to your bash completion directory"
        echo "  Zsh:  Copy completions/_gh-commit-ai to your zsh completion directory"
        exit 1
    fi

    exit 0
elif [ "$1" = "uninstall-completion" ]; then
    # Uninstall shell completion
    echo "Uninstalling shell completion for gh-commit-ai..."
    echo ""

    # Detect shell
    CURRENT_SHELL=$(basename "$SHELL")

    if [ "$CURRENT_SHELL" = "bash" ]; then
        # Try standard locations
        REMOVED=false

        if [ -f "/usr/local/etc/bash_completion.d/gh-commit-ai" ]; then
            sudo rm "/usr/local/etc/bash_completion.d/gh-commit-ai"
            echo "âœ“ Removed from /usr/local/etc/bash_completion.d/"
            REMOVED=true
        fi

        if [ -f "/etc/bash_completion.d/gh-commit-ai" ]; then
            sudo rm "/etc/bash_completion.d/gh-commit-ai"
            echo "âœ“ Removed from /etc/bash_completion.d/"
            REMOVED=true
        fi

        if [ -f "$HOME/.bash_completion.d/gh-commit-ai" ]; then
            rm "$HOME/.bash_completion.d/gh-commit-ai"
            echo "âœ“ Removed from $HOME/.bash_completion.d/"
            REMOVED=true
        fi

        if [ "$REMOVED" = false ]; then
            echo "No completion file found to remove"
        else
            echo ""
            echo "Restart your shell for changes to take effect"
        fi

    elif [ "$CURRENT_SHELL" = "zsh" ]; then
        # Try standard locations
        REMOVED=false

        if [ -f "/usr/local/share/zsh/site-functions/_gh-commit-ai" ]; then
            sudo rm "/usr/local/share/zsh/site-functions/_gh-commit-ai"
            echo "âœ“ Removed from /usr/local/share/zsh/site-functions/"
            REMOVED=true
        fi

        if [ -f "/usr/share/zsh/site-functions/_gh-commit-ai" ]; then
            sudo rm "/usr/share/zsh/site-functions/_gh-commit-ai"
            echo "âœ“ Removed from /usr/share/zsh/site-functions/"
            REMOVED=true
        fi

        if [ -f "$HOME/.zsh/completion/_gh-commit-ai" ]; then
            rm "$HOME/.zsh/completion/_gh-commit-ai"
            echo "âœ“ Removed from $HOME/.zsh/completion/"
            REMOVED=true
        fi

        if [ "$REMOVED" = false ]; then
            echo "No completion file found to remove"
        else
            echo ""
            echo "Run: rm -f ~/.zcompdump && exec zsh"
        fi

    else
        echo -e "${YELLOW}Warning: Unknown shell: $CURRENT_SHELL${NC}"
        echo "Supported shells: bash, zsh"
        exit 1
    fi

    exit 0
elif [ "$1" = "pr-description" ]; then
    PR_DESCRIPTION_MODE=true
    shift

    # Parse pr-description-specific flags
    BASE_BRANCH=""
    OUTPUT_FILE=""
    while [[ $# -gt 0 ]]; do
        case $1 in
            --base)
                BASE_BRANCH="$2"
                shift 2
                ;;
            --output|-o)
                OUTPUT_FILE="$2"
                shift 2
                ;;
            --help|-h)
                echo "gh-commit-ai pr-description - Generate PR description from commits"
                echo ""
                echo "Usage: gh commit-ai pr-description [options]"
                echo ""
                echo "Options:"
                echo "  --base <branch>     Base branch to compare against (default: auto-detect)"
                echo "  --output, -o <file> Save to file instead of stdout"
                echo "  --help, -h          Show this help message"
                echo ""
                echo "Examples:"
                echo "  gh commit-ai pr-description"
                echo "  gh commit-ai pr-description --base main"
                echo "  gh commit-ai pr-description --output pr.md"
                echo "  gh pr create --body \"\$(gh commit-ai pr-description)\""
                exit 0
                ;;
            *)
                echo -e "${RED}Error: Unknown pr-description option $1"
                echo "Use 'gh commit-ai pr-description --help' for usage information"
                exit 1
                ;;
        esac
    done
elif [ "$1" = "review" ]; then
    CODE_REVIEW_MODE=true
    shift

    # Parse review-specific flags
    REVIEW_STAGED_ONLY=true  # Default to staged changes
    while [[ $# -gt 0 ]]; do
        case $1 in
            --all)
                REVIEW_STAGED_ONLY=false
                shift
                ;;
            --help|-h)
                echo "gh-commit-ai review - Code review assistant for your changes"
                echo ""
                echo "Usage: gh commit-ai review [options]"
                echo ""
                echo "Options:"
                echo "  --all               Review all changes (staged + unstaged)"
                echo "  --help, -h          Show this help message"
                echo ""
                echo "Reviews your changes for:"
                echo "  â€¢ Security vulnerabilities"
                echo "  â€¢ Performance concerns"
                echo "  â€¢ Code style issues"
                echo "  â€¢ Missing error handling"
                echo "  â€¢ Potential bugs"
                echo "  â€¢ TODO/FIXME comments"
                echo ""
                echo "Examples:"
                echo "  gh commit-ai review              # Review staged changes"
                echo "  gh commit-ai review --all        # Review all changes"
                exit 0
                ;;
            *)
                echo -e "${RED}Error: Unknown review option $1"
                echo "Use 'gh commit-ai review --help' for usage information"
                exit 1
                ;;
        esac
    done
fi

while [[ $# -gt 0 ]]; do
    case $1 in
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --preview)
            PREVIEW=true
            shift
            ;;
        --amend)
            AMEND=true
            shift
            ;;
        --options)
            MULTIPLE_OPTIONS=true
            shift
            ;;
        --version)
            echo "gh-commit-ai version $VERSION"
            exit 0
            ;;
        --verbose|-v)
            VERBOSE=true
            shift
            ;;
        --type)
            FORCED_TYPE="$2"
            # Validate type is one of the allowed conventional commit types
            if ! validate_allowed_values "$FORCED_TYPE" "--type" "feat" "fix" "docs" "style" "refactor" "test" "chore" "perf" "ci" "build" "revert"; then
                exit 1
            fi
            shift 2
            ;;
        --max-lines)
            CUSTOM_MAX_LINES="$2"
            # Validate max-lines is a positive integer
            if ! validate_positive_integer "$CUSTOM_MAX_LINES" "--max-lines"; then
                exit 1
            fi
            shift 2
            ;;
        --no-lowercase)
            NO_LOWERCASE=true
            shift
            ;;
        --help|-h)
            echo "gh-commit-ai - AI-powered git commit message generator"
            echo ""
            echo "Usage: gh commit-ai [options]"
            echo "       gh commit-ai <command> [options]"
            echo ""
            echo "Commands:"
            echo "  (default)            Generate commit message for current changes"
            echo "  review               Review code changes for potential issues"
            echo "  version              Suggest next semantic version number"
            echo "  changelog            Generate changelog from commit history"
            echo "  pr-description       Generate PR description from branch commits"
            echo "  install-hook         Install git hook for opt-in AI commits"
            echo "  uninstall-hook       Remove git hook"
            echo "  install-man          Install man page"
            echo "  uninstall-man        Remove man page"
            echo "  install-completion   Install shell completion (bash/zsh)"
            echo "  uninstall-completion Remove shell completion"
            echo ""
            echo "Options:"
            echo "  --dry-run           Generate commit message without committing"
            echo "  --preview           Generate and display message, then exit"
            echo "  --amend             Regenerate message for last commit"
            echo "  --options           Generate multiple variations to choose from"
            echo "  --type <type>       Force a specific commit type (feat, fix, docs, etc.)"
            echo "  --max-lines <n>     Override DIFF_MAX_LINES for this run"
            echo "  --no-lowercase      Disable automatic lowercase enforcement"
            echo "  --verbose, -v       Show detailed API request/response info"
            echo "  --version           Show version number"
            echo "  --help, -h          Show this help message"
            echo ""
            echo "Interactive Options (when reviewing commit message):"
            echo "  y - Accept and commit"
            echo "  n - Cancel"
            echo "  e - Edit in your default editor"
            echo ""
            echo "Environment Variables:"
            echo "  AI_PROVIDER         AI provider (auto, ollama, anthropic, openai, groq)"
            echo "                      Default: auto (detects what's available)"
            echo "  COMMIT_LANGUAGE     Language for commit messages (en, es, fr, de, ja, zh, etc.)"
            echo "                      Default: auto-detect from system locale"
            echo "  USE_SCOPE           Enable/disable scopes (true/false)"
            echo "  USE_GITMOJI         Enable/disable gitmoji prefixes (true/false)"
            echo "  DIFF_MAX_LINES      Maximum diff lines to send to AI"
            echo "  GH_COMMIT_AI        Set to 1 to enable hook (opt-in)"
            echo ""
            echo "Configuration Files:"
            echo "  .gh-commit-ai.yml       Local config (repo root)"
            echo "  ~/.gh-commit-ai.yml     Global config"
            echo ""
            echo "Examples:"
            echo "  gh commit-ai"
            echo "  gh commit-ai --dry-run"
            echo "  gh commit-ai --preview"
            echo "  gh commit-ai --amend"
            echo "  gh commit-ai changelog"
            echo "  gh commit-ai changelog --since v1.0.0"
            echo "  gh commit-ai install-hook"
            echo "  gh commit-ai install-completion"
            echo "  GH_COMMIT_AI=1 git commit    # With hook installed"
            echo "  USE_SCOPE=false gh commit-ai"
            echo "  USE_GITMOJI=true gh commit-ai"
            echo "  COMMIT_LANGUAGE=es gh commit-ai    # Spanish messages"
            echo "  COMMIT_LANGUAGE=ja gh commit-ai    # Japanese messages"
            exit 0
            ;;
        *)
            echo -e "${RED}Error: Unknown option $1"
            echo "Use --help for usage information"
            exit 1
            ;;
    esac
done

# Apply command-line overrides
if [ -n "$CUSTOM_MAX_LINES" ]; then
    DIFF_MAX_LINES="$CUSTOM_MAX_LINES"
fi

# Show spinner while waiting
show_spinner() {
    local pid=$1
    local message="$2"
    local delay=0.15
    local arrows=("â†" "â†–" "â†‘" "â†—" "â†’" "â†˜" "â†“" "â†™")
    local i=0

    while kill -0 "$pid" 2>/dev/null; do
        printf "\r${arrows[$i]} ${message}" >&2
        i=$(( (i + 1) % 8 ))
        sleep $delay
    done
    printf "\r%-50s\r" " " >&2  # Clear the line
}

# Intelligently sample diff for large changes
# Prioritizes: function signatures > added lines > context > deleted lines
smart_sample_diff() {
    local full_diff="$1"
    local max_lines="$2"

    # Count total lines
    local total_lines=$(echo "$full_diff" | wc -l | tr -d ' ')

    # If under limit, return full diff
    if [ "$total_lines" -le "$max_lines" ]; then
        echo "$full_diff"
        return
    fi

    # Otherwise, intelligently sample
    local temp_file
    temp_file=$(create_secure_temp_file "gh-commit-ai-smart-sample") || return 1
    echo "$full_diff" > "$temp_file"

    # Extract high-priority lines
    local priority_file
    priority_file=$(create_secure_temp_file "gh-commit-ai-priority") || {
        rm -f "$temp_file"
        return 1
    }
    > "$priority_file"

    # Priority 1: File headers and chunk headers (MUST keep)
    grep -E '^(diff --git|index |---|\+\+\+|@@)' "$temp_file" >> "$priority_file" 2>/dev/null || true

    # Priority 2: Function/class definitions (HIGH priority)
    grep -E '^\+.*(function |def |class |const |export |public |private |func )' "$temp_file" >> "$priority_file" 2>/dev/null || true

    # Priority 3: Added lines (MEDIUM-HIGH priority)
    # Sample added lines evenly throughout the diff
    local added_lines=$(grep -n '^\+[^+]' "$temp_file" | wc -l | tr -d ' ')
    if [ "$added_lines" -gt 0 ]; then
        # Calculate sample rate to get ~40% of max_lines from added lines
        local target_added=$((max_lines * 40 / 100))
        local sample_rate=$((added_lines / target_added + 1))

        grep -n '^\+[^+]' "$temp_file" | awk -v rate="$sample_rate" 'NR % rate == 1' | cut -d: -f1 | while read line_num; do
            sed -n "${line_num}p" "$temp_file" >> "$priority_file"
        done
    fi

    # Priority 4: Context lines around changes (MEDIUM priority)
    # Get a few context lines for readability
    grep -E '^ [a-zA-Z]' "$temp_file" | head -n $((max_lines * 20 / 100)) >> "$priority_file" 2>/dev/null || true

    # Priority 5: Deleted lines (LOW priority) - only sample if we have room
    local current_count=$(cat "$priority_file" | wc -l | tr -d ' ')
    if [ "$current_count" -lt "$max_lines" ]; then
        local remaining=$((max_lines - current_count))
        grep -E '^\-[^-]' "$temp_file" | head -n $((remaining / 2)) >> "$priority_file" 2>/dev/null || true
    fi

    # Sort by line number to maintain diff structure, remove duplicates, and limit
    cat "$priority_file" | sort -u | head -n "$max_lines"

    # Cleanup
    rm -f "$temp_file" "$priority_file"
}

# Analyze commit size (count lines changed)
analyze_commit_size() {
    local diff="$1"

    # Count added and deleted lines (ignore context lines)
    local added=$(echo "$diff" | grep -c '^\+[^+]' 2>/dev/null || echo "0")
    local deleted=$(echo "$diff" | grep -c '^\-[^-]' 2>/dev/null || echo "0")
    local total=$((added + deleted))

    echo "$total"
}

# Check if we're in a git repository (cache the result)
# PERFORMANCE OPTIMIZATION: Cache all git repository info upfront
GIT_DIR=$(git rev-parse --git-dir 2>/dev/null)
if [ -z "$GIT_DIR" ]; then
    echo -e "${RED}Error: Not a git repository"
    exit 1
fi

# Cache branch name early (avoids later git call)
BRANCH_NAME=$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo "")

# Get repository-specific identifier for message history
# This ensures cached messages don't leak between different repositories
REPO_ROOT=$(git rev-parse --show-toplevel 2>/dev/null)
if [ -n "$REPO_ROOT" ]; then
    # Create a hash of the repository path to use as a unique identifier
    if command -v md5sum &> /dev/null; then
        REPO_HASH=$(echo -n "$REPO_ROOT" | md5sum | awk '{print $1}')
    elif command -v md5 &> /dev/null; then
        REPO_HASH=$(echo -n "$REPO_ROOT" | md5 | awk '{print $1}')
    else
        # Fallback: use basename of repo (less robust but better than nothing)
        REPO_HASH=$(basename "$REPO_ROOT")
    fi
    MESSAGE_HISTORY_DIR="/tmp/gh-commit-ai-history-${REPO_HASH}"
    CACHE_DIR="/tmp/gh-commit-ai-cache-${REPO_HASH}"
else
    # Fallback to non-scoped directory (shouldn't happen in valid git repos)
    MESSAGE_HISTORY_DIR="/tmp/gh-commit-ai-history"
    CACHE_DIR="/tmp/gh-commit-ai-cache"
fi
mkdir -p "$MESSAGE_HISTORY_DIR"
mkdir -p "$CACHE_DIR"

# Note: Cache cleanup happens automatically in save_cached_response() to avoid startup delay

# ============================================================================
# Cache Helper Functions
# ============================================================================

# Get cached value if fresh (within TTL)
# Args: cache_key, ttl_seconds
# Returns: cached content if valid, empty otherwise
get_cache() {
    local cache_key="$1"
    local ttl="${2:-3600}"  # Default 1 hour
    local cache_file="${CACHE_DIR}/${cache_key}"

    if [ -f "$cache_file" ]; then
        local file_age=$(($(date +%s) - $(stat -f%m "$cache_file" 2>/dev/null || stat -c%Y "$cache_file" 2>/dev/null)))
        if [ "$file_age" -lt "$ttl" ]; then
            cat "$cache_file"
            return 0
        fi
    fi
    return 1
}

# Save value to cache
# Args: cache_key, content
set_cache() {
    local cache_key="$1"
    local content="$2"
    local cache_file="${CACHE_DIR}/${cache_key}"

    echo "$content" > "$cache_file"
}

# Handle changelog mode
if [ "$CHANGELOG_MODE" = true ]; then
    echo "Generating changelog"
    generate_changelog "$CHANGELOG_SINCE" "$CHANGELOG_FORMAT"
    exit 0
fi

# Handle split mode
if [ "$SPLIT_MODE" = true ]; then
    suggest_commit_splits "$SPLIT_THRESHOLD" "$SPLIT_DRY_RUN"
    exit 0
fi

# Handle amend mode differently
if [ "$AMEND" = true ]; then
    # Check if there's at least one commit
    if ! git rev-parse HEAD >/dev/null 2>&1; then
        echo -e "${RED}Error: No commits to amend"
        exit 1
    fi

    # Create secure temp files for inter-process communication
    status_file=$(create_secure_temp_file "gh-commit-ai-status") || exit 1
    stats_file=$(create_secure_temp_file "gh-commit-ai-stats") || { rm -f "$status_file"; exit 1; }
    diff_file=$(create_secure_temp_file "gh-commit-ai-diff") || { rm -f "$status_file" "$stats_file"; exit 1; }
    size_file=$(create_secure_temp_file "gh-commit-ai-size") || { rm -f "$status_file" "$stats_file" "$diff_file"; exit 1; }

    # Get the changes from the last commit with loading animation (optimized - minimal git calls)
    (
        # Get all needed data with just two git calls (show for diff, numstat for stats)
        SHOW_OUTPUT=$(eval "git show --numstat HEAD $GIT_EXCLUDE_PATTERN")

        # Extract stats from numstat output (before the diff starts)
        GIT_STATS=$(echo "$SHOW_OUTPUT" | awk '/^[0-9]+\t[0-9]+\t/ {print $3}' | head -10 | awk '{print "M " $0}')

        # Extract full diff (after numstat section)
        FULL_DIFF=$(echo "$SHOW_OUTPUT" | awk '/^diff --git/,0')

        # Extract file list for status
        GIT_STATUS=$(echo "$SHOW_OUTPUT" | awk '/^diff --git/ {print "M " $4}' | sed 's|^M b/|M |')

        GIT_DIFF=$(smart_sample_diff "$FULL_DIFF" "$DIFF_MAX_LINES")

        # Calculate commit size (lines added + deleted) from numstat
        COMMIT_SIZE=$(echo "$SHOW_OUTPUT" | awk '/^[0-9]+\t[0-9]+\t/ {added+=$1; deleted+=$2} END {print added+deleted}')

        # Export to temp file for parent process
        echo "$GIT_STATUS" > "$status_file"
        echo "$GIT_STATS" > "$stats_file"
        echo "$GIT_DIFF" > "$diff_file"
        echo "$COMMIT_SIZE" > "$size_file"
    ) &
    ANALYZE_PID=$!

    show_spinner "$ANALYZE_PID" "Analyzing last commit"
    wait "$ANALYZE_PID"

    # Read results from temp files
    GIT_STATUS=$(cat "$status_file" 2>/dev/null || echo "")
    GIT_STATS=$(cat "$stats_file" 2>/dev/null || echo "")
    GIT_DIFF=$(cat "$diff_file" 2>/dev/null || echo "")
    COMMIT_SIZE=$(cat "$size_file" 2>/dev/null || echo "0")
    rm -f "$status_file" "$stats_file" "$diff_file" "$size_file"

    echo "âœ“ Commit analyzed"
else
    # Check if there are changes to commit (exclude lock files from check)
    if eval "git diff --cached --quiet $GIT_EXCLUDE_PATTERN" && eval "git diff --quiet $GIT_EXCLUDE_PATTERN"; then
        echo "No changes to commit"
        exit 0
    fi

    # Create secure temp files for inter-process communication
    status_file=$(create_secure_temp_file "gh-commit-ai-status") || exit 1
    stats_file=$(create_secure_temp_file "gh-commit-ai-stats") || { rm -f "$status_file"; exit 1; }
    diff_file=$(create_secure_temp_file "gh-commit-ai-diff") || { rm -f "$status_file" "$stats_file"; exit 1; }
    size_file=$(create_secure_temp_file "gh-commit-ai-size") || { rm -f "$status_file" "$stats_file" "$diff_file"; exit 1; }

    # Get git status and diff with loading animation (optimized - minimal git calls)
    (
        # PERFORMANCE OPTIMIZATION: Use single git diff call with --numstat to get everything
        # This avoids redundant git diff calls (44% faster)
        FULL_NUMSTAT_OUTPUT=$(eval "git diff --cached --numstat $GIT_EXCLUDE_PATTERN" 2>/dev/null || echo "")
        if [ -z "$FULL_NUMSTAT_OUTPUT" ]; then
            FULL_NUMSTAT_OUTPUT=$(eval "git diff --numstat $GIT_EXCLUDE_PATTERN" 2>/dev/null || echo "")
            IS_STAGED=false
        else
            IS_STAGED=true
        fi

        # Extract numstat data (header lines before the diff)
        NUMSTAT_DATA=$(echo "$FULL_NUMSTAT_OUTPUT" | awk '/^[0-9]+\t[0-9]+\t/ {print}')

        # Generate GIT_STATUS from numstat data (avoids separate git status call)
        GIT_STATUS=$(echo "$NUMSTAT_DATA" | awk '{print "M " $3}')

        # Extract file list for GIT_STATS (first 10 files)
        GIT_STATS=$(echo "$NUMSTAT_DATA" | awk '{print $3}' | head -10 | awk '{print "M " $0}')

        # Get full diff for AI (single call)
        if [ "$IS_STAGED" = "true" ]; then
            FULL_DIFF=$(eval "git diff --cached $GIT_EXCLUDE_PATTERN" 2>/dev/null)
        else
            FULL_DIFF=$(eval "git diff $GIT_EXCLUDE_PATTERN" 2>/dev/null)
        fi
        GIT_DIFF=$(smart_sample_diff "$FULL_DIFF" "$DIFF_MAX_LINES")

        # Calculate commit size from numstat
        COMMIT_SIZE=$(echo "$NUMSTAT_DATA" | awk '{added+=$1; deleted+=$2} END {print added+deleted}')

        # Export to temp file for parent process
        echo "$GIT_STATUS" > "$status_file"
        echo "$GIT_STATS" > "$stats_file"
        echo "$GIT_DIFF" > "$diff_file"
        echo "$COMMIT_SIZE" > "$size_file"
    ) &
    ANALYZE_PID=$!

    show_spinner "$ANALYZE_PID" "Analyzing changes"
    wait "$ANALYZE_PID"

    # Read results from temp files
    GIT_STATUS=$(cat "$status_file" 2>/dev/null || echo "")
    GIT_STATS=$(cat "$stats_file" 2>/dev/null || echo "")
    GIT_DIFF=$(cat "$diff_file" 2>/dev/null || echo "")
    COMMIT_SIZE=$(cat "$size_file" 2>/dev/null || echo "0")
    rm -f "$status_file" "$stats_file" "$diff_file" "$size_file"

    echo "âœ“ Changes analyzed"

    # Show auto-detection info if applicable
    if [ "$AUTO_DETECTED" = "true" ]; then
        case "$AI_PROVIDER" in
            ollama)
                echo "Using Ollama with model: $OLLAMA_MODEL (auto-detected)"
                ;;
            anthropic)
                echo "Using Anthropic Claude (auto-detected)"
                ;;
            openai)
                echo "Using OpenAI (auto-detected)"
                ;;
        esac
    fi
fi

# Extract ticket number from branch name (e.g., feature/ABC-123-description â†’ ABC-123)
# Note: BRANCH_NAME already cached earlier for performance
TICKET_NUMBER=""
if [ -n "$BRANCH_NAME" ]; then
    TICKET_NUMBER=$(echo "$BRANCH_NAME" | grep -oE '[A-Z][A-Z0-9]+-[0-9]+' | head -1)
fi

# Detect suggested type from branch name
SUGGESTED_TYPE=""
if [ -n "$BRANCH_NAME" ]; then
    case "$BRANCH_NAME" in
        feat/*|feature/*) SUGGESTED_TYPE="feat" ;;
        fix/*|bugfix/*|hotfix/*) SUGGESTED_TYPE="fix" ;;
        docs/*|doc/*) SUGGESTED_TYPE="docs" ;;
        style/*) SUGGESTED_TYPE="style" ;;
        refactor/*) SUGGESTED_TYPE="refactor" ;;
        test/*|tests/*) SUGGESTED_TYPE="test" ;;
        chore/*) SUGGESTED_TYPE="chore" ;;
    esac
fi

# Smart type detection based on changed files and content
detect_smart_type() {
    local files="$1"
    local diff="$2"

    # Get list of changed files (extract filenames from git status)
    local changed_files=$(echo "$files" | awk '{print $NF}')

    # Count different file types
    local doc_count=0
    local test_count=0
    local config_count=0
    local code_count=0
    local total_count=0

    while IFS= read -r file; do
        [ -z "$file" ] && continue
        total_count=$((total_count + 1))

        # Check for documentation files
        if [[ "$file" =~ \.(md|txt|rst|adoc)$ ]] || [[ "$file" =~ ^docs?/ ]] || [[ "$file" =~ ^documentation/ ]] || [[ "$file" =~ README|CHANGELOG|LICENSE ]]; then
            doc_count=$((doc_count + 1))
        # Check for test files
        elif [[ "$file" =~ ^tests?/ ]] || [[ "$file" =~ \.(test|spec)\. ]] || [[ "$file" =~ [_-](test|spec)\. ]] || [[ "$file" =~ __tests?__/ ]]; then
            test_count=$((test_count + 1))
        # Check for config files
        elif [[ "$file" =~ \.(json|ya?ml|toml|ini|conf|config)$ ]] || [[ "$file" =~ ^\..*rc$ ]] || [[ "$file" =~ package\.json|setup\.py|Cargo\.toml|go\.mod ]]; then
            config_count=$((config_count + 1))
        else
            code_count=$((code_count + 1))
        fi
    done <<< "$changed_files"

    # Return early if no files detected
    [ $total_count -eq 0 ] && return

    # If only docs changed, suggest docs
    if [ $doc_count -gt 0 ] && [ $test_count -eq 0 ] && [ $code_count -eq 0 ]; then
        echo "docs"
        return
    fi

    # If only tests changed, suggest test
    if [ $test_count -gt 0 ] && [ $doc_count -eq 0 ] && [ $code_count -eq 0 ]; then
        echo "test"
        return
    fi

    # Check for version bumps in config files
    if [ $config_count -gt 0 ]; then
        if echo "$diff" | grep -qE '^\+.*"version".*:' || \
           echo "$diff" | grep -qE '^\+.*version\s*='; then
            echo "chore"
            return
        fi
    fi

    # Check for bug-related keywords in diff
    if echo "$diff" | grep -qiE '^\+.*(fix|bug|issue|error|crash|problem|broken|incorrect|wrong)'; then
        echo "fix"
        return
    fi

    # No strong signal detected
    echo ""
}

# Run smart type detection
SMART_TYPE=$(detect_smart_type "$GIT_STATUS" "$GIT_DIFF")

# Track where the suggestion came from for better prompting
TYPE_SOURCE=""
if [ -n "$SUGGESTED_TYPE" ]; then
    TYPE_SOURCE="branch name"
fi

# Smart type detection can override if branch gives no suggestion
if [ -z "$SUGGESTED_TYPE" ] && [ -n "$SMART_TYPE" ]; then
    SUGGESTED_TYPE="$SMART_TYPE"
    TYPE_SOURCE="file analysis"
elif [ -n "$SMART_TYPE" ] && [ "$SMART_TYPE" != "$SUGGESTED_TYPE" ]; then
    # Both exist but differ - mention both in context
    TYPE_SOURCE="branch name (smart detection also suggests: $SMART_TYPE)"
fi

# Override with forced type if provided
if [ -n "$FORCED_TYPE" ]; then
    SUGGESTED_TYPE="$FORCED_TYPE"
    TYPE_SOURCE="user-specified via --type flag"
fi

# Detect breaking changes
detect_breaking_changes() {
    local diff="$1"
    local breaking_detected=false
    local breaking_reason=""

    # Check for explicit breaking change keywords in diff
    if echo "$diff" | grep -qiE '^\+.*(BREAKING CHANGE|breaking change|BREAKING:|breaking:)'; then
        breaking_detected=true
        breaking_reason="explicit breaking change keyword in diff"
        echo "true|$breaking_reason"
        return
    fi

    # Check for removal of public APIs/exports
    # Look for lines being removed that contain export, public, or function definitions
    if echo "$diff" | grep -qE '^-.*\b(export (function|class|const|let|var|default|interface|type)|public (class|function|static|final)|def [a-zA-Z_]|function [a-zA-Z_])'; then
        breaking_detected=true
        breaking_reason="removal of public API/function"
        echo "true|$breaking_reason"
        return
    fi

    # Check for major version bumps (0.x.x -> 1.0.0, 1.x.x -> 2.0.0, etc.)
    # Look for version changes in package.json, setup.py, Cargo.toml, etc.
    local old_version=$(echo "$diff" | grep -E '^-.*"version".*:|^-.*version\s*=' | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -1)
    local new_version=$(echo "$diff" | grep -E '^\+.*"version".*:|^\+.*version\s*=' | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | head -1)

    if [ -n "$old_version" ] && [ -n "$new_version" ]; then
        local old_major=$(echo "$old_version" | cut -d. -f1)
        local new_major=$(echo "$new_version" | cut -d. -f1)

        if [ "$new_major" -gt "$old_major" ]; then
            breaking_detected=true
            breaking_reason="major version bump ($old_version -> $new_version)"
            echo "true|$breaking_reason"
            return
        fi
    fi

    # Check for signature changes (parameter removal/change)
    # Only flag if we can identify the SAME function being modified
    # Look for function name patterns to ensure we're comparing the same function
    local removed_functions=$(echo "$diff" | grep -E '^-.*\b(function |def |const |let |var |export (function|const|let|var)) [a-zA-Z_][a-zA-Z0-9_]*\s*\(' | sed 's/^-.*\b\(function\|def\|const\|let\|var\|export\) \+\([a-zA-Z_][a-zA-Z0-9_]*\).*/\2/' | sort)
    local added_functions=$(echo "$diff" | grep -E '^\+.*\b(function |def |const |let |var |export (function|const|let|var)) [a-zA-Z_][a-zA-Z0-9_]*\s*\(' | sed 's/^\+.*\b\(function\|def\|const\|let\|var\|export\) \+\([a-zA-Z_][a-zA-Z0-9_]*\).*/\2/' | sort)

    # Find functions that appear in both removed and added (same name = modified function)
    local modified_functions=$(comm -12 <(echo "$removed_functions") <(echo "$added_functions") 2>/dev/null)

    if [ -n "$modified_functions" ]; then
        # Found functions with same name being modified - check if parameters reduced
        while IFS= read -r func_name; do
            [ -z "$func_name" ] && continue

            local removed_sig=$(echo "$diff" | grep -E "^-.*\b(function |def |const |let |var |export .*) ${func_name}\s*\(" | head -1)
            local added_sig=$(echo "$diff" | grep -E "^\+.*\b(function |def |const |let |var |export .*) ${func_name}\s*\(" | head -1)

            if [ -n "$removed_sig" ] && [ -n "$added_sig" ]; then
                # Extract parameter lists
                local removed_params=$(echo "$removed_sig" | grep -oE '\([^)]*\)' | head -1)
                local added_params=$(echo "$added_sig" | grep -oE '\([^)]*\)' | head -1)

                # Count parameters (rough heuristic using commas)
                local old_count=$(echo "$removed_params" | tr -cd ',' | wc -c)
                local new_count=$(echo "$added_params" | tr -cd ',' | wc -c)

                # Only flag if parameters were removed (breaking change)
                if [ "$new_count" -lt "$old_count" ]; then
                    breaking_detected=true
                    breaking_reason="function '${func_name}' signature changed (parameters reduced)"
                    echo "true|$breaking_reason"
                    return
                fi
            fi
        done <<< "$modified_functions"
    fi

    echo "false|"
}

# Run breaking change detection (skip for docs-only commits - no code changes)
if [ "$SMART_TYPE" = "docs" ]; then
    # Docs-only commits can't have breaking changes
    BREAKING_RESULT="false|"
else
    BREAKING_RESULT=$(detect_breaking_changes "$GIT_DIFF")
fi
IS_BREAKING=$(echo "$BREAKING_RESULT" | cut -d'|' -f1)
BREAKING_REASON=$(echo "$BREAKING_RESULT" | cut -d'|' -f2)

# Analyze commit history to learn repository patterns
analyze_commit_history() {
    # Check if we should learn from history
    if [ "$LEARN_FROM_HISTORY" != "true" ]; then
        echo ""
        return
    fi

    # Check cache first (keyed by latest commit hash)
    local latest_commit=$(git rev-parse HEAD 2>/dev/null || echo "")
    if [ -n "$latest_commit" ]; then
        local cached=$(get_cache "commit-history-${latest_commit}" 3600 2>/dev/null)
        if [ $? -eq 0 ] && [ -n "$cached" ]; then
            echo "$cached"
            return
        fi
    fi

    # Get last 50 commits (or less if repo is new)
    local commits=$(git log --pretty=format:"%s" -n 50 2>/dev/null)

    if [ -z "$commits" ]; then
        echo ""
        return
    fi

    local total_commits=$(echo "$commits" | wc -l | LC_ALL=C tr -d ' ')

    # Return early if very few commits
    if [ "$total_commits" -lt 5 ]; then
        echo ""
        return
    fi

    # Detect emoji usage
    local emoji_count=$(echo "$commits" | grep -cE '[\x{1F600}-\x{1F64F}\x{1F300}-\x{1F5FF}\x{1F680}-\x{1F6FF}\x{1F1E0}-\x{1F1FF}\x{2600}-\x{26FF}\x{2700}-\x{27BF}]|:[a-z_]+:' 2>/dev/null || echo "0")
    local uses_emoji=false
    if [ "$emoji_count" -gt 0 ]; then
        uses_emoji=true
    fi

    # Detect scope usage (look for parentheses after type)
    local scope_count=$(echo "$commits" | grep -cE '^[a-z]+\([a-z]+\):' 2>/dev/null || echo "0")
    scope_count=$(echo "$scope_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local uses_scopes=false
    local scope_percentage=0
    if [ "$scope_count" -gt 0 ] 2>/dev/null; then
        uses_scopes=true
        scope_percentage=$((scope_count * 100 / total_commits))
    fi

    # Detect conventional commit types used
    local feat_count=$(echo "$commits" | grep -ciE '^feat[(!:]' 2>/dev/null || echo "0")
    feat_count=$(echo "$feat_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local fix_count=$(echo "$commits" | grep -ciE '^fix[(!:]' 2>/dev/null || echo "0")
    fix_count=$(echo "$fix_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local docs_count=$(echo "$commits" | grep -ciE '^docs[(!:]' 2>/dev/null || echo "0")
    docs_count=$(echo "$docs_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local chore_count=$(echo "$commits" | grep -ciE '^chore[(!:]' 2>/dev/null || echo "0")
    chore_count=$(echo "$chore_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local refactor_count=$(echo "$commits" | grep -ciE '^refactor[(!:]' 2>/dev/null || echo "0")
    refactor_count=$(echo "$refactor_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local test_count=$(echo "$commits" | grep -ciE '^test[(!:]' 2>/dev/null || echo "0")
    test_count=$(echo "$test_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local style_count=$(echo "$commits" | grep -ciE '^style[(!:]' 2>/dev/null || echo "0")
    style_count=$(echo "$style_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')

    # Detect capitalization preference (first word after type)
    local lowercase_count=$(echo "$commits" | grep -cE '^[a-z]+(\([a-z]+\))?!?: [a-z]' 2>/dev/null || echo "0")
    lowercase_count=$(echo "$lowercase_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local uppercase_count=$(echo "$commits" | grep -cE '^[a-z]+(\([a-z]+\))?!?: [A-Z]' 2>/dev/null || echo "0")
    uppercase_count=$(echo "$uppercase_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local prefers_lowercase=true
    if [ "$uppercase_count" -gt "$lowercase_count" ] 2>/dev/null; then
        prefers_lowercase=false
    fi

    # Detect breaking change usage
    local breaking_count=$(echo "$commits" | grep -cE '!:' 2>/dev/null || echo "0")
    breaking_count=$(echo "$breaking_count" | LC_ALL=C tr -d '\n' | LC_ALL=C tr -d ' ')
    local uses_breaking_changes=false
    if [ "$breaking_count" -gt 0 ]; then
        uses_breaking_changes=true
    fi

    # Build history insights
    local insights="Repository commit style (based on last $total_commits commits):"

    # Report scope usage
    if [ "$uses_scopes" = "true" ]; then
        insights="$insights\n- Uses scopes in ${scope_percentage}% of commits"
    else
        insights="$insights\n- Rarely uses scopes"
    fi

    # Report type preferences
    local most_common_type="feat"
    local max_count=$feat_count
    [ "$fix_count" -gt "$max_count" ] 2>/dev/null && most_common_type="fix" && max_count=$fix_count
    [ "$docs_count" -gt "$max_count" ] 2>/dev/null && most_common_type="docs" && max_count=$docs_count
    [ "$chore_count" -gt "$max_count" ] 2>/dev/null && most_common_type="chore" && max_count=$chore_count

    insights="$insights\n- Most common type: $most_common_type"

    # Report capitalization
    if [ "$prefers_lowercase" = "true" ]; then
        insights="$insights\n- Prefers lowercase commit messages"
    else
        insights="$insights\n- Uses capitalized commit messages"
    fi

    # Report emoji usage
    if [ "$uses_emoji" = "true" ]; then
        insights="$insights\n- Sometimes uses emojis"
    fi

    # Report breaking change usage
    if [ "$uses_breaking_changes" = "true" ]; then
        insights="$insights\n- Uses breaking change notation (!) when appropriate"
    fi

    insights="$insights\n\nMatch this repository's style in your commit message."

    # Cache the result
    if [ -n "$latest_commit" ]; then
        set_cache "commit-history-${latest_commit}" "$insights" 2>/dev/null
    fi

    echo -e "$insights"
}

# Detect WordPress plugin/theme updates
# Returns "plugin:name" or "theme:name" if any files are in plugin/theme directories
detect_wordpress_plugin_update() {
    local files="$1"
    local plugin_names=()
    local theme_names=()

    # Parse each filename and check if it's in a plugin/theme directory
    while IFS= read -r line; do
        # Skip empty lines
        [ -z "$line" ] && continue

        # Extract filename (remove git status prefix like "M " or "A ")
        local file=$(echo "$line" | awk '{print $NF}')

        # Convert to lowercase for pattern matching
        local file_lower=$(echo "$file" | tr '[:upper:]' '[:lower:]')

        # Check if file is in wp-content/plugins/
        if [[ "$file_lower" =~ wp-content/plugins/([^/]+) ]]; then
            local plugin_name="${BASH_REMATCH[1]}"

            # Add plugin name to array if not already there
            if [[ ! " ${plugin_names[@]} " =~ " ${plugin_name} " ]]; then
                plugin_names+=("$plugin_name")
            fi
        fi

        # Check if file is in wp-content/themes/
        if [[ "$file_lower" =~ wp-content/themes/([^/]+) ]]; then
            local theme_name="${BASH_REMATCH[1]}"

            # Add theme name to array if not already there
            if [[ ! " ${theme_names[@]} " =~ " ${theme_name} " ]]; then
                theme_names+=("$theme_name")
            fi
        fi
    done <<< "$files"

    # If any plugin files found, return plugin names (comma-separated if multiple)
    if [ ${#plugin_names[@]} -gt 0 ]; then
        # Join plugin names with commas
        local plugin_list=$(IFS=,; echo "${plugin_names[*]}")
        echo "plugin:${plugin_list}"
        return 0
    fi

    # If any theme files found, return theme names (comma-separated if multiple)
    if [ ${#theme_names[@]} -gt 0 ]; then
        # Join theme names with commas
        local theme_list=$(IFS=,; echo "${theme_names[*]}")
        echo "theme:${theme_list}"
        return 0
    fi

    return 1
}

# Extract semantic context from changed filenames
extract_file_context() {
    local files="$1"
    local contexts=()

    # Parse each filename and extract semantic meaning
    while IFS= read -r line; do
        # Skip empty lines
        [ -z "$line" ] && continue

        # Extract filename (remove git status prefix like "M " or "A ")
        local file=$(echo "$line" | awk '{print $NF}')

        # Convert to lowercase for pattern matching
        local file_lower=$(echo "$file" | tr '[:upper:]' '[:lower:]')

        # Extract context based on filename patterns
        case "$file_lower" in
            *video*) contexts+=("video handling") ;;
            *audio*|*sound*|*music*) contexts+=("audio processing") ;;
            *image*|*photo*|*picture*|*img*) contexts+=("image handling") ;;
            *auth*|*login*|*signin*|*signup*) contexts+=("authentication") ;;
            *user*|*profile*|*account*) contexts+=("user management") ;;
            *payment*|*checkout*|*billing*|*invoice*) contexts+=("payment processing") ;;
            *order*|*cart*|*shopping*) contexts+=("order management") ;;
            *product*|*catalog*|*inventory*) contexts+=("product catalog") ;;
            *email*|*mail*|*notification*) contexts+=("email/notifications") ;;
            *report*|*analytics*|*dashboard*) contexts+=("reporting/analytics") ;;
            *search*|*query*|*filter*) contexts+=("search functionality") ;;
            *upload*|*download*|*file*) contexts+=("file handling") ;;
            *api/*|*endpoint*|*route*) contexts+=("API endpoints") ;;
            *component*/*|*components/*) contexts+=("UI components") ;;
            *database*|*db/*|*migration*|*schema*) contexts+=("database") ;;
            *model*/*|*models/*) contexts+=("data models") ;;
            *service*/*|*services/*) contexts+=("services layer") ;;
            *controller*/*|*controllers/*) contexts+=("controllers") ;;
            *view*/*|*views/*|*template*) contexts+=("views/templates") ;;
            *test*|*spec*|*.test.*|*.spec.*) contexts+=("tests") ;;
            *doc*|*readme*) contexts+=("documentation") ;;
            *config*|*.json|*.yml|*.yaml|*.toml) contexts+=("configuration") ;;
            *security*|*permission*|*role*) contexts+=("security/permissions") ;;
            *cache*|*redis*|*memcache*) contexts+=("caching") ;;
            *queue*|*job*|*worker*) contexts+=("background jobs") ;;
            *webhook*|*callback*|*integration*) contexts+=("integrations") ;;
            *export*|*import*) contexts+=("data import/export") ;;
        esac

        # Domain-specific patterns
        # Laravel
        case "$file_lower" in
            *controller.php) contexts+=("Laravel controller") ;;
            *model.php|app/models/*) contexts+=("Laravel model") ;;
            database/migrations/*) contexts+=("Laravel migration") ;;
            *middleware.php|app/http/middleware/*) contexts+=("Laravel middleware") ;;
            *request.php|app/http/requests/*) contexts+=("Laravel request validation") ;;
            *seeder.php|database/seeders/*) contexts+=("Laravel seeder") ;;
            *provider.php|app/providers/*) contexts+=("Laravel service provider") ;;
            resources/views/*) contexts+=("Laravel Blade views") ;;
        esac

        # React/Vue/Angular
        case "$file_lower" in
            *component.tsx|*component.jsx) contexts+=("React component") ;;
            *.tsx|*.jsx) contexts+=("React/TypeScript") ;;
            *hook*.ts|*hook*.js|use*.ts|use*.js) contexts+=("React hooks") ;;
            *.vue) contexts+=("Vue component") ;;
            *component.ts|*component.js) contexts+=("Angular component") ;;
            *service.ts|*service.js) contexts+=("Angular service") ;;
            *module.ts) contexts+=("Angular/NestJS module") ;;
        esac

        # WordPress
        case "$file_lower" in
            wp-content/themes/*)
                # Extract theme name from path
                if [[ "$file_lower" =~ wp-content/themes/([^/]+) ]]; then
                    local theme_name="${BASH_REMATCH[1]}"
                    contexts+=("$theme_name theme")
                else
                    contexts+=("WordPress theme")
                fi
                ;;
            wp-content/plugins/*)
                # Extract plugin name from path
                if [[ "$file_lower" =~ wp-content/plugins/([^/]+) ]]; then
                    local plugin_name="${BASH_REMATCH[1]}"
                    contexts+=("$plugin_name plugin")
                else
                    contexts+=("WordPress plugin")
                fi
                ;;
            *functions.php) contexts+=("WordPress theme functions") ;;
            wp-admin/*) contexts+=("WordPress admin") ;;
        esac

        # Django/Flask
        case "$file_lower" in
            */views.py) contexts+=("Django/Flask views") ;;
            */models.py) contexts+=("Django models") ;;
            */serializers.py) contexts+=("Django serializers") ;;
            */forms.py) contexts+=("Django forms") ;;
            */urls.py) contexts+=("Django URL routing") ;;
        esac

        # Ruby on Rails
        case "$file_lower" in
            *_controller.rb|app/controllers/*) contexts+=("Rails controller") ;;
            *_model.rb|app/models/*) contexts+=("Rails model") ;;
            db/migrate/*) contexts+=("Rails migration") ;;
            *_helper.rb|app/helpers/*) contexts+=("Rails helper") ;;
        esac

        # Docker/DevOps
        case "$file_lower" in
            dockerfile|*dockerfile*) contexts+=("Docker configuration") ;;
            docker-compose.yml|docker-compose.yaml) contexts+=("Docker Compose") ;;
            .github/workflows/*|.gitlab-ci.yml) contexts+=("CI/CD pipeline") ;;
            kubernetes/*|k8s/*|*.yaml|*.yml) contexts+=("Kubernetes config") ;;
        esac

        # Also extract from directory names
        if [[ "$file_lower" == *"/"* ]]; then
            local dir=$(dirname "$file_lower")
            local base=$(basename "$dir")
            case "$base" in
                video*|videos) contexts+=("video handling") ;;
                audio*|sounds|music) contexts+=("audio processing") ;;
                image*|images|photos) contexts+=("image handling") ;;
                auth*|authentication) contexts+=("authentication") ;;
                user*|users|profiles) contexts+=("user management") ;;
                payment*|payments|billing) contexts+=("payment processing") ;;
                order*|orders) contexts+=("order management") ;;
                product*|products) contexts+=("product catalog") ;;
                api|apis) contexts+=("API endpoints") ;;
                admin*|dashboard) contexts+=("admin dashboard") ;;
            esac
        fi
    done <<< "$files"

    # Return unique contexts as comma-separated string
    if [ ${#contexts[@]} -gt 0 ]; then
        printf '%s\n' "${contexts[@]}" | sort -u | paste -sd ", " -
    fi
}

# Extract function and class names from diff
extract_changed_functions() {
    local diff="$1"
    local functions=()

    # Extract function names from various languages
    # PHP: function name() or public function name()
    while IFS= read -r line; do
        if [[ "$line" =~ ^\+.*function[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*) ]]; then
            functions+=("${BASH_REMATCH[1]}()")
        fi
    done <<< "$diff"

    # Python: def name(
    while IFS= read -r line; do
        if [[ "$line" =~ ^\+.*def[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*) ]]; then
            functions+=("${BASH_REMATCH[1]}()")
        fi
    done <<< "$diff"

    # JavaScript/TypeScript: function name( or const name = function
    while IFS= read -r line; do
        if [[ "$line" =~ ^\+.*(const|let|var)[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*)[[:space:]]*= ]] || \
           [[ "$line" =~ ^\+.*function[[:space:]]+([a-zA-Z_][a-zA-Z0-9_]*) ]]; then
            local name="${BASH_REMATCH[2]:-${BASH_REMATCH[1]}}"
            [[ "$name" != "const" && "$name" != "let" && "$name" != "var" ]] && functions+=("${name}()")
        fi
    done <<< "$diff"

    # Class names: class ClassName
    while IFS= read -r line; do
        if [[ "$line" =~ ^\+.*class[[:space:]]+([A-Z][a-zA-Z0-9_]*) ]]; then
            functions+=("${BASH_REMATCH[1]}")
        fi
    done <<< "$diff"

    # Return unique function/class names (limit to first 8 to avoid clutter)
    if [ ${#functions[@]} -gt 0 ]; then
        local result=$(printf '%s\n' "${functions[@]}" | sort -u | head -8 | paste -sd "," -)
        echo "$result" | sed 's/,/, /g'
    fi
}

# Extract WordPress function calls from diff
extract_wordpress_function_calls() {
    local diff="$1"

    # Whitelist of important WordPress functions to detect
    local wp_functions="register_post_type|register_taxonomy|add_action|add_filter|wp_enqueue_script|wp_enqueue_style|register_nav_menu|add_theme_support|register_sidebar|register_widget"

    # Extract function calls with first argument
    # Pattern: +.*function_name('argument' or "argument")
    local functions=$(echo "$diff" | grep -E "^\+.*(${wp_functions})\(" | \
        sed -E "s/.*($wp_functions)[^'\"]*['\"]([^'\"]+)['\"].*/\1:\2/" | \
        grep ":" | \
        sort -u | \
        head -10)

    # Return comma-separated format (function_name:arg_value,...)
    if [ -n "$functions" ]; then
        echo "$functions" | tr '\n' ',' | sed 's/,$//'
    fi
}

# Look up WordPress function documentation (local database first, then API)
lookup_wordpress_function() {
    local function_name="$1"

    # Cache directory for WordPress function documentation
    local cache_dir="/tmp/gh-commit-ai-wp-docs-cache"
    local cache_file="$cache_dir/$function_name"

    # Check cache first to avoid repeated lookups
    if [ -f "$cache_file" ]; then
        cat "$cache_file"
        return
    fi

    # Check local database first (fast, no network required)
    local script_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
    local local_db="${script_dir}/data/wordpress-functions.txt"

    # If installed via gh extension, try extension directory
    if [ ! -f "$local_db" ]; then
        local_db="${HOME}/.local/share/gh/extensions/gh-commit-ai/data/wordpress-functions.txt"
    fi

    # If installed via homebrew, try homebrew directory
    if [ ! -f "$local_db" ] && command -v brew &>/dev/null; then
        local brew_prefix=$(brew --prefix 2>/dev/null)
        local_db="${brew_prefix}/opt/gh-commit-ai/data/wordpress-functions.txt"
    fi

    if [ -f "$local_db" ]; then
        # Look up function in local database (format: function_name|description)
        local description=$(grep "^${function_name}|" "$local_db" | cut -d'|' -f2-)
        if [ -n "$description" ]; then
            # Cache the result
            mkdir -p "$cache_dir"
            echo "$description" > "$cache_file"
            echo "$description"
            return
        fi
    fi

    # Fallback to API for uncommon functions (with reduced timeout)
    local url="https://developer.wordpress.org/wp-json/wp/v2/wp-parser-function?slug=$function_name"
    local response=$(curl -s --connect-timeout 1 --max-time 2 "$url" 2>/dev/null)

    # Parse JSON response (no jq dependency - use grep/sed)
    # Extract description from excerpt field, strip HTML tags
    local description=$(echo "$response" | \
        grep -o '"rendered":"<p>[^<]*' | \
        sed 's/"rendered":"<p>//' | \
        head -1)

    # Cache the result if successful
    if [ -n "$description" ]; then
        mkdir -p "$cache_dir"
        echo "$description" > "$cache_file"
        echo "$description"
    fi
}

# Build WordPress context from function calls and documentation
build_wordpress_context() {
    local wp_function_calls="$1"

    if [ -z "$wp_function_calls" ]; then
        return
    fi

    local context="ðŸš¨ WORDPRESS FUNCTIONS DETECTED - READ THIS FIRST ðŸš¨\n\n"
    local first_func=""
    local first_arg=""

    # Parse comma-separated function calls
    IFS=',' read -ra CALLS <<< "$wp_function_calls"
    for call in "${CALLS[@]}"; do
        [ -z "$call" ] && continue

        # Split function_name:arg_value
        IFS=':' read -r func_name arg_value <<< "$call"

        # Save first function for example
        if [ -z "$first_func" ]; then
            first_func="$func_name"
            first_arg="$arg_value"
        fi

        # Look up function documentation from API
        local func_desc=$(lookup_wordpress_function "$func_name")

        # Build context line with function, argument, and description
        if [ -n "$func_desc" ]; then
            context="${context}${func_name}('${arg_value}'): ${func_desc}\n"
        else
            # Fallback if API lookup fails
            context="${context}${func_name}('${arg_value}')\n"
        fi
    done

    # Add immediate instructions using the detected function
    if [ -n "$first_func" ]; then
        context="${context}\nâš ï¸ YOUR SUMMARY LINE MUST USE THE FUNCTION NAME ABOVE:\n"
        if [ "$first_func" = "register_post_type" ]; then
            context="${context}  âœ“ CORRECT: 'feat: register ${first_arg} custom post type'\n"
            context="${context}  âœ— WRONG: 'feat: update ${first_arg} post type fields'\n"
        elif [ "$first_func" = "register_taxonomy" ]; then
            context="${context}  âœ“ CORRECT: 'feat: add ${first_arg} taxonomy'\n"
            context="${context}  âœ— WRONG: 'feat: update ${first_arg} taxonomy fields'\n"
        else
            context="${context}  âœ“ Start with: 'feat: ${first_func} ${first_arg}...'\n"
            context="${context}  âœ— Do NOT start with: 'feat: update...'\n"
        fi
        context="${context}Write what is being REGISTERED/ADDED, not what is being 'updated'.\n"
    fi

    echo -e "$context"
}

# Extract best commit examples from repository history
get_best_commit_examples() {
    # Check cache first (keyed by latest commit hash)
    local latest_commit=$(git rev-parse HEAD 2>/dev/null || echo "")
    if [ -n "$latest_commit" ]; then
        local cached=$(get_cache "commit-examples-${latest_commit}" 3600 2>/dev/null)
        if [ $? -eq 0 ] && [ -n "$cached" ]; then
            echo "$cached"
            return
        fi
    fi

    # Get last 100 commits with subject and body
    local commits=$(git log --pretty=format:"%s|||%b" -100 2>/dev/null)

    [ -z "$commits" ] && return

    local examples=""
    local count=0
    local max_examples=2

    # Find well-formed commits with bullets and proper conventional format
    while IFS='|||' read -r subject body; do
        # Check if has proper format and bullets
        if [[ "$subject" =~ ^(feat|fix|docs|refactor|test|chore|perf|style) ]] && \
           [[ "$body" == *"- "* ]]; then
            # This is a good example
            if [ $count -eq 0 ]; then
                examples="EXAMPLES FROM THIS REPOSITORY:"
            fi

            examples="$examples

$subject
$body"

            count=$((count + 1))
            [ $count -ge $max_examples ] && break
        fi
    done <<< "$commits"

    if [ -n "$examples" ]; then
        # Cache the result
        if [ -n "$latest_commit" ]; then
            set_cache "commit-examples-${latest_commit}" "$examples" 2>/dev/null
        fi
        echo "$examples"
    fi
}

# Analyze the type of changes in the diff (semantic analysis)
analyze_change_type() {
    local diff="$1"
    local change_types=()

    # Count additions vs deletions
    local adds=$(echo "$diff" | grep -c "^+" 2>/dev/null)
    local dels=$(echo "$diff" | grep -c "^-" 2>/dev/null)

    # Ensure numeric values (default to 0 if empty)
    adds=${adds:-0}
    dels=${dels:-0}

    # Detect error handling additions
    if echo "$diff" | grep -qE '^\+.*(throw new|try \{|catch|except:|raise )'; then
        change_types+=("added error handling")
    fi

    # Detect TODO/FIXME additions
    if echo "$diff" | grep -qE '^\+.*(TODO|FIXME|XXX|HACK)'; then
        change_types+=("added TODOs")
    fi

    # Detect logging additions
    if echo "$diff" | grep -qE '^\+.*(console\.log|logger\.|logging\.|log\.|print\()'; then
        change_types+=("added logging")
    fi

    # Detect test additions
    if echo "$diff" | grep -qE '^\+.*(it\(|test\(|describe\(|assert|expect\()'; then
        change_types+=("added tests")
    fi

    # Detect validation additions
    if echo "$diff" | grep -qE '^\+.*(validate|check|verify|assert|ensure).*\('; then
        change_types+=("added validation")
    fi

    # Detect API/endpoint changes
    if echo "$diff" | grep -qE '^\+.*(route|endpoint|@RequestMapping|@GetMapping|@PostMapping|@app\.route)'; then
        change_types+=("added API endpoints")
    fi

    # Detect database/model changes
    if echo "$diff" | grep -qE '^\+.*(CREATE TABLE|ALTER TABLE|migration|Schema::|add_column|create_table)'; then
        change_types+=("database schema changes")
    fi

    # Detect code removal (refactoring)
    if [ "$dels" -gt 0 ] && [ "$adds" -gt 0 ] && [ "$dels" -gt $((adds * 2)) ]; then
        change_types+=("code removal/cleanup")
    fi

    # Detect new function/class additions
    if echo "$diff" | grep -qE '^\+.*(function |def |class |const .* = \()'; then
        change_types+=("new functions/classes")
    fi

    # Detect configuration changes
    if echo "$diff" | grep -qE '^\+.*(config|settings|env|ENV|CONST)'; then
        change_types+=("configuration updates")
    fi

    # Detect dependency changes
    if echo "$diff" | grep -qE '^\+.*(import |require\(|from .* import|include |use )'; then
        change_types+=("dependency changes")
    fi

    # Detect documentation
    if echo "$diff" | grep -qE '^\+.*(\/\*\*|"""|\* @|#.*:|<!-- )'; then
        change_types+=("documentation updates")
    fi

    # Return change types
    if [ ${#change_types[@]} -gt 0 ]; then
        local result=$(printf '%s\n' "${change_types[@]}" | sort -u | paste -sd "," -)
        echo "$result" | sed 's/,/, /g'
    fi
}

# Generate per-file change summaries
generate_file_summaries() {
    local status="$1"
    local summaries=""
    local count=0
    local max_files=5

    # Use git diff --numstat for accurate per-file statistics
    # Format: <added lines> <deleted lines> <filename>
    local numstat
    if [ "$AMEND_MODE" = "true" ]; then
        numstat=$(git show HEAD --numstat --format="" 2>/dev/null)
    else
        numstat=$(git diff --cached --numstat 2>/dev/null)
    fi

    # Parse git status to get changed files
    while IFS= read -r line; do
        [ -z "$line" ] && continue
        [ "$count" -ge "$max_files" ] && break

        # Extract status and filename
        local file_status=$(echo "$line" | awk '{print $1}')
        local file=$(echo "$line" | awk '{print $NF}')

        # Skip if empty
        [ -z "$file" ] && continue

        # Get stats from numstat for this file
        local adds=0
        local dels=0
        local stats=$(echo "$numstat" | grep -F "$file" | head -1)
        if [ -n "$stats" ]; then
            adds=$(echo "$stats" | awk '{print $1}')
            dels=$(echo "$stats" | awk '{print $2}')

            # Handle binary files (marked with -)
            [ "$adds" = "-" ] && adds=0
            [ "$dels" = "-" ] && dels=0
        fi

        # Ensure numeric values (default to 0 if empty)
        adds=${adds:-0}
        dels=${dels:-0}

        # Create summary
        local action=""
        case "$file_status" in
            A) action="new file" ;;
            M) action="modified" ;;
            D) action="deleted" ;;
            R) action="renamed" ;;
            *) action="changed" ;;
        esac

        # Only show files with significant changes
        if [ "$adds" -gt 2 ] || [ "$dels" -gt 2 ] || [ "$file_status" = "A" ] || [ "$file_status" = "D" ]; then
            if [ -z "$summaries" ]; then
                summaries="FILE SUMMARIES:"
            fi
            summaries="$summaries
- $file: $action (+$adds/-$dels lines)"
            count=$((count + 1))
        fi
    done <<< "$status"

    echo "$summaries"
}

# Detect relationships between changed files
detect_file_relationships() {
    local files="$1"
    local relationships=()

    # Convert to lowercase for matching
    local files_lower=$(echo "$files" | tr '[:upper:]' '[:lower:]')

    # Migration + Model pattern
    if echo "$files_lower" | grep -q "migration" && echo "$files_lower" | grep -qE "(model|schema)"; then
        relationships+=("database migration with model changes")
    fi

    # Test + Source pattern
    local has_test=$(echo "$files_lower" | grep -cE "(test|spec)" 2>/dev/null)
    local total_files=$(echo "$files" | wc -l | tr -d ' ')

    # Ensure numeric values
    has_test=${has_test:-0}
    total_files=${total_files:-0}

    if [ "$has_test" -gt 0 ] && [ "$total_files" -gt "$has_test" ]; then
        relationships+=("includes test coverage")
    fi

    # Component + Style pattern
    if echo "$files_lower" | grep -qE "\.(tsx|jsx|vue)" && echo "$files_lower" | grep -qE "\.(css|scss|sass|less)"; then
        relationships+=("component with styling changes")
    fi

    # Controller + View pattern
    if echo "$files_lower" | grep -q "controller" && echo "$files_lower" | grep -qE "(view|template)"; then
        relationships+=("controller and view updates")
    fi

    # API + Documentation pattern
    if echo "$files_lower" | grep -qE "(api|endpoint|route)" && echo "$files_lower" | grep -qE "(readme|doc|swagger)"; then
        relationships+=("API changes with documentation")
    fi

    # Config + Code pattern
    if echo "$files_lower" | grep -qE "(config|\.env|settings)" && echo "$files" | wc -l | awk '{if ($1 > 1) print "yes"}' | grep -q "yes"; then
        relationships+=("configuration changes with code")
    fi

    # Docker + CI pattern
    if echo "$files_lower" | grep -qE "(dockerfile|docker-compose)" && echo "$files_lower" | grep -qE "(\.github|\.gitlab|jenkins|ci)"; then
        relationships+=("Docker and CI/CD updates")
    fi

    # Return relationships
    if [ ${#relationships[@]} -gt 0 ]; then
        printf '%s\n' "${relationships[@]}" | paste -sd ", " -
    fi
}

# ============================================================================
# PARALLEL ANALYSIS - Run all analysis functions simultaneously for speed
# ============================================================================

# Create temp files for parallel job outputs
TEMP_HISTORY="${CACHE_DIR}/temp_history_$$"
TEMP_EXAMPLES="${CACHE_DIR}/temp_examples_$$"
TEMP_CONTEXTS="${CACHE_DIR}/temp_contexts_$$"
TEMP_FUNCTIONS="${CACHE_DIR}/temp_functions_$$"
TEMP_CHANGES="${CACHE_DIR}/temp_changes_$$"
TEMP_SUMMARIES="${CACHE_DIR}/temp_summaries_$$"
TEMP_RELATIONSHIPS="${CACHE_DIR}/temp_relationships_$$"
TEMP_WP_FUNCTIONS="${CACHE_DIR}/temp_wp_functions_$$"

# Determine if this is a small commit that can skip expensive analysis
SKIP_EXPENSIVE_ANALYSIS=false
COMMIT_SIZE_INT=$(echo "${COMMIT_SIZE:-0}" | tr -d ' ')
if [ "$COMMIT_SIZE_INT" -lt "$ANALYSIS_THRESHOLD" ] && [ "$COMMIT_SIZE_INT" -gt 0 ]; then
    SKIP_EXPENSIVE_ANALYSIS=true
fi

# Spawn all analysis jobs in parallel (background)
# Skip expensive operations for small commits to improve speed
if [ "$LEARN_FROM_HISTORY" = "true" ]; then
    analyze_commit_history > "$TEMP_HISTORY" 2>/dev/null &
    get_best_commit_examples > "$TEMP_EXAMPLES" 2>/dev/null &
fi

# Lightweight analysis (always run)
extract_file_context "$GIT_STATUS" > "$TEMP_CONTEXTS" 2>/dev/null &
generate_file_summaries "$GIT_STATUS" > "$TEMP_SUMMARIES" 2>/dev/null &

# Expensive analysis (skip for small commits)
if [ "$SKIP_EXPENSIVE_ANALYSIS" = false ]; then
    extract_changed_functions "$GIT_DIFF" > "$TEMP_FUNCTIONS" 2>/dev/null &
    analyze_change_type "$GIT_DIFF" > "$TEMP_CHANGES" 2>/dev/null &
    detect_file_relationships "$GIT_STATUS" > "$TEMP_RELATIONSHIPS" 2>/dev/null &
    extract_wordpress_function_calls "$GIT_DIFF" > "$TEMP_WP_FUNCTIONS" 2>/dev/null &
fi

# Wait for all background jobs to complete
wait

# Read results from temp files
HISTORY_INSIGHTS=""
if [ "$LEARN_FROM_HISTORY" = "true" ] && [ -f "$TEMP_HISTORY" ]; then
    HISTORY_INSIGHTS=$(cat "$TEMP_HISTORY")
fi

REPO_EXAMPLES=""
if [ "$LEARN_FROM_HISTORY" = "true" ] && [ -f "$TEMP_EXAMPLES" ]; then
    REPO_EXAMPLES=$(cat "$TEMP_EXAMPLES")
    if [ -n "$REPO_EXAMPLES" ]; then
        REPO_EXAMPLES="

$REPO_EXAMPLES"
    fi
fi

FILE_CONTEXT=""
if [ -f "$TEMP_CONTEXTS" ]; then
    EXTRACTED_CONTEXTS=$(cat "$TEMP_CONTEXTS")
    if [ -n "$EXTRACTED_CONTEXTS" ]; then
        FILE_CONTEXT="
Detected code areas being modified: $EXTRACTED_CONTEXTS
Make sure your commit message reflects the specific area(s) being changed.
Analyze the diff content to understand the nature and purpose of the changes.
"
    fi
fi

FUNCTION_CONTEXT=""
if [ -f "$TEMP_FUNCTIONS" ]; then
    EXTRACTED_FUNCTIONS=$(cat "$TEMP_FUNCTIONS")
    if [ -n "$EXTRACTED_FUNCTIONS" ]; then
        FUNCTION_CONTEXT="
Modified functions/classes: $EXTRACTED_FUNCTIONS
Consider mentioning these in your commit message if they represent significant changes."
    fi
fi

SEMANTIC_ANALYSIS=""
if [ -f "$TEMP_CHANGES" ]; then
    CHANGE_TYPES=$(cat "$TEMP_CHANGES")
    if [ -n "$CHANGE_TYPES" ]; then
        SEMANTIC_ANALYSIS="
Type of changes detected: $CHANGE_TYPES"
    fi
fi

FILE_SUMMARIES=""
if [ -f "$TEMP_SUMMARIES" ]; then
    FILE_SUMMARIES=$(cat "$TEMP_SUMMARIES")
fi

FILE_RELATIONSHIPS=""
if [ -f "$TEMP_RELATIONSHIPS" ]; then
    DETECTED_RELATIONSHIPS=$(cat "$TEMP_RELATIONSHIPS")
    if [ -n "$DETECTED_RELATIONSHIPS" ]; then
        FILE_RELATIONSHIPS="
Related file changes: $DETECTED_RELATIONSHIPS"
    fi
fi

# Extract WordPress function calls and build context (for all WordPress projects)
# IMPORTANT: Must happen BEFORE cleanup since it reads from TEMP_WP_FUNCTIONS
WP_CONTEXT=""
if [ -f "$TEMP_WP_FUNCTIONS" ]; then
    WP_FUNCTION_CALLS=$(cat "$TEMP_WP_FUNCTIONS")
    if [ -n "$WP_FUNCTION_CALLS" ]; then
        WP_CONTEXT=$(build_wordpress_context "$WP_FUNCTION_CALLS")
    fi
fi

# Cleanup temp files (after reading WordPress functions)
rm -f "$TEMP_HISTORY" "$TEMP_EXAMPLES" "$TEMP_CONTEXTS" "$TEMP_FUNCTIONS" "$TEMP_CHANGES" "$TEMP_SUMMARIES" "$TEMP_RELATIONSHIPS" "$TEMP_WP_FUNCTIONS" 2>/dev/null

# Check for WordPress plugin/theme bulk update
WP_COMPONENT_TYPE=""
WP_COMPONENT_NAME=""
DETECTED_WP_COMPONENT=$(detect_wordpress_plugin_update "$GIT_STATUS" || true)
if [ $? -eq 0 ] && [ -n "$DETECTED_WP_COMPONENT" ]; then
    # Parse type:name format
    WP_COMPONENT_TYPE=$(echo "$DETECTED_WP_COMPONENT" | cut -d: -f1)
    WP_COMPONENT_NAME=$(echo "$DETECTED_WP_COMPONENT" | cut -d: -f2)
fi

# Define few-shot examples for better AI learning
FEW_SHOT_EXAMPLES="
EXAMPLES OF GOOD COMMIT MESSAGES (BE SPECIFIC LIKE THESE):

Example 1 - Video feature:
Input: Changed video.php, added uploadVideo() function
Output:
feat: add video upload with format validation

- implement uploadVideo() function
- add support for mp4, avi, mov formats
- validate file size and duration

Example 2 - Authentication:
Input: Modified auth/login.php, updated validateUser()
Output:
fix: resolve session timeout in user login

- increase session lifetime to 24 hours
- add automatic token refresh
- fix validateUser() edge case

Example 3 - Payment processing:
Input: Changed payment.php and invoice.php
Output:
fix: correct tax calculation in payment flow

- fix rounding error in calculateTax()
- update invoice generation logic
- add currency conversion handling

BAD EXAMPLES (AVOID THESE - TOO GENERIC):
âŒ 'fix: resolve bug'
âŒ 'update: change files'
âŒ 'feat: add feature'
âŒ 'chore: update code'

REMEMBER: Mention the SPECIFIC AREA (video, auth, payment, etc.) and WHAT changed (function names, features)."

# Prepare branch context
BRANCH_CONTEXT="Branch context:
- Branch name: $BRANCH_NAME"

if [ -n "$TICKET_NUMBER" ]; then
    BRANCH_CONTEXT="$BRANCH_CONTEXT
- Ticket number: $TICKET_NUMBER (include this in your commit message)"
fi

if [ -n "$SUGGESTED_TYPE" ]; then
    BRANCH_CONTEXT="$BRANCH_CONTEXT
- Suggested type: $SUGGESTED_TYPE (based on $TYPE_SOURCE)"
fi

if [ "$IS_BREAKING" = "true" ]; then
    BRANCH_CONTEXT="$BRANCH_CONTEXT
- BREAKING CHANGE DETECTED: $BREAKING_REASON"
fi

# Prepare closing instruction
CLOSING_INSTRUCTION="CRITICAL: Look at the filenames being changed and describe WHAT FEATURE/AREA is affected.
- If video.php is changed, mention 'video' in your summary (e.g., 'fix video upload', 'add video processing')
- If auth/login.php is changed, mention 'authentication' or 'login'
- If UserProfile.tsx is changed, mention 'user profile'
- Make your commit message SPECIFIC to what was actually worked on, not generic.

Think: What are all the changes? Then: What's the one-line summary that captures the specific area and all changes?"
if [ -n "$WP_CONTEXT" ]; then
    CLOSING_INSTRUCTION="$CLOSING_INSTRUCTION

ðŸš¨ CRITICAL - WORDPRESS FUNCTIONS DETECTED ðŸš¨
Your summary line MUST describe the WordPress functionality being added/modified.

REQUIRED format for summary line:
- register_post_type('research') â†’ feat: register research custom post type
- register_taxonomy('genre') â†’ feat: add genre taxonomy for [post type]
- add_action('init', ...) â†’ feat: add [what] initialization hook
- wp_enqueue_script('handle') â†’ feat: enqueue [handle] script

DO NOT write:
âŒ 'feat: update research post type fields'
âŒ 'feat: modify register function'
âŒ 'feat: update acf fields and register function'

The summary MUST start with the WordPress action (register/add/enqueue) and the specific thing being registered.
Your FIRST PRIORITY is describing the WordPress function being used."
fi
if [ -n "$TICKET_NUMBER" ]; then
    CLOSING_INSTRUCTION="$CLOSING_INSTRUCTION Include ticket as ($TICKET_NUMBER) after the type, like: feat: ($TICKET_NUMBER) summary text"
fi
if [ "$IS_BREAKING" = "true" ]; then
    CLOSING_INSTRUCTION="$CLOSING_INSTRUCTION This is a BREAKING CHANGE - add ! after type and include BREAKING CHANGE footer."
fi

# Prepare prompt with scope and gitmoji options
# Define gitmoji mappings
GITMOJI_INSTRUCTION=""
if [ "$USE_GITMOJI" = "true" ]; then
    GITMOJI_INSTRUCTION="
GITMOJI PREFIXES:
Add the appropriate emoji prefix before the type:
- âœ¨ feat: new feature
- ðŸ› fix: bug fix
- ðŸ“ docs: documentation
- ðŸ’„ style: formatting/styling
- â™»ï¸ refactor: code refactoring
- âœ… test: adding tests
- ðŸ”§ chore: tooling/config/maintenance
- ðŸš€ perf: performance improvement
- ðŸ”’ security: security fix"
fi

# Build format instruction based on USE_SCOPE and USE_GITMOJI
if [ "$USE_SCOPE" = "true" ] && [ "$USE_GITMOJI" = "true" ]; then
    SCOPE_INSTRUCTION="OUTPUT FORMAT (summary line MUST be first):
<emoji> <type>(<scope>): <concise summary of all changes below>
$GITMOJI_INSTRUCTION

The scope should be a short noun describing what part of the codebase changed:
- auth, api, ui, db, cli, docs, config, tests, deps, etc.
- Choose the most relevant scope based on which files/areas changed
- If changes span multiple areas, pick the primary one

BREAKING CHANGES (RARE - only for incompatible changes):
- ONLY add ! if this breaks existing functionality for users
- Examples: removing APIs, changing CLI flags, changing config format
- Bug fixes, new features, and refactors are NOT breaking changes
- If breaking, add ! after type: <emoji> <type>!(<scope>):
- Add a BREAKING CHANGE footer explaining what breaks"
    SCOPE_EXAMPLES="Examples (note: most commits should NOT have !):
- âœ¨ feat(auth): add JWT token validation
- âœ¨ feat(auth): (ABC-123) add JWT token validation
- ðŸ› fix(api): resolve timeout in user endpoint
- ðŸ› fix(api): (JIRA-456) resolve timeout in user endpoint
- âœ¨ feat!(api): remove legacy login endpoint

BREAKING CHANGE: Legacy /auth/login endpoint removed, use /auth/v2/login instead"
elif [ "$USE_SCOPE" = "true" ]; then
    SCOPE_INSTRUCTION="OUTPUT FORMAT (summary line MUST be first):
<type>(<scope>): <concise summary of all changes below>

The scope should be a short noun describing what part of the codebase changed:
- auth, api, ui, db, cli, docs, config, tests, deps, etc.
- Choose the most relevant scope based on which files/areas changed
- If changes span multiple areas, pick the primary one

BREAKING CHANGES (RARE - only for incompatible changes):
- ONLY add ! if this breaks existing functionality for users
- Examples: removing APIs, changing CLI flags, changing config format
- Bug fixes, new features, and refactors are NOT breaking changes
- If breaking, add ! after type: <type>!(<scope>):
- Add a BREAKING CHANGE footer explaining what breaks"
    SCOPE_EXAMPLES="Examples (note: most commits should NOT have !):
- feat(auth): add JWT token validation
- feat(auth): (ABC-123) add JWT token validation
- fix(api): resolve timeout in user endpoint
- fix(api): (JIRA-456) resolve timeout in user endpoint
- feat!(api): remove legacy login endpoint

BREAKING CHANGE: Legacy /auth/login endpoint removed, use /auth/v2/login instead"
elif [ "$USE_GITMOJI" = "true" ]; then
    SCOPE_INSTRUCTION="OUTPUT FORMAT (summary line MUST be first):
<emoji> <type>: <concise summary of all changes below>
$GITMOJI_INSTRUCTION

BREAKING CHANGES (RARE - only for incompatible changes):
- ONLY add ! if this breaks existing functionality for users
- Examples: removing APIs, changing CLI flags, changing config format
- Bug fixes, new features, and refactors are NOT breaking changes
- If breaking, add ! after type: <emoji> <type>!:
- Add a BREAKING CHANGE footer explaining what breaks"
    SCOPE_EXAMPLES="Examples (note: most commits should NOT have !):
- âœ¨ feat: add user authentication
- âœ¨ feat(auth): (ABC-123) add user login
- ðŸ› fix: resolve database connection issue
- ðŸ› fix(api): (JIRA-456) fix timeout error
- âœ¨ feat!: remove legacy login endpoint

BREAKING CHANGE: Legacy /auth/login endpoint removed, use /auth/v2/login instead"
else
    SCOPE_INSTRUCTION="OUTPUT FORMAT (summary line MUST be first):
<type>: <concise summary of all changes below>

BREAKING CHANGES (RARE - only for incompatible changes):
- ONLY add ! if this breaks existing functionality for users
- Examples: removing APIs, changing CLI flags, changing config format
- Bug fixes, new features, and refactors are NOT breaking changes
- If breaking, add ! after type: <type>!:
- Add a BREAKING CHANGE footer explaining what breaks"
    SCOPE_EXAMPLES="Examples (note: most commits should NOT have !):
- feat: add user authentication
- feat: (ABC-123) add user login
- fix: resolve database connection issue
- fix: (JIRA-456) fix timeout error
- feat!: remove legacy login endpoint

BREAKING CHANGE: Legacy /auth/login endpoint removed, use /auth/v2/login instead"
fi

# Prepare multiple options instruction if requested
MULTIPLE_OPTIONS_INSTRUCTION=""
if [ "$MULTIPLE_OPTIONS" = "true" ]; then
    MULTIPLE_OPTIONS_INSTRUCTION="

IMPORTANT: Generate 3 different variations of the commit message with reasoning:

For each variation, follow this exact format:
[OPTION X]
<commit message here>

[REASONING]
<explain why this option is good and when to use it>

1. CONCISE - Minimal details, shorter bullet list
2. DETAILED - More comprehensive, longer bullet list
3. ALTERNATIVE - Different perspective or scope

After all 3 options, provide your recommendation:

[RECOMMENDATION]
I recommend Option X because <reasoning for which is most appropriate for these changes>

Separate each variation with the marker: ---OPTION---"
fi

# Prepare language instruction
LANGUAGE_INSTRUCTION=""
if [ "$COMMIT_LANGUAGE" != "en" ]; then
    LANGUAGE_NAME=$(get_language_name "$COMMIT_LANGUAGE")
    LANGUAGE_INSTRUCTION="

IMPORTANT - LANGUAGE:
- Write ALL commit message text in $LANGUAGE_NAME
- Keep the commit type prefix in English (feat:, fix:, docs:, etc.)
- Write the summary and bullets in $LANGUAGE_NAME
- Maintain technical terms (API, HTTP, function names, etc.) in English
- Example format: feat: [summary in $LANGUAGE_NAME]
  - [bullet 1 in $LANGUAGE_NAME]
  - [bullet 2 in $LANGUAGE_NAME]"
fi

# Use simplified prompt for WordPress plugin/theme updates
if [ -n "$WP_COMPONENT_NAME" ]; then
    # Capitalize first letter for display (portable method)
    if [ "$WP_COMPONENT_TYPE" = "plugin" ]; then
        WP_COMPONENT_TYPE_CAP="Plugin"
        WP_COMPONENT_TYPE_PLURAL="plugins"
    else
        WP_COMPONENT_TYPE_CAP="Theme"
        WP_COMPONENT_TYPE_PLURAL="themes"
    fi

    # Check if multiple plugins/themes (comma-separated)
    if [[ "$WP_COMPONENT_NAME" == *,* ]]; then
        # Multiple components
        WP_CONTEXT_SECTION=""
        if [ -n "$WP_CONTEXT" ]; then
            WP_CONTEXT_SECTION="
$WP_CONTEXT
"
        fi

        PROMPT="Create a commit message for WordPress $WP_COMPONENT_TYPE_PLURAL updates.

$WP_COMPONENT_TYPE_CAP names: $WP_COMPONENT_NAME
${WP_CONTEXT_SECTION}
Files changed:
$GIT_STATUS

Stats:
$GIT_STATS

Generate a commit message describing what WordPress functionality was added or modified.
If specific WordPress functions are detected above, incorporate them into your message.

Format:
<type>: <specific description>

- <detailed change 1>
- <detailed change 2>

RULES:
- Choose appropriate type based on changes: feat (new functionality), fix (bug fixes), chore (maintenance)
- Summary line should be specific about what was changed (not just 'update $WP_COMPONENT_TYPE_PLURAL')
- If WordPress functions are detected, mention them specifically
- Add detailed bullets describing the changes
- Use lowercase for all text
- Use imperative mood (add/fix not added/fixed)
- Output ONLY the commit message, NO explanations, NO markdown, NO code fences$LANGUAGE_INSTRUCTION"
    else
        # Single component
        WP_CONTEXT_SECTION=""
        if [ -n "$WP_CONTEXT" ]; then
            WP_CONTEXT_SECTION="
$WP_CONTEXT
"
        fi

        PROMPT="Create a commit message for WordPress $WP_COMPONENT_TYPE changes.

$WP_COMPONENT_TYPE_CAP name: $WP_COMPONENT_NAME
${WP_CONTEXT_SECTION}
Files changed:
$GIT_STATUS

Stats:
$GIT_STATS

Generate a commit message describing what WordPress functionality was added or modified.
If specific WordPress functions are detected above, incorporate them into your message.

Format:
<type>: <specific description>

- <detailed change 1>
- <detailed change 2>

RULES:
- Choose appropriate type based on changes: feat (new functionality), fix (bug fixes), chore (maintenance)
- Summary line should be specific about what was changed (e.g., 'register book custom post type', not just 'update $WP_COMPONENT_NAME')
- If WordPress functions are detected, mention them specifically
- Add detailed bullets describing the changes
- Use lowercase for all text
- Use imperative mood (add/fix not added/fixed)
- Output ONLY the commit message, NO explanations, NO markdown, NO code fences$LANGUAGE_INSTRUCTION"
    fi
else
    PROMPT="Analyze these git changes and create a commit message.

PROCESS:
1. First, identify all significant changes and list them as bullets
2. Then, synthesize those changes into ONE concise summary line
3. Choose the right type: feat, fix, docs, style, refactor, test, or chore

$SCOPE_INSTRUCTION

- <change 1>
- <change 2>
- <change 3>
- <change 4>

RULES:
- Summary line: max 50 chars, describes the overall purpose
- Use lowercase for all text (except API, HTTP, JSON, JWT, SQL, and ticket codes like ABC-123)
- Ticket codes must stay UPPERCASE: use (ABC-123) not (abc-123)
- Use imperative mood (add/fix not added/fixed)
- The summary should capture the essence of all bullets below it
- Do NOT use ! unless instructions above say this breaks existing functionality
- Output ONLY the commit message, NO explanations, NO markdown, NO code fences$LANGUAGE_INSTRUCTION

$SCOPE_EXAMPLES

$FEW_SHOT_EXAMPLES
$REPO_EXAMPLES

$BRANCH_CONTEXT

$HISTORY_INSIGHTS
$WP_CONTEXT
$FILE_CONTEXT
$FUNCTION_CONTEXT
$SEMANTIC_ANALYSIS
$FILE_RELATIONSHIPS

=== KEY FILES MODIFIED ===
Pay special attention to these filenames when writing your commit message.
Your summary line MUST reflect WHAT PART of the application was changed.

$GIT_STATUS

$FILE_SUMMARIES

Stats:
$GIT_STATS

Diff sample:
$GIT_DIFF

$CLOSING_INSTRUCTION$MULTIPLE_OPTIONS_INSTRUCTION"
fi

# Escape JSON strings (replace backslash, double quote, newline, carriage return, tab)
escape_json() {
    echo "$1" | sed 's/\\/\\\\/g; s/"/\\"/g; s/\n/\\n/g; s/\r/\\r/g; s/\t/\\t/g' | awk '{printf "%s\\n", $0}' | sed '$ s/\\n$//'
}

# Unescape JSON strings (handle unicode escapes like \u0026)
unescape_json() {
    local text="$1"

    # First, decode unicode escapes (\uXXXX)
    # This handles common cases like \u0026 (&), \u003c (<), \u003e (>)
    while [[ "$text" =~ \\u([0-9a-fA-F]{4}) ]]; do
        local hex="${BASH_REMATCH[1]}"
        local dec=$((16#$hex))
        # Use printf to convert to actual character
        local char=$(printf "\\$(printf '%03o' "$dec")")
        text="${text/\\u$hex/$char}"
    done

    # Then handle standard JSON escapes
    text="${text//\\\\/\\}"    # \\ -> \
    text="${text//\\\"/\"}"    # \" -> "

    echo "$text"
}

# Enforce lowercase on commit message while preserving acronyms and ticket numbers
enforce_lowercase() {
    local message="$1"
    local temp_message="$message"

    # First, protect ticket numbers by replacing them with placeholders
    # Pattern: ABC-123, JIRA-456, etc.
    local ticket_counter=0
    local tickets_file=$(mktemp)

    # Find all ticket numbers and store them
    echo "$message" | grep -oE '[A-Z][A-Z0-9]+-[0-9]+' > "$tickets_file"

    # Replace tickets with placeholders
    while IFS= read -r ticket; do
        if [ -n "$ticket" ]; then
            temp_message=$(echo "$temp_message" | sed "s/$ticket/__TICKET${ticket_counter}__/g")
            ((ticket_counter++))
        fi
    done < "$tickets_file"

    # Convert entire message to lowercase
    temp_message=$(echo "$temp_message" | tr '[:upper:]' '[:lower:]')

    # Restore ticket numbers
    ticket_counter=0
    while IFS= read -r ticket; do
        if [ -n "$ticket" ]; then
            temp_message=$(echo "$temp_message" | sed "s/__ticket${ticket_counter}__/$ticket/g")
            ((ticket_counter++))
        fi
    done < "$tickets_file"

    rm -f "$tickets_file"

    # Restore common acronyms (case-insensitive search and replace)
    local acronyms="API HTTP HTTPS JSON XML SQL JWT OAuth REST CLI UI UX CSS HTML JS TS URL URI PDF CSV IDE SDK CI CD AWS GCP DNS SSL TLS SSH FTP SMTP TCP UDP IP DOM npm NPM README TODO FIXME"

    for acronym in $acronyms; do
        local lowercase_acronym=$(echo "$acronym" | tr '[:upper:]' '[:lower:]')
        # Use word boundaries to avoid partial matches
        temp_message=$(echo "$temp_message" | sed "s/\b$lowercase_acronym\b/$acronym/g")
    done

    echo "$temp_message"
}

# Detect project type based on files present
detect_project_type() {
    # Web application indicators
    if [ -f "package.json" ]; then
        local pkg_content=$(cat "package.json" 2>/dev/null || echo "")
        if echo "$pkg_content" | grep -qE '(react|vue|angular|svelte|next|nuxt|webpack|vite)'; then
            echo "web-app"
            return
        fi
        if echo "$pkg_content" | grep -q '"type".*:.*"module"'; then
            echo "library"
            return
        fi
    fi

    # CLI tool indicators
    if [ -d "bin" ] || [ -d "cmd" ]; then
        echo "cli"
        return
    fi

    # Library indicators
    if [ -f "setup.py" ] || [ -f "pyproject.toml" ]; then
        echo "library"
        return
    fi

    if [ -f "Cargo.toml" ]; then
        local cargo_content=$(cat "Cargo.toml" 2>/dev/null || echo "")
        if echo "$cargo_content" | grep -q '\[lib\]'; then
            echo "library"
            return
        fi
        echo "cli"
        return
    fi

    if [ -f "go.mod" ]; then
        if [ -f "main.go" ] && grep -q "package main" "main.go" 2>/dev/null; then
            echo "cli"
            return
        fi
        echo "library"
        return
    fi

    # Default
    echo "general"
}

# Load template from file or return built-in template
load_template() {
    local project_type="$1"

    # Check for local template file
    if [ -f ".gh-commit-ai-template" ]; then
        cat ".gh-commit-ai-template"
        return
    fi

    # Return built-in template based on project type
    case "$project_type" in
        web-app)
            cat <<'EOF'
{{emoji}} {{type}}{{scope}}: {{message}}

{{bullets}}
{{breaking}}
EOF
            ;;
        library)
            cat <<'EOF'
{{emoji}} {{type}}{{scope}}: {{message}}

{{bullets}}
{{breaking}}

Changes: {{files_changed}} files changed
EOF
            ;;
        cli)
            cat <<'EOF'
{{emoji}} {{type}}{{scope}}: {{message}}

{{bullets}}
{{breaking}}
EOF
            ;;
        *)
            # General/default template - same as current format
            cat <<'EOF'
{{emoji}} {{type}}{{scope}}: {{message}}

{{bullets}}
{{breaking}}
EOF
            ;;
    esac
}

# Parse commit message components from AI-generated message
parse_commit_components() {
    local message="$1"

    # Extract first line (summary with type/scope)
    local first_line=$(echo "$message" | head -1)

    # Parse type, emoji, scope, and summary
    local emoji=""
    local type=""
    local scope=""
    local summary=""
    local breaking_marker=""

    # Check for emoji at start
    if [[ "$first_line" =~ ^([[:space:]]*)([^[:space:][:alnum:]]+)[[:space:]]+ ]]; then
        emoji="${BASH_REMATCH[2]}"
        first_line="${first_line#*${emoji}}"
        first_line="${first_line#"${first_line%%[![:space:]]*}"}" # trim leading spaces
    fi

    # Parse type with optional scope and breaking marker
    # Patterns: feat:, feat(scope):, feat!:, feat(scope)!:
    if [[ "$first_line" =~ ^([a-z]+)(\([a-z0-9_-]+\))?(!)?:[[:space:]]*(.+)$ ]]; then
        type="${BASH_REMATCH[1]}"
        scope="${BASH_REMATCH[2]}"  # includes parentheses
        breaking_marker="${BASH_REMATCH[3]}"
        summary="${BASH_REMATCH[4]}"
    else
        # Fallback: treat entire line as summary
        summary="$first_line"
    fi

    # Extract bullets (lines starting with -)
    local bullets=$(echo "$message" | tail -n +2 | awk '/^[[:space:]]*-/ {print}' | sed '/^$/d')

    # Extract BREAKING CHANGE footer if present
    local breaking=""
    if echo "$message" | grep -q "^BREAKING CHANGE:"; then
        breaking=$(echo "$message" | sed -n '/^BREAKING CHANGE:/,$ p')
    fi

    # Export as variables that can be used by apply_template
    echo "TYPE=$type"
    echo "EMOJI=$emoji"
    echo "SCOPE=$scope"
    echo "BREAKING_MARKER=$breaking_marker"
    echo "SUMMARY=$summary"
    echo "BULLETS<<BULLETS_EOF"
    echo "$bullets"
    echo "BULLETS_EOF"
    echo "BREAKING<<BREAKING_EOF"
    echo "$breaking"
    echo "BREAKING_EOF"
}

# Apply template variables and return formatted message
apply_template() {
    local template="$1"
    local message="$2"

    # Parse components from AI message
    local components=$(parse_commit_components "$message")

    # Extract component values using heredoc parsing
    local TYPE=$(echo "$components" | grep "^TYPE=" | cut -d= -f2-)
    local EMOJI=$(echo "$components" | grep "^EMOJI=" | cut -d= -f2-)
    local SCOPE=$(echo "$components" | grep "^SCOPE=" | cut -d= -f2-)
    local BREAKING_MARKER=$(echo "$components" | grep "^BREAKING_MARKER=" | cut -d= -f2-)
    local SUMMARY=$(echo "$components" | grep "^SUMMARY=" | cut -d= -f2-)

    # Extract multiline values (bullets and breaking)
    local BULLETS=$(echo "$components" | sed -n '/^BULLETS<<BULLETS_EOF$/,/^BULLETS_EOF$/p' | sed '1d;$d')
    local BREAKING=$(echo "$components" | sed -n '/^BREAKING<<BREAKING_EOF$/,/^BREAKING_EOF$/p' | sed '1d;$d')

    # Get additional template variables
    local BRANCH=$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo "")
    local TICKET=$(echo "$BRANCH" | grep -oE '[A-Z][A-Z0-9]+-[0-9]+' | head -1 || echo "")
    local AUTHOR=$(git config user.name 2>/dev/null || echo "")
    local DATE=$(date +"%Y-%m-%d")
    local FILES_CHANGED=$(git diff --cached --name-only 2>/dev/null | wc -l | tr -d ' ')

    # Build scope string with format: (scope) or empty
    local SCOPE_STR=""
    if [ -n "$SCOPE" ]; then
        SCOPE_STR="$SCOPE"
    fi

    # Build breaking marker: ! or empty
    local BREAKING_STR=""
    if [ -n "$BREAKING_MARKER" ]; then
        BREAKING_STR="!"
    fi

    # Apply template substitutions
    local result="$template"

    # Simple variable substitution
    result="${result//\{\{emoji\}\}/$EMOJI}"
    result="${result//\{\{type\}\}/$TYPE}"
    result="${result//\{\{scope\}\}/$SCOPE_STR}"
    result="${result//\{\{breaking_marker\}\}/$BREAKING_STR}"
    result="${result//\{\{message\}\}/$SUMMARY}"
    result="${result//\{\{bullets\}\}/$BULLETS}"
    result="${result//\{\{breaking\}\}/$BREAKING}"
    result="${result//\{\{ticket\}\}/$TICKET}"
    result="${result//\{\{branch\}\}/$BRANCH}"
    result="${result//\{\{author\}\}/$AUTHOR}"
    result="${result//\{\{date\}\}/$DATE}"
    result="${result//\{\{files_changed\}\}/$FILES_CHANGED}"

    # Clean up: remove lines that only contain empty template variables
    result=$(echo "$result" | sed '/^[[:space:]]*$/d')

    # Remove trailing blank lines
    result=$(echo "$result" | awk '
        { lines[NR] = $0 }
        END {
            for (i = 1; i <= NR; i++) {
                if (i == NR) {
                    if (lines[i] != "") print lines[i]
                } else if (lines[i] != "" || lines[i+1] != "") {
                    print lines[i]
                }
            }
        }
    ')

    echo "$result"
}

# Calculate cost for API usage
calculate_cost() {
    local provider="$1"
    local model="$2"
    local input_tokens="$3"
    local output_tokens="$4"

    # Return early if no token data
    if [ -z "$input_tokens" ] || [ -z "$output_tokens" ]; then
        return
    fi

    local input_cost=0
    local output_cost=0
    local currency="USD"

    # Pricing per 1M tokens (as of early 2025)
    case "$provider" in
        anthropic)
            case "$model" in
                claude-3-5-sonnet-20241022|claude-3-5-sonnet-latest)
                    input_cost=3.00    # $3 per MTok
                    output_cost=15.00  # $15 per MTok
                    ;;
                claude-3-opus-20240229)
                    input_cost=15.00   # $15 per MTok
                    output_cost=75.00  # $75 per MTok
                    ;;
                claude-3-haiku-20240307)
                    input_cost=0.25    # $0.25 per MTok
                    output_cost=1.25   # $1.25 per MTok
                    ;;
                *)
                    # Default to Sonnet pricing
                    input_cost=3.00
                    output_cost=15.00
                    ;;
            esac
            ;;
        openai)
            case "$model" in
                gpt-4o)
                    input_cost=2.50    # $2.50 per MTok
                    output_cost=10.00  # $10 per MTok
                    ;;
                gpt-4o-mini)
                    input_cost=0.15    # $0.15 per MTok
                    output_cost=0.60   # $0.60 per MTok
                    ;;
                gpt-4-turbo|gpt-4-turbo-preview)
                    input_cost=10.00   # $10 per MTok
                    output_cost=30.00  # $30 per MTok
                    ;;
                gpt-4)
                    input_cost=30.00   # $30 per MTok
                    output_cost=60.00  # $60 per MTok
                    ;;
                *)
                    # Default to gpt-4o-mini pricing
                    input_cost=0.15
                    output_cost=0.60
                    ;;
            esac
            ;;
    esac

    # Calculate costs (tokens / 1,000,000 * price per million)
    # Using bc for floating point, or awk if bc not available
    if command -v bc >/dev/null 2>&1; then
        local input_cost_calc=$(echo "scale=6; $input_tokens / 1000000 * $input_cost" | bc)
        local output_cost_calc=$(echo "scale=6; $output_tokens / 1000000 * $output_cost" | bc)
        local total_cost=$(echo "scale=6; $input_cost_calc + $output_cost_calc" | bc)
    else
        # Fallback to awk if bc not available
        local input_cost_calc=$(awk "BEGIN {printf \"%.6f\", $input_tokens / 1000000 * $input_cost}")
        local output_cost_calc=$(awk "BEGIN {printf \"%.6f\", $output_tokens / 1000000 * $output_cost}")
        local total_cost=$(awk "BEGIN {printf \"%.6f\", $input_cost_calc + $output_cost_calc}")
    fi

    # Format for display (remove trailing zeros)
    local total_cost_display=$(echo "$total_cost" | sed 's/0*$//' | sed 's/\.$//')

    # If cost is very small, show more precision
    if [ $(echo "$total_cost < 0.0001" | bc 2>/dev/null || echo 0) -eq 1 ]; then
        total_cost_display=$(printf "%.6f" "$total_cost" | sed 's/0*$//' | sed 's/\.$//')
    else
        total_cost_display=$(printf "%.4f" "$total_cost" | sed 's/0*$//' | sed 's/\.$//')
    fi

    # Display token usage and cost
    local total_tokens=$((input_tokens + output_tokens))
    echo "ðŸ’° Token usage: ${total_tokens} tokens (${input_tokens} input + ${output_tokens} output)"
    echo "ðŸ’° Estimated cost: \$$total_cost_display $currency"

    # Track cumulative cost
    track_cumulative_cost "$total_cost"
}

# Track cumulative costs
track_cumulative_cost() {
    local cost="$1"
    local cost_file="/tmp/gh-commit-ai-costs-$(date +%Y%m%d)"

    # Append to daily cost file
    echo "$cost" >> "$cost_file"

    # Calculate cumulative total for today
    if command -v bc >/dev/null 2>&1; then
        local cumulative=$(awk '{sum+=$1} END {printf "%.6f", sum}' "$cost_file")
    else
        local cumulative=$(awk '{sum+=$1} END {printf "%.6f", sum}' "$cost_file")
    fi

    # Format for display
    local cumulative_display=$(printf "%.4f" "$cumulative" | sed 's/0*$//' | sed 's/\.$//')

    echo "ðŸ’° Today's total: \$$cumulative_display USD"
}

# Strip ANSI color codes from text
strip_ansi_codes() {
    local text="$1"
    # Remove ANSI escape sequences
    echo "$text" | sed 's/\x1b\[[0-9;]*m//g' | sed 's/\\033\[[0-9;]*m//g'
}

# Convert literal \n to actual newlines for better display in GitHub
convert_newlines() {
    local text="$1"
    # Use printf %b to interpret backslash escapes
    printf "%b" "$text"
}

# Parse multiple commit message options from AI response
parse_multiple_options() {
    local response="$1"

    # Extract recommendation if present
    if echo "$response" | grep -q "\[RECOMMENDATION\]"; then
        echo "$response" | sed -n '/\[RECOMMENDATION\]/,$ p' | tail -n +2 > /tmp/ai_recommendation.txt
    fi

    # Parse with a simple sed/bash approach for better compatibility
    local current_option=0
    local in_option=0
    local in_reasoning=0

    # Process line by line
    echo "$response" | while IFS= read -r line; do
        # Check for section markers
        if echo "$line" | grep -q '^\[OPTION [0-9]\]'; then
            current_option=$((current_option + 1))
            in_option=1
            in_reasoning=0
            continue
        elif echo "$line" | grep -q '^\[REASONING\]'; then
            in_option=0
            in_reasoning=1
            continue
        elif echo "$line" | grep -q '^\[RECOMMENDATION\]'; then
            break
        elif echo "$line" | grep -q '^---OPTION---'; then
            continue
        fi

        # Write to appropriate file
        if [ "$in_option" = "1" ] && [ "$current_option" -gt 0 ]; then
            echo "$line" >> "/tmp/option_${current_option}.txt"
        elif [ "$in_reasoning" = "1" ] && [ "$current_option" -gt 0 ]; then
            echo "$line" >> "/tmp/reasoning_${current_option}.txt"
        fi
    done

    # If no structured format found, fallback to old simple parsing
    if [ ! -f "/tmp/option_1.txt" ]; then
        current_option=1
        echo "$response" | while IFS= read -r line; do
            if echo "$line" | grep -q "^---OPTION---$"; then
                current_option=$((current_option + 1))
            else
                echo "$line" >> "/tmp/option_${current_option}.txt"
            fi
        done
    fi

    # If still no options, treat as single option
    if [ ! -f "/tmp/option_1.txt" ]; then
        echo "$response" > "/tmp/option_1.txt"
        echo "1"
        return
    fi

    # Count how many options we have
    count=0
    for f in /tmp/option_*.txt; do
        [ -f "$f" ] && count=$((count + 1))
    done

    echo "$count"
}

# Display multiple options for user selection
display_options() {
    local num_options="$1"

    echo -e "Generated ${num_options} commit message options:\n"

    for i in $(seq 1 $num_options); do
        local option_file="/tmp/option_${i}.txt"
        local reasoning_file="/tmp/reasoning_${i}.txt"

        if [ -f "$option_file" ]; then
            local option_content=$(cat "$option_file" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
            echo -e "${GREEN}Option $i:${NC}"
            echo -e "$option_content"

            # Display reasoning if available
            if [ -f "$reasoning_file" ]; then
                local reasoning=$(cat "$reasoning_file" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
                echo -e "\n${YELLOW}Reasoning:${NC} $reasoning"
            fi
            echo ""
        fi
    done

    # Display AI recommendation if available
    if [ -f "/tmp/ai_recommendation.txt" ]; then
        local recommendation=$(cat "/tmp/ai_recommendation.txt" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
        echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}"
        echo -e "${CYAN}AI Recommendation:${NC}"
        echo -e "$recommendation"
        echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}\n"
    fi
}

# Get user's option selection
select_option() {
    local num_options="$1"

    while true; do
        echo -n "Select option (1-${num_options}), or 'n' to cancel: "
        read -n 1 -r
        echo

        if [[ $REPLY =~ ^[Nn]$ ]]; then
            echo "cancelled"
            return
        fi

        if [[ $REPLY =~ ^[0-9]+$ ]] && [ "$REPLY" -ge 1 ] && [ "$REPLY" -le "$num_options" ]; then
            echo "$REPLY"
            return
        fi

        echo -e "${RED}âŒ Invalid selection. Please enter 1-${num_options} or 'n' to cancel."
    done
}

# Call Ollama API
call_ollama() {
    local prompt="$1"

    # Quick pre-flight check: verify Ollama is reachable
    if ! curl -s --connect-timeout 2 --max-time 5 "$OLLAMA_HOST/api/tags" >/dev/null 2>&1; then
        echo -e "${RED}Error: Cannot connect to Ollama at $OLLAMA_HOST${NC}" >&2
        echo "" >&2
        echo "Ollama is not responding. Possible causes:" >&2
        echo "  â€¢ Ollama service is not running" >&2
        echo "  â€¢ Wrong OLLAMA_HOST configuration" >&2
        echo "  â€¢ Port conflict or firewall blocking" >&2
        echo "" >&2
        echo "Troubleshooting:" >&2
        echo "  â€¢ Start Ollama: ollama serve" >&2
        echo "  â€¢ Check if running: ps aux | grep ollama" >&2
        echo "  â€¢ Verify host: curl $OLLAMA_HOST/api/tags" >&2
        echo "  â€¢ List models: ollama list" >&2
        echo "" >&2
        echo "Don't have Ollama? Install from: https://ollama.ai" >&2
        return 1
    fi

    local model_escaped=$(escape_json "$OLLAMA_MODEL")
    local prompt_escaped=$(escape_json "$prompt")
    local json_payload=$(printf '{"model":"%s","prompt":"%s","stream":false}' "$model_escaped" "$prompt_escaped")

    if [ "$VERBOSE" = "true" ]; then
        echo "[Verbose] API Endpoint:${NC} $OLLAMA_HOST/api/generate"
        echo "[Verbose] Request payload:"
        echo "$json_payload" | jq '.' 2>/dev/null || echo "$json_payload"
        echo ""
    fi

    # Run API call with retry logic in background with spinner
    local temp_response
    local temp_error
    temp_response=$(create_secure_temp_file "gh-commit-ai-response") || return 1
    temp_error=$(create_secure_temp_file "gh-commit-ai-error") || {
        rm -f "$temp_response"
        return 1
    }
    local exit_code=0
    (
        retry_api_call \
            "$OLLAMA_HOST/api/generate" \
            "$json_payload" \
            "$temp_response" \
            "$temp_error" \
            "Ollama" \
            -H "Content-Type: application/json"
        echo $? > "${temp_response}.exit"
    ) &
    local api_pid=$!

    show_spinner "$api_pid" "Thinking"
    wait "$api_pid"

    exit_code=$(cat "${temp_response}.exit" 2>/dev/null || echo "1")

    # Read response from file
    local response=$(cat "$temp_response" 2>/dev/null)

    # Check for final failure after all retries
    if [ "$exit_code" != "0" ] || [ -z "$response" ]; then
        echo -e "${RED}Error: Failed to get response from Ollama after $MAX_RETRIES attempts${NC}" >&2
        echo "" >&2
        echo "All retry attempts exhausted. Possible causes:" >&2
        echo "  â€¢ Model '$OLLAMA_MODEL' not found or not loaded" >&2
        echo "  â€¢ Ollama service stopped during request" >&2
        echo "  â€¢ Out of memory (model too large)" >&2
        echo "  â€¢ Request timeout" >&2
        echo "" >&2

        # Show actual error if available
        if [ -s "$temp_error" ]; then
            echo -e "${YELLOW}Error details: $(cat "$temp_error" | head -1)${NC}" >&2
            echo "" >&2
        fi

        echo "Troubleshooting:" >&2
        echo "  â€¢ Check if model exists: ollama list" >&2
        echo "  â€¢ Pull model if needed: ollama pull $OLLAMA_MODEL" >&2
        echo "  â€¢ Verify service: curl $OLLAMA_HOST/api/tags" >&2
        echo "  â€¢ Check service status: ps aux | grep ollama" >&2
        echo "  â€¢ Try smaller model: OLLAMA_MODEL=gemma2:2b gh commit-ai" >&2
        echo "  â€¢ Run with verbose mode: gh commit-ai --verbose" >&2

        rm -f "$temp_response" "$temp_error" "${temp_response}.exit"
        return 1
    fi

    # Validate response content
    if ! validate_api_response "$response"; then
        echo -e "${RED}Error: Invalid response from Ollama${NC}" >&2
        echo "" >&2
        echo "The Ollama API returned an unexpected response format." >&2
        echo "This could indicate:" >&2
        echo "  â€¢ Model compatibility issues" >&2
        echo "  â€¢ Corrupted model installation" >&2
        echo "  â€¢ Ollama version mismatch" >&2
        echo "" >&2
        echo "Try:" >&2
        echo "  â€¢ Update Ollama: brew upgrade ollama" >&2
        echo "  â€¢ Reinstall model: ollama rm $OLLAMA_MODEL && ollama pull $OLLAMA_MODEL" >&2
        echo "  â€¢ Run with verbose mode: gh commit-ai --verbose" >&2
        rm -f "$temp_response" "$temp_error" "${temp_response}.exit"
        return 1
    fi

    rm -f "$temp_error" "${temp_response}.exit"

    if [ "$VERBOSE" = "true" ]; then
        echo "[Verbose] Response:"
        echo "$response" | jq '.' 2>/dev/null || echo "$response"
        echo ""
    fi

    # Check for errors
    if echo "$response" | grep -q '"error"'; then
        local error_msg=$(echo "$response" | grep -o '"error":"[^"]*"' | sed 's/"error":"//;s/"$//')
        echo -e "${RED}Error from Ollama: $error_msg${NC}" >&2
        echo "" >&2

        # Check if it's a model not found error
        if echo "$error_msg" | grep -qi "model.*not found\|pull.*model"; then
            echo -e "Model '${BLUE}$OLLAMA_MODEL${NC}' is not installed." >&2
            echo "" >&2
            echo "To fix this, run:" >&2
            echo -e "  ${GREEN}ollama pull $OLLAMA_MODEL${NC}" >&2
            echo "" >&2
            echo "Or use a different model:" >&2
            echo -e "  ${GREEN}OLLAMA_MODEL=llama3.2 gh commit-ai${NC}" >&2
        else
            echo "Troubleshooting:" >&2
            echo "  - Check available models: ollama list" >&2
            echo "  - Verify Ollama status: ollama ps" >&2
            echo "  - Try verbose mode: gh commit-ai --verbose" >&2
        fi
        return 1
    fi

    # Extract commit message from response
    # Use awk to properly extract JSON string value (handles escaped quotes)
    local raw_message=$(echo "$response" | awk -F'"response":"' '{
        if (NF > 1) {
            str = $2
            result = ""
            escaped = 0
            for (i = 1; i <= length(str); i++) {
                c = substr(str, i, 1)
                if (escaped) {
                    result = result c
                    escaped = 0
                } else if (c == "\\") {
                    result = result c
                    escaped = 1
                } else if (c == "\"") {
                    break
                } else {
                    result = result c
                }
            }
            print result
        }
    }')
    unescape_json "$raw_message"
}

# Call Anthropic API
call_anthropic() {
    local prompt="$1"

    if [ -z "$ANTHROPIC_API_KEY" ]; then
        show_api_key_error "Anthropic" "ANTHROPIC_API_KEY"
        exit 1
    fi

    # Check network connectivity before making API call
    if ! check_network_connectivity; then
        show_offline_error "Anthropic"
        exit 1
    fi

    # Check if Anthropic API is reachable
    if ! check_host_reachability "api.anthropic.com"; then
        echo -e "${RED}Error: Cannot reach Anthropic API${NC}" >&2
        echo "" >&2
        echo "The API endpoint api.anthropic.com is not reachable." >&2
        echo "Possible causes:" >&2
        echo "  â€¢ Anthropic service is down" >&2
        echo "  â€¢ Firewall or network filtering" >&2
        echo "  â€¢ DNS issues" >&2
        echo "" >&2
        echo "Try:" >&2
        echo "  â€¢ Check service status: https://status.anthropic.com/" >&2
        echo "  â€¢ Use a different provider (export AI_PROVIDER=groq or ollama)" >&2
        exit 1
    fi

    local prompt_escaped=$(escape_json "$prompt")
    local json_payload=$(printf '{"model":"%s","max_tokens":1024,"messages":[{"role":"user","content":"%s"}]}' "$ANTHROPIC_MODEL" "$prompt_escaped")

    if [ "$VERBOSE" = "true" ]; then
        echo "[Verbose] API Endpoint:${NC} https://api.anthropic.com/v1/messages"
        echo "[Verbose] Model:${NC} $ANTHROPIC_MODEL"
        echo "[Verbose] Request payload:"
        echo "$json_payload" | jq '.' 2>/dev/null || echo "$json_payload"
        echo ""
    fi

    # Run API call with retry logic in background with spinner
    local temp_response
    local temp_error
    temp_response=$(create_secure_temp_file "gh-commit-ai-response") || return 1
    temp_error=$(create_secure_temp_file "gh-commit-ai-error") || {
        rm -f "$temp_response"
        return 1
    }
    local exit_code=0
    (
        retry_api_call \
            "https://api.anthropic.com/v1/messages" \
            "$json_payload" \
            "$temp_response" \
            "$temp_error" \
            "Anthropic" \
            -H "Content-Type: application/json" \
            -H "x-api-key: $ANTHROPIC_API_KEY" \
            -H "anthropic-version: 2023-06-01"
        echo $? > "${temp_response}.exit"
    ) &
    local api_pid=$!

    show_spinner "$api_pid" "Thinking"
    wait "$api_pid"

    # Read exit code
    exit_code=$(cat "${temp_response}.exit" 2>/dev/null || echo "1")

    # Read response from file
    local response=$(cat "$temp_response" 2>/dev/null)

    # Check for final failure after all retries
    if [ "$exit_code" != "0" ]; then
        echo -e "${RED}Error: Failed to get response from Anthropic after $MAX_RETRIES attempts${NC}" >&2
        echo "" >&2
        echo "All retry attempts exhausted. This could be due to:" >&2
        echo "  â€¢ Poor network connection" >&2
        echo "  â€¢ API service issues" >&2
        echo "  â€¢ Request timeouts" >&2
        echo "" >&2
        echo "Suggestions:" >&2
        echo "  â€¢ Check your internet connection" >&2
        echo "  â€¢ Check Anthropic status: https://status.anthropic.com/" >&2
        echo "  â€¢ Try again in a few minutes" >&2
        echo "  â€¢ Use a different provider: export AI_PROVIDER=ollama" >&2
        rm -f "$temp_response" "$temp_error" "${temp_response}.exit"
        return 1
    fi

    # Validate API response
    if ! validate_api_response "$response"; then
        echo -e "${RED}Error: Invalid response from Anthropic${NC}" >&2
        echo "" >&2
        echo "The API returned an unexpected response format." >&2
        echo "This could indicate:" >&2
        echo "  â€¢ API version changes" >&2
        echo "  â€¢ Service degradation" >&2
        echo "  â€¢ Network proxy interference" >&2
        echo "" >&2
        echo "Try:" >&2
        echo "  â€¢ Run with verbose mode: gh commit-ai --verbose" >&2
        echo "  â€¢ Use a different provider: export AI_PROVIDER=ollama" >&2
        rm -f "$temp_response" "$temp_error" "${temp_response}.exit"
        return 1
    fi

    # Cleanup temp files
    rm -f "$temp_error" "${temp_response}.exit"

    if [ "$VERBOSE" = "true" ]; then
        echo "[Verbose] Response:"
        echo "$response" | jq '.' 2>/dev/null || echo "$response"
        echo ""
    fi

    # Check for errors
    if echo "$response" | grep -q '"error"'; then
        local error_type=$(echo "$response" | grep -o '"type":"[^"]*"' | head -1 | sed 's/"type":"//;s/"$//')
        local error_msg=$(echo "$response" | grep -o '"message":"[^"]*"' | head -1 | sed 's/"message":"//;s/"$//')
        echo -e "${RED}Error from Anthropic ($error_type): $error_msg" >&2

        if [[ "$error_type" == *"authentication"* ]] || [[ "$error_msg" == *"API key"* ]]; then
            echo "Tip: Check your API key is valid and has credits" >&2
        elif [[ "$error_type" == *"rate_limit"* ]]; then
            echo "Tip: You've hit the rate limit. Wait a moment and try again" >&2
        fi
        return 1
    fi

    # Extract token usage (global variables for cost tracking)
    INPUT_TOKENS=$(echo "$response" | grep -o '"input_tokens":[0-9]*' | head -1 | grep -o '[0-9]*')
    OUTPUT_TOKENS=$(echo "$response" | grep -o '"output_tokens":[0-9]*' | head -1 | grep -o '[0-9]*')

    # Extract commit message from response
    # Anthropic returns: {"content":[{"text":"...","type":"text"}],...}
    # Use awk to properly extract JSON string value (handles escaped quotes)
    local raw_message=$(echo "$response" | awk -F'"text":"' '{
        if (NF > 1) {
            str = $2
            result = ""
            escaped = 0
            for (i = 1; i <= length(str); i++) {
                c = substr(str, i, 1)
                if (escaped) {
                    result = result c
                    escaped = 0
                } else if (c == "\\") {
                    result = result c
                    escaped = 1
                } else if (c == "\"") {
                    break
                } else {
                    result = result c
                }
            }
            print result
            exit
        }
    }')

    # Cleanup temp files
    rm -f "$temp_response"

    unescape_json "$raw_message"
}

# Call OpenAI API
call_openai() {
    local prompt="$1"

    if [ -z "$OPENAI_API_KEY" ]; then
        show_api_key_error "OpenAI" "OPENAI_API_KEY"
        exit 1
    fi

    # Check network connectivity before making API call
    if ! check_network_connectivity; then
        show_offline_error "OpenAI"
        exit 1
    fi

    # Check if OpenAI API is reachable
    if ! check_host_reachability "api.openai.com"; then
        echo -e "${RED}Error: Cannot reach OpenAI API${NC}" >&2
        echo "" >&2
        echo "The API endpoint api.openai.com is not reachable." >&2
        echo "Possible causes:" >&2
        echo "  â€¢ OpenAI service is down" >&2
        echo "  â€¢ Firewall or network filtering" >&2
        echo "  â€¢ DNS issues" >&2
        echo "" >&2
        echo "Try:" >&2
        echo "  â€¢ Check service status: https://status.openai.com/" >&2
        echo "  â€¢ Use a different provider (export AI_PROVIDER=groq or ollama)" >&2
        exit 1
    fi

    local prompt_escaped=$(escape_json "$prompt")
    local json_payload=$(printf '{"model":"%s","messages":[{"role":"user","content":"%s"}],"temperature":0.7}' "$OPENAI_MODEL" "$prompt_escaped")

    if [ "$VERBOSE" = "true" ]; then
        echo "[Verbose] API Endpoint:${NC} https://api.openai.com/v1/chat/completions"
        echo "[Verbose] Model:${NC} $OPENAI_MODEL"
        echo "[Verbose] Request payload:"
        echo "$json_payload" | jq '.' 2>/dev/null || echo "$json_payload"
        echo ""
    fi

    # Run API call with retry logic in background with spinner
    local temp_response
    local temp_error
    temp_response=$(create_secure_temp_file "gh-commit-ai-response") || return 1
    temp_error=$(create_secure_temp_file "gh-commit-ai-error") || {
        rm -f "$temp_response"
        return 1
    }
    local exit_code=0
    (
        retry_api_call \
            "https://api.openai.com/v1/chat/completions" \
            "$json_payload" \
            "$temp_response" \
            "$temp_error" \
            "OpenAI" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $OPENAI_API_KEY"
        echo $? > "${temp_response}.exit"
    ) &
    local api_pid=$!

    show_spinner "$api_pid" "Thinking"
    wait "$api_pid"

    # Read exit code
    exit_code=$(cat "${temp_response}.exit" 2>/dev/null || echo "1")

    # Read response from file
    local response=$(cat "$temp_response" 2>/dev/null)

    # Check for final failure after all retries
    if [ "$exit_code" != "0" ] || [ -z "$response" ]; then
        echo -e "${RED}Error: Failed to get response from OpenAI after $MAX_RETRIES attempts${NC}" >&2
        echo "" >&2
        echo "All retry attempts exhausted. Possible causes:" >&2
        echo "  â€¢ Network connection issues" >&2
        echo "  â€¢ OpenAI API is experiencing downtime" >&2
        echo "  â€¢ Request timeout (large diff or slow connection)" >&2
        echo "  â€¢ Rate limiting or quota exceeded" >&2
        echo "" >&2
        echo "Suggestions:" >&2
        echo "  â€¢ Check your internet: ping api.openai.com" >&2
        echo "  â€¢ Verify service status: https://status.openai.com/" >&2
        echo "  â€¢ Try reducing diff size: DIFF_MAX_LINES=50 gh commit-ai" >&2
        echo "  â€¢ Use a different provider:" >&2
        echo "    - Groq (fast, free tier): export AI_PROVIDER=groq" >&2
        echo "    - Ollama (local, no internet): export AI_PROVIDER=ollama" >&2
        echo "  â€¢ Wait a few minutes and try again" >&2
        rm -f "$temp_response" "$temp_error" "${temp_response}.exit"
        return 1
    fi

    # Validate response content
    if ! validate_api_response "$response"; then
        echo -e "${RED}Error: Invalid response from OpenAI${NC}" >&2
        echo "" >&2
        echo "The API returned an unexpected response format." >&2
        echo "This could indicate:" >&2
        echo "  â€¢ API version changes" >&2
        echo "  â€¢ Service degradation" >&2
        echo "  â€¢ Network proxy interference" >&2
        echo "" >&2
        echo "Try:" >&2
        echo "  â€¢ Run with verbose mode: gh commit-ai --verbose" >&2
        echo "  â€¢ Use a different provider: export AI_PROVIDER=ollama" >&2
        rm -f "$temp_response" "$temp_error" "${temp_response}.exit"
        return 1
    fi

    # Cleanup temp files
    rm -f "$temp_error" "${temp_response}.exit"

    if [ "$VERBOSE" = "true" ]; then
        echo "[Verbose] Response:"
        echo "$response" | jq '.' 2>/dev/null || echo "$response"
        echo ""
    fi

    # Check for errors
    if echo "$response" | grep -q '"error"'; then
        local error_type=$(echo "$response" | grep -o '"type":"[^"]*"' | head -1 | sed 's/"type":"//;s/"$//')
        local error_msg=$(echo "$response" | grep -o '"message":"[^"]*"' | head -1 | sed 's/"message":"//;s/"$//')
        local error_code=$(echo "$response" | grep -o '"code":"[^"]*"' | head -1 | sed 's/"code":"//;s/"$//')

        echo -e "${RED}Error from OpenAI" >&2
        [ -n "$error_code" ] && echo -e "${RED}Code: $error_code" >&2
        [ -n "$error_type" ] && echo -e "${RED}Type: $error_type" >&2
        [ -n "$error_msg" ] && echo -e "${RED}Message: $error_msg" >&2

        if [[ "$error_code" == *"invalid_api_key"* ]] || [[ "$error_msg" == *"API key"* ]]; then
            echo "Tip: Check your API key is valid and has credits" >&2
        elif [[ "$error_code" == *"rate_limit"* ]]; then
            echo "Tip: You've hit the rate limit. Wait a moment and try again" >&2
        elif [[ "$error_code" == *"model_not_found"* ]]; then
            echo "Tip: The model '$OPENAI_MODEL' doesn't exist or you don't have access" >&2
        fi
        return 1
    fi

    # Extract token usage (global variables for cost tracking)
    INPUT_TOKENS=$(echo "$response" | grep -o '"prompt_tokens":[0-9]*' | head -1 | grep -o '[0-9]*')
    OUTPUT_TOKENS=$(echo "$response" | grep -o '"completion_tokens":[0-9]*' | head -1 | grep -o '[0-9]*')

    # Extract commit message from response
    # OpenAI returns: {"choices":[{"message":{"content":"..."},...}],...}
    # Use awk to properly extract JSON string value (handles escaped quotes)
    local raw_message=$(echo "$response" | awk -F'"content":"' '{
        if (NF > 1) {
            str = $2
            result = ""
            escaped = 0
            for (i = 1; i <= length(str); i++) {
                c = substr(str, i, 1)
                if (escaped) {
                    result = result c
                    escaped = 0
                } else if (c == "\\") {
                    result = result c
                    escaped = 1
                } else if (c == "\"") {
                    break
                } else {
                    result = result c
                }
            }
            print result
            exit
        }
    }')

    # Cleanup temp files
    rm -f "$temp_response"

    unescape_json "$raw_message"
}

call_groq() {
    local prompt="$1"

    if [ -z "$GROQ_API_KEY" ]; then
        show_api_key_error "Groq" "GROQ_API_KEY"
        exit 1
    fi

    # Check network connectivity before making API call
    if ! check_network_connectivity; then
        show_offline_error "Groq"
        exit 1
    fi

    # Check if Groq API is reachable
    if ! check_host_reachability "api.groq.com"; then
        echo -e "${RED}Error: Cannot reach Groq API${NC}" >&2
        echo "" >&2
        echo "The API endpoint api.groq.com is not reachable." >&2
        echo "Possible causes:" >&2
        echo "  â€¢ Groq service is down" >&2
        echo "  â€¢ Firewall or network filtering" >&2
        echo "  â€¢ DNS issues" >&2
        echo "" >&2
        echo "Try:" >&2
        echo "  â€¢ Check service status: https://status.groq.com/" >&2
        echo "  â€¢ Use a different provider (export AI_PROVIDER=ollama)" >&2
        exit 1
    fi

    local prompt_escaped=$(escape_json "$prompt")
    local json_payload=$(printf '{"model":"%s","messages":[{"role":"user","content":"%s"}],"temperature":0.7}' "$GROQ_MODEL" "$prompt_escaped")

    if [ "$VERBOSE" = "true" ]; then
        echo "[Verbose] API Endpoint:${NC} https://api.groq.com/openai/v1/chat/completions"
        echo "[Verbose] Model:${NC} $GROQ_MODEL"
        echo "[Verbose] Request payload:"
        echo "$json_payload" | jq '.' 2>/dev/null || echo "$json_payload"
        echo ""
    fi

    # Run API call with retry logic in background with spinner
    local temp_response
    local temp_error
    temp_response=$(create_secure_temp_file "gh-commit-ai-response") || return 1
    temp_error=$(create_secure_temp_file "gh-commit-ai-error") || {
        rm -f "$temp_response"
        return 1
    }
    local exit_code=0
    (
        retry_api_call \
            "https://api.groq.com/openai/v1/chat/completions" \
            "$json_payload" \
            "$temp_response" \
            "$temp_error" \
            "Groq" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $GROQ_API_KEY"
        echo $? > "${temp_response}.exit"
    ) &
    local api_pid=$!

    show_spinner "$api_pid" "Thinking"
    wait "$api_pid"

    # Read exit code
    exit_code=$(cat "${temp_response}.exit" 2>/dev/null || echo "1")

    # Read response from file
    local response=$(cat "$temp_response" 2>/dev/null)

    # Check for final failure after all retries
    if [ "$exit_code" != "0" ] || [ -z "$response" ]; then
        echo -e "${RED}Error: Failed to get response from Groq after $MAX_RETRIES attempts${NC}" >&2
        echo "" >&2
        echo "All retry attempts exhausted. Possible causes:" >&2
        echo "  â€¢ Network connection issues" >&2
        echo "  â€¢ Groq API is experiencing downtime" >&2
        echo "  â€¢ Request timeout (large diff or slow connection)" >&2
        echo "  â€¢ Rate limiting or quota exceeded" >&2
        echo "" >&2
        echo "Suggestions:" >&2
        echo "  â€¢ Check your internet: ping api.groq.com" >&2
        echo "  â€¢ Verify service status: https://status.groq.com/" >&2
        echo "  â€¢ Try reducing diff size: DIFF_MAX_LINES=50 gh commit-ai" >&2
        echo "  â€¢ Use a different provider:" >&2
        echo "    - Ollama (local, no internet): export AI_PROVIDER=ollama" >&2
        echo "    - Anthropic: export AI_PROVIDER=anthropic" >&2
        echo "  â€¢ Wait a few minutes and try again" >&2
        rm -f "$temp_response" "$temp_error" "${temp_response}.exit"
        return 1
    fi

    # Validate response content
    if ! validate_api_response "$response"; then
        echo -e "${RED}Error: Invalid response from Groq${NC}" >&2
        echo "" >&2
        echo "The API returned an unexpected response format." >&2
        echo "This could indicate:" >&2
        echo "  â€¢ API version changes" >&2
        echo "  â€¢ Service degradation" >&2
        echo "  â€¢ Network proxy interference" >&2
        echo "" >&2
        echo "Try:" >&2
        echo "  â€¢ Run with verbose mode: gh commit-ai --verbose" >&2
        echo "  â€¢ Use a different provider: export AI_PROVIDER=ollama" >&2
        rm -f "$temp_response" "$temp_error" "${temp_response}.exit"
        return 1
    fi

    # Cleanup temp files
    rm -f "$temp_error" "${temp_response}.exit"

    if [ "$VERBOSE" = "true" ]; then
        echo "[Verbose] Response:"
        echo "$response" | jq '.' 2>/dev/null || echo "$response"
        echo ""
    fi

    # Check for errors
    if echo "$response" | grep -q '"error"'; then
        local error_type=$(echo "$response" | grep -o '"type":"[^"]*"' | head -1 | sed 's/"type":"//;s/"$//')
        local error_msg=$(echo "$response" | grep -o '"message":"[^"]*"' | head -1 | sed 's/"message":"//;s/"$//')
        local error_code=$(echo "$response" | grep -o '"code":"[^"]*"' | head -1 | sed 's/"code":"//;s/"$//')

        echo -e "${RED}Error from Groq" >&2
        [ -n "$error_code" ] && echo -e "${RED}Code: $error_code" >&2
        [ -n "$error_type" ] && echo -e "${RED}Type: $error_type" >&2
        [ -n "$error_msg" ] && echo -e "${RED}Message: $error_msg" >&2

        if [[ "$error_code" == *"invalid_api_key"* ]] || [[ "$error_msg" == *"API key"* ]]; then
            echo "Tip: Check your API key is valid" >&2
        elif [[ "$error_code" == *"rate_limit"* ]]; then
            echo "Tip: You've hit the rate limit. Wait a moment and try again" >&2
        elif [[ "$error_code" == *"model_not_found"* ]]; then
            echo "Tip: The model '$GROQ_MODEL' doesn't exist or you don't have access" >&2
        fi
        return 1
    fi

    # Extract token usage (global variables for cost tracking)
    INPUT_TOKENS=$(echo "$response" | grep -o '"prompt_tokens":[0-9]*' | head -1 | grep -o '[0-9]*')
    OUTPUT_TOKENS=$(echo "$response" | grep -o '"completion_tokens":[0-9]*' | head -1 | grep -o '[0-9]*')

    # Extract commit message from response
    # Groq uses OpenAI format: {"choices":[{"message":{"content":"..."},...}],...}
    # Use awk to properly extract JSON string value (handles escaped quotes)
    local raw_message=$(echo "$response" | awk -F'"content":"' '{
        if (NF > 1) {
            str = $2
            result = ""
            escaped = 0
            for (i = 1; i <= length(str); i++) {
                c = substr(str, i, 1)
                if (escaped) {
                    result = result c
                    escaped = 0
                } else if (c == "\\") {
                    result = result c
                    escaped = 1
                } else if (c == "\"") {
                    break
                } else {
                    result = result c
                }
            }
            print result
            exit
        }
    }')

    # Cleanup temp files
    rm -f "$temp_response"

    unescape_json "$raw_message"
}

# Handle version suggestion mode
if [ "$VERSION_MODE" = true ]; then
    suggest_next_version "$CREATE_TAG" "$TAG_PREFIX"
    exit 0
fi

# Handle code review mode (needs AI functions defined above)
if [ "$CODE_REVIEW_MODE" = true ]; then
    generate_code_review "$REVIEW_STAGED_ONLY"
    exit 0
fi

# Handle PR description mode (needs AI functions defined above)
if [ "$PR_DESCRIPTION_MODE" = true ]; then
    generate_pr_description "$BASE_BRANCH" "$OUTPUT_FILE"
    exit 0
fi

# Check for recent message in history (within last 5 minutes)
RECOVERED_MESSAGE=""
if is_recent_message && [ "$PREVIEW" != true ] && [ "$DRY_RUN" != true ]; then
    LAST_MESSAGE=$(get_last_message)
    if [ -n "$LAST_MESSAGE" ]; then
        echo ""
        echo "ðŸ’¡ Found recent commit message from history:"
        echo ""
        DISPLAY_LAST=$(convert_newlines "$LAST_MESSAGE")
        printf "%s\n\n" "$DISPLAY_LAST"
        echo -n "Reuse this message? (y/n/r to regenerate): "
        read -n 1 -r
        echo

        if [[ $REPLY =~ ^[Yy]$ ]]; then
            # Reuse the message
            COMMIT_MSG="$LAST_MESSAGE"
            RECOVERED_MESSAGE="true"
        elif [[ $REPLY =~ ^[Rr]$ ]]; then
            # User wants to regenerate - continue normally
            echo "Regenerating commit message..."
            echo ""
        else
            # Cancel
            echo "Commit cancelled"
            exit 0
        fi
    fi
fi

# Call the appropriate AI provider (skip if message was recovered)
if [ "$RECOVERED_MESSAGE" != "true" ]; then
    # Caching with debug instrumentation
    CACHE_KEY=""
    CACHED_MSG=""

    # Debug logging function (only when CACHE_DEBUG=true)
    cache_debug() {
        if [ "$CACHE_DEBUG" = "true" ]; then
            # Cross-platform timestamp (BSD date doesn't support milliseconds)
            local timestamp=$(date +%H:%M:%S 2>/dev/null || date +%T)
            echo "[$timestamp] $*" >> "${CACHE_DIR}/debug.log"
        fi
    }

    # Initialize debug log
    if [ "$CACHE_DEBUG" = "true" ]; then
        echo "=== Cache Debug Log ===" > "${CACHE_DIR}/debug.log"
    fi

    # Generate cache key from diff (with timing and error handling)
    if [ "$DISABLE_CACHE" != "true" ]; then
        cache_debug "Starting cache key generation"

        # Use the already-generated GIT_DIFF variable to avoid redundant git calls
        if [ -n "$GIT_DIFF" ]; then
            cache_debug "Using GIT_DIFF for cache key (length: ${#GIT_DIFF})"
            CACHE_KEY=$(echo "$GIT_DIFF" | get_diff_hash 2>/dev/null)
        else
            cache_debug "No diff available, generating from git"
            if [ "$AMEND_MODE" = true ]; then
                CACHE_KEY=$(git show HEAD 2>/dev/null | get_diff_hash 2>/dev/null)
            else
                CACHE_KEY=$(git diff --cached 2>/dev/null | get_diff_hash 2>/dev/null)
            fi
        fi

        cache_debug "Cache key generated: $CACHE_KEY"

        # Check cache
        if [ -n "$CACHE_KEY" ]; then
            cache_debug "Checking cache for key: $CACHE_KEY"
            CACHED_MSG=$(get_cached_response "$CACHE_KEY" 2>/dev/null) || true
            if [ -n "$CACHED_MSG" ]; then
                cache_debug "Cache check complete (found: yes)"
            else
                cache_debug "Cache check complete (found: no)"
            fi
        else
            cache_debug "ERROR: Cache key is empty"
        fi
    else
        cache_debug "Cache disabled via DISABLE_CACHE"
    fi

    # Use cached message if available
    if [ -n "$CACHED_MSG" ]; then
        cache_debug "Using cached message"
        echo "âœ“ Using cached commit message"
        COMMIT_MSG="$CACHED_MSG"
    else
        cache_debug "No cache hit, calling AI provider: $AI_PROVIDER"

        # Call AI provider
        case "$AI_PROVIDER" in
            ollama)
                cache_debug "Calling call_ollama"
                COMMIT_MSG=$(call_ollama "$PROMPT")
                cache_debug "call_ollama returned (length: ${#COMMIT_MSG})"
                ;;
            anthropic)
                cache_debug "Calling call_anthropic"
                COMMIT_MSG=$(call_anthropic "$PROMPT")
                cache_debug "call_anthropic returned (length: ${#COMMIT_MSG})"
                ;;
            openai)
                cache_debug "Calling call_openai"
                COMMIT_MSG=$(call_openai "$PROMPT")
                cache_debug "call_openai returned (length: ${#COMMIT_MSG})"
                ;;
            groq)
                cache_debug "Calling call_groq"
                COMMIT_MSG=$(call_groq "$PROMPT")
                cache_debug "call_groq returned (length: ${#COMMIT_MSG})"
                ;;
            *)
                echo -e "${RED}Error: Unknown AI provider '$AI_PROVIDER'"
                echo "Supported providers: ollama, anthropic, openai, groq"
                exit 1
                ;;
        esac

        # Save to cache (with error handling)
        if [ -n "$CACHE_KEY" ] && [ -n "$COMMIT_MSG" ] && [ "$DISABLE_CACHE" != "true" ]; then
            cache_debug "Saving to cache"
            save_cached_response "$CACHE_KEY" "$COMMIT_MSG" 2>/dev/null || cache_debug "ERROR: Failed to save cache"
            cache_debug "Cache save complete"
        fi
    fi

    cache_debug "AI provider section complete"
fi

# Strip markdown code fences and explanations if AI added them
# Remove lines that are just code fences and any explanatory text after the commit
COMMIT_MSG=$(echo "$COMMIT_MSG" | awk '
    /^```[a-zA-Z]*$/ { next }   # Skip opening fence line
    /^```$/ { next }             # Skip closing fence line
    /^\*\*explanation/ { exit }  # Stop at explanation section
    /^\*\*why/ { exit }          # Stop at why section
    /^\*\*note/ { exit }         # Stop at note section
    { print }
' | awk '
    # Remove trailing blank lines
    { lines[NR] = $0 }
    END {
        for (i = 1; i <= NR; i++) {
            if (i == NR) {
                # Last line - check if followed by blanks
                if (lines[i] != "") print lines[i]
            } else if (lines[i] != "" || lines[i+1] != "") {
                print lines[i]
            }
        }
    }
')

if [ -z "$COMMIT_MSG" ] || [ "$COMMIT_MSG" = "null" ]; then
    echo -e "${RED}Error: Failed to generate commit message"
    echo "Please check your API configuration and try again."
    exit 1
fi

# Handle multiple options mode
if [ "$MULTIPLE_OPTIONS" = "true" ]; then
    # Clean up any existing temp files
    rm -f /tmp/option_*.txt /tmp/reasoning_*.txt /tmp/ai_recommendation.txt 2>/dev/null

    # Parse options from response
    num_options=$(parse_multiple_options "$COMMIT_MSG")

    # Enforce lowercase on each option (unless disabled)
    if [ "$NO_LOWERCASE" != "true" ]; then
        for i in $(seq 1 $num_options); do
            if [ -f "/tmp/option_${i}.txt" ]; then
                option_content=$(cat "/tmp/option_${i}.txt")
                lowercased=$(enforce_lowercase "$option_content")
                echo "$lowercased" > "/tmp/option_${i}.txt"
            fi
        done
    fi

    # Apply template to each option if custom template exists
    if [ -f ".gh-commit-ai-template" ]; then
        PROJECT_TYPE=$(detect_project_type)
        TEMPLATE=$(load_template "$PROJECT_TYPE")
        for i in $(seq 1 $num_options); do
            if [ -f "/tmp/option_${i}.txt" ]; then
                option_content=$(cat "/tmp/option_${i}.txt")
                templated=$(apply_template "$TEMPLATE" "$option_content")
                echo "$templated" > "/tmp/option_${i}.txt"
            fi
        done
    fi

    # Display all options
    echo ""
    display_options "$num_options"

    # Show cost information for paid APIs
    if [ "$AI_PROVIDER" = "anthropic" ]; then
        calculate_cost "anthropic" "$ANTHROPIC_MODEL" "$INPUT_TOKENS" "$OUTPUT_TOKENS"
        echo ""
    elif [ "$AI_PROVIDER" = "openai" ]; then
        calculate_cost "openai" "$OPENAI_MODEL" "$INPUT_TOKENS" "$OUTPUT_TOKENS"
        echo ""
    fi

    # Get user selection
    selected=$(select_option "$num_options")

    if [ "$selected" = "cancelled" ]; then
        echo "Commit cancelled"
        rm -f /tmp/option_*.txt /tmp/reasoning_*.txt /tmp/ai_recommendation.txt 2>/dev/null
        exit 0
    fi

    # Load selected option
    COMMIT_MSG=$(cat "/tmp/option_${selected}.txt")
    rm -f /tmp/option_*.txt /tmp/reasoning_*.txt /tmp/ai_recommendation.txt 2>/dev/null

    # Save to message history
    save_message_history "$COMMIT_MSG"

    # Show selected message
    echo -e "\nSelected commit message:"
    echo "$COMMIT_MSG"
    echo ""
else
    # Single message mode - enforce lowercase (unless disabled)
    if [ "$NO_LOWERCASE" != "true" ]; then
        COMMIT_MSG=$(enforce_lowercase "$COMMIT_MSG")
    fi

    # Apply template if custom template exists
    if [ -f ".gh-commit-ai-template" ]; then
        PROJECT_TYPE=$(detect_project_type)
        TEMPLATE=$(load_template "$PROJECT_TYPE")
        COMMIT_MSG=$(apply_template "$TEMPLATE" "$COMMIT_MSG")
    fi

    # Save to message history
    save_message_history "$COMMIT_MSG"

    # Show the generated commit message with proper newlines
    echo -e "\nâœ“ Generated commit message:"
    DISPLAY_MSG=$(convert_newlines "$COMMIT_MSG")
    printf "%s\n\n" "$DISPLAY_MSG"

    # Show cost information for paid APIs
    if [ "$AI_PROVIDER" = "anthropic" ]; then
        calculate_cost "anthropic" "$ANTHROPIC_MODEL" "$INPUT_TOKENS" "$OUTPUT_TOKENS"
        echo ""
    elif [ "$AI_PROVIDER" = "openai" ]; then
        calculate_cost "openai" "$OPENAI_MODEL" "$INPUT_TOKENS" "$OUTPUT_TOKENS"
        echo ""
    fi
fi

# If message was recovered, display it
if [ "$RECOVERED_MESSAGE" = "true" ]; then
    echo -e "\nâœ“ Recovered commit message:"
    DISPLAY_MSG=$(convert_newlines "$COMMIT_MSG")
    printf "%s\n\n" "$DISPLAY_MSG"
fi

# Handle preview mode - just show and exit
if [ "$PREVIEW" = true ]; then
    exit 0
fi

# Handle dry-run mode - ask if user wants to save to file
if [ "$DRY_RUN" = true ]; then
    read -p "Save to file? (y/n): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        COMMIT_FILE=".git/COMMIT_MSG_$(date +%s)"
        # Strip ANSI codes and convert newlines before saving
        CLEAN_MSG=$(strip_ansi_codes "$COMMIT_MSG")
        CLEAN_MSG=$(convert_newlines "$CLEAN_MSG")
        printf "%s" "$CLEAN_MSG" > "$COMMIT_FILE"
        echo "âœ“ Saved to $COMMIT_FILE"
    else
        echo "Message not saved"
    fi
    exit 0
fi

# Ask for confirmation
while true; do
    echo -n "Use this commit message? (y/n/e to edit/r to regenerate): "
    read -n 1 -r
    echo

    if [[ $REPLY =~ ^[Yy]$ ]]; then
        # Strip any ANSI color codes before committing
        CLEAN_MSG=$(strip_ansi_codes "$COMMIT_MSG")
        # Convert literal \n to actual newlines
        CLEAN_MSG=$(convert_newlines "$CLEAN_MSG")

        if [ "$AMEND" = true ]; then
            # Amend the last commit with new message using HEREDOC for proper newline handling
            git commit --amend -m "$(cat <<EOF
$CLEAN_MSG
EOF
)"
            echo "âœ“ Amended commit successfully!"
            clear_message_history
        else
            # Stage all changes if nothing is staged
            if git diff --cached --quiet; then
                echo "Staging all changes"
                git add -A
            fi

            # Commit with the generated message using HEREDOC for proper newline handling
            git commit -m "$(cat <<EOF
$CLEAN_MSG
EOF
)"
            echo "âœ“ Committed successfully!"
            clear_message_history
        fi
        break
    elif [[ $REPLY =~ ^[Ee]$ ]]; then
        # Strip any ANSI color codes before editing
        CLEAN_MSG=$(strip_ansi_codes "$COMMIT_MSG")
        # Convert literal \n to actual newlines
        CLEAN_MSG=$(convert_newlines "$CLEAN_MSG")

        # Allow user to edit the message in editor using HEREDOC for proper newline handling
        if [ "$AMEND" = true ]; then
            git commit --amend -e -m "$(cat <<EOF
$CLEAN_MSG
EOF
)"
            echo "âœ“ Amended commit with edited message!"
            clear_message_history
        else
            git commit -e -m "$(cat <<EOF
$CLEAN_MSG
EOF
)"
            echo "âœ“ Committed with edited message!"
            clear_message_history
        fi
        break
    elif [[ $REPLY =~ ^[Rr]$ ]]; then
        # Regenerate the commit message
        echo "Regenerating commit message..."
        echo ""

        # Call the AI provider again
        case "$AI_PROVIDER" in
            ollama)
                COMMIT_MSG=$(call_ollama "$PROMPT")
                ;;
            anthropic)
                COMMIT_MSG=$(call_anthropic "$PROMPT")
                ;;
            openai)
                COMMIT_MSG=$(call_openai "$PROMPT")
                ;;
        esac

        # Strip markdown code fences
        COMMIT_MSG=$(echo "$COMMIT_MSG" | awk '
            /^```[a-zA-Z]*$/ { next }
            /^```$/ { next }
            /^\*\*explanation/ { exit }
            /^\*\*why/ { exit }
            /^\*\*note/ { exit }
            { print }
        ' | awk '
            { lines[NR] = $0 }
            END {
                for (i = 1; i <= NR; i++) {
                    if (i == NR) {
                        if (lines[i] != "") print lines[i]
                    } else if (lines[i] != "" || lines[i+1] != "") {
                        print lines[i]
                    }
                }
            }
        ')

        # Enforce lowercase (unless disabled)
        if [ "$NO_LOWERCASE" != "true" ]; then
            COMMIT_MSG=$(enforce_lowercase "$COMMIT_MSG")
        fi

        # Apply template if custom template exists
        if [ -f ".gh-commit-ai-template" ]; then
            PROJECT_TYPE=$(detect_project_type)
            TEMPLATE=$(load_template "$PROJECT_TYPE")
            COMMIT_MSG=$(apply_template "$TEMPLATE" "$COMMIT_MSG")
        fi

        # Save to message history
        save_message_history "$COMMIT_MSG"

        # Show the new message
        echo -e "\nâœ“ Regenerated commit message:"
        DISPLAY_MSG=$(convert_newlines "$COMMIT_MSG")
        printf "%s\n\n" "$DISPLAY_MSG"

        # Show cost information for paid APIs
        if [ "$AI_PROVIDER" = "anthropic" ]; then
            calculate_cost "anthropic" "$ANTHROPIC_MODEL" "$INPUT_TOKENS" "$OUTPUT_TOKENS"
            echo ""
        elif [ "$AI_PROVIDER" = "openai" ]; then
            calculate_cost "openai" "$OPENAI_MODEL" "$INPUT_TOKENS" "$OUTPUT_TOKENS"
            echo ""
        fi

        # Loop back to confirmation prompt
    else
        echo "Commit cancelled"
        exit 0
    fi
done
